\capitulo{5}{Aspectos relevantes del desarrollo del proyecto}

\section{Algoritmos de aprendizaje semisupervisado}

A continuación se facilitan los resultados de las experimentaciones realizadas con las implementaciones propias de algunos métodos de aprendizaje semisupervisado.

Para evaluar la calidad de las implementaciones, se han realizado distintos experimentos con algunos de los \textit{dataset} más comunes en métodos de clasificación. En concreto, se han utilizado los que están disponibles en la librería \textit{SKlearn}, que se muestran en la tabla~\ref{tabla_datasets_sklearn}. El parámetro $n$ representa el número de instancias que contiene un determinado conjunto de datos, mientras que el parámetro $m$ muestra el número de características que contiene cada una de esas instancias.

\begin{table}
	\small
	\begin{centering}
		\begin{tabular}{@{}p{4em} p{20em} r r r @{}}
			\toprule
			\textbf{Nombre} & \textbf{Descripción} & \textbf{Clases} & $n$ & $m$\\ 
			\midrule
			
			Iris & Conjunto de instancias pertenecientes a diferentes tipos de plantas de la especie Iris. & 3 & 150 & 4 \\\\
			Dígitos & Conjunto de instancias que representan una imagen de 8x8 perteneciente a un dígito. & 10 & 1797 & 64 \\\\
			Vino & Conjunto de instancias pertenecientes a tres clases de vino con sus parámetros estimados mediante análisis químico. & 3 & 178 & 13 \\\\
			Cáncer de Mama & Conjunto de instancias que representan parámetros de distintas mujeres que pueden padecer o no cáncer (clasificación binaria). & 2 & 569 & 30 \\
			\bottomrule
		\end{tabular}
	\end{centering}
	\caption[Experimentación: \textit{datasets} estándar]{Descripción de los \textit{datasets} utilizados para validar los algoritmos.}
	\label{tabla_datasets_sklearn}	
\end{table}



\subsection{\textit{Co-forest}}

Para comprobar la correctitud del algoritmo se han realizado diversos experimentos. En primer lugar, se ha evaluado el modelo en diversas situaciones de su ciclo de vida. Posteriormente, se ha realizado una comparativa contra la implementación proporcionada por KEEL.

\subsubsection{Experimentación con el algoritmo}

Los resultados se pueden observar en las gráficas~\ref{gr:cf_train-iterations},~\ref{cf:cf_time-percentage} y ~\ref{cf:tt_trees}.


\begin{itemize}
	\item \textbf{Fase de entrenamiento:} como se ha desarrollado en los conceptos teóricos, la fase de entrenamiento en el \textit{co-forest} es iterativa, y finaliza cuando ningún árbol recibe nuevas pseudo-etiquetas que puedan cambiar su comportamiento (en la fase de re-entrenamiento).
	
	Se ha querido estudiar la evolución del \textit{score} (porcentaje de aciertos respecto al total de las predicciones) del algoritmo durante la fase de entrenamiento para los cuatro conjuntos de datos definidos en la tabla~\ref{tabla_datasets_sklearn}. Para ello, se ha realizado una gráfica ilustrando cómo evoluciona en función de la iteración en la que se encuentre.
	
	\begin{figure}[h]
		\caption[\textit{Co-Forest}: Distribución de datos entrenamiento y \textit{test}]{Gráfica que representa la distribución de los datos.}
		\centering
		\includegraphics[scale=0.3]{../img/memoria/5_entrenamiento_particiones}
		\label{5_entrenamiento_particiones}
	\end{figure}

	Para garantizar que los resultados obtenidos no son producto de una partición concreta de los datos, se ha realizado validación cruzada (con 10 particiones sin repetición). Por lo tanto, el porcentaje de datos utilizados para el entrenamiento es el $90\%$ del total (utilizando estratificación). Los datos de entrenamiento, a su vez, se dividen en etiquetados y no etiquetados. En este caso, el $20\%$ representa los datos etiquetados, y el $80\%$ los no etiquetados, como se puede observar en la imagen~\ref{5_entrenamiento_particiones}. Se han utilizado 20 árboles.
	
	La exactitud media obtenida se puede ver representada en la gráfica~\ref{gr:cf_train-iterations}. Es destacable que, dependiendo de los datos que se utilicen para entrenar el \textit{co-forest}, puede variar el número de iteraciones que se necesiten (incluso dentro de un mismo \textit{dataset}). Por ello, siempre se representa el número máximo de iteraciones realizadas, y para no deformar la media, se ha considerado que el valor de las iteraciones inexistentes es el mismo que el valor obtenido en la última iteración (ya que si, el algoritmo siguiese, el resultado devuelto sería igual debido a que no se volvería a entrenar ningún árbol).
	
	\begin{figure}[h]
		\caption[\textit{Co-Forest}: resultados experimentación (iteraciones-entrenamiento)]{Gráfica que muestra la evolución de la \textit{accuracy} para cada \textit{dataset} (además de su desviación) durante las iteraciones del entrenamiento del \textit{co-forest}.}
		\centering
		\includegraphics[scale=0.55]{../img/memoria/5_coforest_score-iteraciones}
		\label{gr:cf_train-iterations}
	\end{figure}

	Como se puede comprobar, el modelo mejora los resultados iniciales (exactitud obtenida en la iteración $0$, cuando todavía no se ha realizado entrenamiento semi-supervisado y se cuenta con un \textit{random forest} tradicional) en dos de los conjuntos de datos, mientras que en los otros dos empeora. Este comportamiento es lógico debido a que no todos los modelos son apropiados para todos los conjuntos de datos. Si se observa con más detenimiento cada conjunto de datos individualmente en el resto de los cuadrantes de la gráfica~\ref{gr:cf_train-iterations}, se puede observar que la desviación típica varía considerablemente, por lo que se puede deducir que el modelo podría llegar a ser utilizable en la mayoría de los casos si la partición es la adecuada.

	\item \textbf{Tiempo de entrenamiento:} además, también se ha querido evaluar cómo varía el tiempo de entrenamiento en función del número de instancias utilizadas. Para ello, se ha trabajado con el \textit{dataset} que contiene un mayor número de datos (<<Dígitos>>), y los resultados obtenidos se pueden observar en el primer cuadrante de la gráfica~\ref{cf:cf_time-percentage}. Como se puede comprobar, sigue un crecimiento aproximadamente lineal. La velocidad, en este caso, es alta, pero cabe recordar que depende en gran medida del número de árboles utilizados y de las iteraciones que estos realicen. Se ha representado en la línea negra punteada, además, el resultado del modelo de regresión lineal.

\begin{figure}[h]
	\caption[\textit{Co-Forest}: resultados experimentación (tiempo-porcentaje)]{Gráfica que muestra el tiempo de entrenamiento requerido para el \textit{co-forest} en función del número de instancias, además de la evolución del \textit{score} (\textit{accuracy}) en función del porcentaje total de datos destinado al entrenamiento.}
	\centering
	\includegraphics[scale=0.4]{../img/memoria/5_coforest_time-percentage}
	\label{cf:cf_time-percentage}
\end{figure}


	\item \textbf{Datos de entrenamiento:} En este apartado de la experimentación, se ha querido evaluar cómo se comporta el \textit{co-forest} en función del porcentaje de datos que se utilice para el entrenamiento. Nuevamente, se han utilizado  $20$ árboles, y la división del conjunto de datos de entrenamiento se ha mantenido: $20\%$ etiquetados y $80\%$ no etiquetados. Los conjuntos están estratificados.
	
	Como se puede comprobar en el segundo cuadrante de la gráfica~\ref{cf:cf_time-percentage}, sigue el comportamiento esperado, y por lo general a más instancias utilizadas para entrenar el modelo, mejor desempeño presenta. Nuevamente, recalcar que el resultado obtenido es la media de 10 experimentos realizados.
	
	\item{\textbf{Número de árboles}}: Hasta este momento, todos los resultados han sido realizados para $n=20$. Es decir, utilizando $20$ árboles. Sin embargo, el comportamiento del \textit{co-forest} varía considerablemente en función del número de árboles contenidos en el \textit{ensemble}, lo que motiva la realización del siguiente experimento. Nuevamente, se ha desarrollado utilizando cuatro conjuntos de datos y validación cruzada, por lo que se muestra la media en la exactitud para las $10$ particiones.
	
	Como se puede comprobar en la gráfica~\ref{cf:tt_trees}, en general, cuantos más árboles se utilicen, mejor \textit{score} alcanza el \textit{co-forest}. Es destacable que, evidentemente, a mayor $n$, mayor tiempo de procesamiento es requerido, como se ilustra en el segundo cuadrante de esa misma gráfica. Por lo tanto, se debería alcanzar un compromiso. Por lo general, los autores~\cite{originalCoForest2007} utilizan valores de $n \geq 6$.
	
	\begin{figure}[h]
		\caption[\textit{Co-Forest}: resultados experimentación (número de árboles)]{Gráfica que muestra la \textit{accuracy} alcanzada por el \textit{co-forest}, además del tiempo de entrenamiento requerido en función del número de árboles utilizados}
		\centering
		\includegraphics[scale=0.7]{../img/memoria/5_coforest_trees}
		\label{cf:tt_trees}
	\end{figure}
	
\end{itemize} 


\subsubsection{Comparativa contra KEEL}

Para asegurar el correcto funcionamiento del algoritmo implementado, se ha decidido comparar contra la herramienta \textit{KEEL}, creada por distintas universidades españolas y financiada por el Ministerio de Educación y Ciencia.

En primer lugar y para tener más capacidad de <<manipulación>>, se optó por descargar los ficheros fuentes de la última versión de Github~\cite{keelRepo} en lugar de utilizar la versión compilada que ofrecen los desarrolladores. Se puede consultar cómo en los anexos.

Para comparar los algoritmos en las condiciones más realistas posibles, se definieron las características mostradas en la tabla~\ref{tabla_coforest_keelvsnuestro_diseño}.

\begin{table}
	\begin{centering}
		\begin{tabular}{@{}p{10em} p{20em} @{}}
			\toprule
			\textbf{Parámetro} & \textbf{Valor} \\ 
			\midrule
			$n$ & 6\\
			$\theta$ & 0.75 \\
			\textit{Folds} & 10 \\
			\% etiquetados & 10\% (en el conjunto de entrenamiento). \\
			Comentarios & Para la comparativa se han utilizado los \textit{datasets} <<Iris>> y <<Vino>>, ambos estratificados.\\
			\bottomrule
			
		\end{tabular}
	\end{centering}
	\caption[\textit{Co-forest}: resumen del experimento]{Tabla resumen con el diseño del experimento.}
	\label{tabla_coforest_keelvsnuestro_diseño}	
\end{table}

\begin{table}
	\begin{centering}
		
		\begin{tabular}{@{} p{4em} p{5em} p{7em} p{7em} p{7em} @{}}
			\toprule
			\multirow{2}{*}{\textbf{\textit{ \hfil Fold}}} & \multicolumn{2}{c}{\hfil \textbf{Iris}}& \multicolumn{2}{c}{\hfil \textbf{Vino}} \\
			\cmidrule{2-3} \cmidrule{4-5}
			& \hfil Propia & \hfil KEEL & \hfil Propia & \hfil KEEL\\ 
			\toprule
			\hfil 1 &\hfil 1.00	&\hfil 0.87	& \hfil 0.89  & \hfil0.83 \\
			\hfil 2 &\hfil 0.86	&\hfil 0.80	& \hfil 1.00 	&  \hfil 0.94 \\
			\hfil 3 & \hfil 1.00	& \hfil 1.00	& \hfil 0.94	& \hfil 1.00 \\
			\hfil 4 & \hfil 1.00	& \hfil 1.00	& \hfil 0.94	& \hfil 0.89 \\
			\hfil 5 & \hfil 0.87	& \hfil 1.00	& \hfil 0.65	& \hfil 0.88 \\
			\hfil 6 & \hfil 0.93	& \hfil 0.93	& \hfil 0.94	& \hfil 0.71 \\
			\hfil 7 & \hfil 0.93	& \hfil 1.00	& \hfil 0.83	& \hfil 0.89 \\
			\hfil 8 & \hfil 0.93	& \hfil 0.93	& \hfil 0.94	& \hfil 0.78 \\
			\hfil 	9 & \hfil 0.93	& \hfil 0.93	& \hfil 0.67	& \hfil 0.72 \\
			\hfil 10& \hfil 0.87	& \hfil 0.87	& \hfil 0.94	& \hfil 0.94 \\
			\midrule
			\hfil \textbf{Media} 			& \hfil 0.93	& \hfil 0.93	& \hfil 0.88	& \hfil 0.86 \\
			\bottomrule
		\end{tabular}
	\end{centering}
	\caption[\textit{Co-forest}: comparativa entre KEEL y la implementación propia]{Comparativa entre la \textit{accuracy} del \textit{co-forest} de KEEL y el propio sobre el conjunto de \textit{test}.}
	\label{tabla_coforest_keelvsnuestro}	
\end{table}

Dentro de los ficheros fuente de KEEL, se pueden encontrar distintos conjuntos de datos con las particiones del \textit{K-cross-validation} ya hechas y que son utilizadas en las ejecuciones de sus experimentos. Para comprobar ambos algoritmos en igualdad de condiciones, se convirtieron dichos archivos \texttt{*.dat} en \texttt{*.csv} y se importaron en la implementación propia mediante la librería Pandas. De esta manera, el único parámetro que no es idéntico entre ambas implementaciones es qué instancias de entre los datos etiquetados seleccionan los árboles para entrenarse en un primer momento (son aleatorios y generar las pequeñas diferencias observadas).

Los resultados obtenidos se pueden observar en la tabla~\ref{tabla_coforest_keelvsnuestro}. Como se puede comprobar, ambos algoritmos obtienen resultados prácticamente idénticos, siendo un poco superior el porcentaje de acierto logrado por la herramienta implementada propia en el caso del \textit{dataset} <<Vino>>.


\subsection{\textit{Tri-Training}}

Al igual que en los algoritmos anteriores, se ha decidido experimentar con distintas opciones a la hora de representar las gráficas, además de realizar una comparativa contra \textit{sslearn} y LAMDA para probar la implementación.


\subsubsection{Experimentación con el algoritmo}

Los resultados se pueden observar en las gráficas~\ref{gr:tt_train-iterations} y~\ref{gr:tt_time-percentage}.

\begin{figure}[h]
	\caption[\textit{Tri-training}: resultados experimentación (iteraciones-entrenamiento)]{Gráfica que muestra la evolución de la \textit{accuracy} para cada \textit{dataset} (además de su desviación) durante las iteraciones del entrenamiento del \textit{tri-training}.}
	\centering
	\includegraphics[scale=0.5]{../img/memoria/5_tritraining_score-iteraciones}
	\label{gr:tt_train-iterations}
\end{figure}

\begin{figure}[h]
	\caption[\textit{Tri-training}: resultados experimentación (tiempo-porcentaje)]{Gráfica que muestra el tiempo de entrenamiento requerido para el \textit{tri-training}, además de la evolución del \textit{score} en función del número de instancias.}
	\centering
	\includegraphics[scale=0.4]{../img/memoria/5_tritraining_time-percentage}
	\label{gr:tt_time-percentage}
\end{figure}

\begin{itemize}
	\item \textbf{Fase de entrenamiento:} se ha querido evaluar la evolución de la \textit{accuracy} del modelo en función de la iteración del entrenamiento en la que se encuentre. En este caso, el \textit{tri-training} utiliza como estimadores base un \textit{naive-bayes} gaussiano, un árbol de decisión y un \textit{K-neighbors}. Al igual que en el \textit{co-forest}, los resultados representados son la media de 10 experimentos realizados mediante validación cruzada (10 <<entrenamientos>> distintos) y se pueden observar en la gráfica~\ref{gr:tt_train-iterations}, donde el primer cuadrante compara todos los \textit{datasers} y el resto representa la desviación entre las distintas fases de entenamiento para cada \textit{dataset}.
	
	Como se puede comprobar, el modelo mejora los resultados iniciales (exactitud obtenida en la iteración $0$, cuando todavía no se ha comenzado el algoritmo de entrenamiento semisupervisado), siendo especialmente notable en los \textit{datasets} <<Vino>> y  <<Dígitos>>. Por ello, se deduce que la incorporación del conjunto de datos no etiquetado durante el entrenamiento es útil y mejora la hipótesis aprendida en cada uno de los clasificadores base (y, por ello, la general del \textit{ensemble}).
	
	\item \textbf{Tiempo de entrenamiento:} nuevamente se ha trabajado con el \textit{dataset} que contiene un mayor número de datos y los resultados obtenidos se representan en el primer cuadrante de la gráfica~\ref{gr:tt_time-percentage}. Como se puede observar, el tiempo crece de forma aproximadamente lineal con una alta velocidad (debido en parte a que este \textit{dataset} no realiza un número elevado de iteraciones durante el entrenamiento).
	
	\item \textbf{Datos de entrenamiento:} en este caso, se quiere evaluar el desempeño del \textit{tri-training} en función del porcentaje del \textit{dataset} que se utilice para el entrenamiento (posteriormente este conjunto será dividido en $L$ ($20\%$) y $U$ ($80\%$)). Los resultados mostrados son la media de 10 experimentos y se observan en el segundo cuadrante de la gráfica~\ref{gr:tt_time-percentage}. En este caso, un buen compromiso sería utilizar un $80\%$ de los datos, ya que por lo general a mayor número de instancias utilizadas durante el entrenamiento mejor resultado, no alcanzándose siempre la máxima exactitud cuando se usa el mayor porcentaje.
\end{itemize} 

\subsubsection{Comparativa contra sslearn y LAMDA}

En el caso del \textit{tri-training}, existen implementaciones en \texttt{python} que, además, permiten que los estimadores base utilizados sean los disponibles en la librería \textit{Scikit-learn}. Estas son <<\textit{sslearn}>>, biblioteca de aprendizaje semisupervisado escrita por José Luis Garrido-Labrador y disponible en Github~\cite{sslearnRepo} y <<LAMDA>>, un \textit{toolkit}~\cite{lamdasslPaper} desarrollado por Lin-Han Jia (y su equipo) que se encuentra públicamente disponible para su uso~\cite{lamdasslRepo}.

Para la comparativa se ha realizado validación cruzada utilizando 10 \textit{folds}. Evidentemente, ambos modelos han sido entrenados con el mismo conjunto de entrenamiento (más concretamente, idénticos $L$ y $U$) y probados con el mismo conjunto de \textit{test}. Como estimadores base se ha utilizado el árbol de decisión disponible en la librería \textit{Scikit-learn}.

\begin{figure}[h]
	\caption[\textit{Tri-training}: comparativa contra LAMDA]{Gráfica que representa la variación de la \textit{accuracy} en cada \textit{fold} y la media para la implementación del \textit{tri-training} de LAMDA y la propia.}
	\centering
	\includegraphics[scale=0.62]{../img/memoria/5_tritraining_lamda}
	\label{gr:tt_vs_lamda}
\end{figure}

En el caso de la comparativa contra \textit{sslearn}, el resultado se puede contemplar en la gráfica~\ref{gr:tt_vs_sslearn}, mientras que el caso de LAMDA se observa en la gráfica~\ref{gr:tt_vs_lamda}. Como se puede comprobar, la media de la \textit{accuracy} para ambos modelos es prácticamente idéntica. Hay algunas variaciones en la \textit{score} para distintos \textit{folds}, pero pueden deberse a detalles de implementación y selección de los conjuntos internamente. Por este motivo, la implementación se considera correcta.

\begin{figure}[h]
	\caption[\textit{Tri-training}: comparativa contra \textit{sslearn}]{Gráfica que representa la variación de la \textit{accuracy} en cada \textit{fold} y la media para la implementación del \textit{tri-training} de \textit{sslearn} y la propia.}
	\centering
	\includegraphics[scale=0.62]{../img/memoria/5_tritraining_sslearn}
	\label{gr:tt_vs_sslearn}
\end{figure}


\section{Detección de ataques en sistemas de recomendación}

El objetivo de este apartado en el proyecto es probar nuevos métodos de aprendizaje semisupervisado aplicados a la detección de ataques en sistemas de recomendación. Para lograr este fin, se decidió, en primer lugar, reproducir el artículo original~\cite{zhou2021SemisupervisedRecommendationAttack}, que utiliza el algoritmo \textit{co-forest}. Como los autores no especifican detalles de implementación en su artículo (cómo construir perfiles de ataque, dónde encontrar bases de datos o código, etc.), se concluyó que comparar los resultados obtenidos contra los suyos es la mejor forma de determinar la correctitud del trabajo desarrollado. Para ello, se ha utilizado el \textit{dataset} MovieLens10M.

\subsection{MovieLens 10M}
\subsubsection{Descripción}

MovieLens10M~\cite{groupLensDatasets} es un conjunto de datos utilizado típicamente en la investigación y desarrollo de sistemas de recomendación. Contiene 10\,000\,054 opiniones generadas por 71\,567 usuarios acerca de 10\,681 películas. Estas reseñas han sido recopiladas del servicio \textit{online} de películas MovieLens\footnote{https://movielens.org/}.

Los usuarios han sido seleccionados aleatoriamente entre los perfiles que tengan más de 20 películas valoradas y está documentado que todos son auténticos~\cite{zhou2021SemisupervisedRecommendationAttack} y pertenecen a usuarios reales. Por lo tanto, los perfiles atacantes han de ser construidos mediante programación.

\subsubsection{Extracción de vectores de características}

Como se puede comprobar en el \textit{paper} de Zhou y Duan~\cite{zhou2021SemisupervisedRecommendationAttack} los perfiles de usuarios normales son distinguibles de los atacantes debido a su forma de puntuar. En función de estos hábitos, se puede elaborar un método de detección basado en ventanas.

En primer lugar, se dividen todos los ítems del \textit{dataset} en ventanas, consiguiendo un conjunto de $J$ ventanas (\{$w_1, w_2, ..., w_J$\}). No se aplica ningún orden especial, sino que se respeta el que aparece en la propia base de datos. El número de ítems que posee cada ventana se reparte como se muestra en la ecuación~\ref{eqn:window_reparto}, donde $Q$ es el cociente de dividir el número total de ítems entre $J$.
	
\[|w_j| = \left\{ \begin{array}{lr} Q + 1, & j < q\\ Q, & j \ge q \label{eqn:window_reparto} \end{array} \right. \] 

Posteriormente se calcula, para cada usuario y ventana, $NRW_{u, w_j}$ y  $WNRW_{u, w_j}$ como se muestra en las ecuaciones~\ref{eqn:NRW} y \ref{eqn:WNRW} respectivamente. $NRW$ son las siglas de \textit{number of ratings per window}, y $WNRW$ \textit{weighted number of ratings per window}. Es decir, para un determinado usuario, el número de votaciones que haya realizado en una ventana y el ratio de esta respecto al total.

\begin{equation}\label{eqn:NRW} NRW_{u, w_j} = \sum_{i\in w_j, r_{u,i} \ne 0}^{} 1 \end{equation}
\begin{equation}\label{eqn:WNRW} WNRW_{u, w_j} = \frac{\sum_{i\in w_j, r_{u,i} \ne 0}^{} 1}{\sum_{i\in I, r_{u,i} \ne 0}^{} 1} \end{equation}

Aplicando estas fórmulas como se muestra en el pseudocódigo~\ref{alg:window_feature_extraction}, se obtienen los vectores de características. Como se puede deducir, este algoritmo se aplica indistintamente a perfiles genuinos y atacantes, ya que únicamente se precisan las reseñas del usuario. Para una mayor comodidad a la hora de experimentar con estos datos, se han generado ficheros \texttt{.csv} con los vectores de características que posteriormente se importarán mediante Pandas para generar conjuntos de entrenamiento y \textit{test}. Debido a que se trata de un problema de clasificación binaria, los perfiles atacantes reciben una etiqueta de $1$ y los verdaderos un $0$. Cabe destacar, que debido a que en el conjunto de MovieLens todos los usuarios son genuinos, se han de generar las reseñas de los perfiles atacantes. 

\begin{algorithm}
	\KwIn{Conjunto de usuarios $S$, número de ventanas $J$, conjunto de reseñas del usuario $R$.}
	\KwOut{Conjunto de vectores de características $X$.}
	\BlankLine
	$X \leftarrow \emptyset$\\
	\For{$u \in S$}{
		\For{$j \in J$}{
			Calcular $NRW_{u, w_j}$\\
			Calcular $WNRW_{u, w_j}$\\
		}
		$x_u \leftarrow \{NRW_{u, w_1},  WNRW_{u, w_1},  ..., NRW_{u, w_j},  WNRW_{u, w_j}\}$\\
		$X \leftarrow X \cup x_u$\\
	}
	\Return{$X$}
	\caption{Algoritmo de generación de vectores de características.}
	\label{alg:window_feature_extraction}
\end{algorithm}


\subsubsection{Creación de reseñas atacantes}

Se han incluido tres tipos de ataques distintos: \textit{random}, \textit{average} y \textit{bandwagon}. En primer lugar, se han sintetizado las reseñas y posteriormente se han generado los vectores de características idénticamente a los perfiles verdaderos.

La metodología de construcción de las valoraciones sigue los modelos estadísticos expuestos en la sección teórica del proyecto. Sin embargo, se puede visualizar un resumen de los escogidos en la tabla~\ref{ataques_coforest}.

\begin{table}
\begin{centering}
	\begin{tabular}{@{}p{5em} p{6em} p{11em} p{8em}@{}}
		\toprule
		\textbf{Modelo} & $\hfil{I_S}$ & \textbf{Valoración} $\mathbf{I_F}$ &  \textbf{Valoración} $\mathbf{I_t}$\\ 
		\midrule
		Random & $\hfil\emptyset$ & Aleatoria siguiendo una distribución $\mathcal{N}(\mu,\,\sigma)$. & máxima o mínima \\
		Average & $\hfil\emptyset$ & Aleatoria siguiendo una distribución $\mathcal{N}(\mu_i,\,\sigma_i)$. & máxima o mínima\\
		Bandwagon (random) &\centering$k$ ítems más populares & Aleatoria siguiendo una distribución $\mathcal{N}(\mu,\,\sigma)$. & máxima o mínima\\
		\bottomrule
	\end{tabular}
	\caption[Experimentación: características de ataques a detectar]{Características estadísticas de los tipos de perfiles atacantes.}
	\label{ataques_coforest}	
\end{centering}
\end{table}

Para construir las reseñas pertenecientes a un ataque del tipo \textit{random}, se ha obtenido, en primer lugar, la media de la puntuación general para todas las películas del sistema y su desviación. Los ítems de relleno han sido seleccionados aleatoriamente entre toda la base de datos (excluyendo, evidentemente, los ítems objetivo), y se ha asignado a cada uno una puntuación aleatoria siguiendo una distribución normal parametrizada por la media y desviación <<global>> del sistema. Evidentemente, esta puntuación ha sido corregida para que se encuentre entre los rangos admitidos (por ejemplo, de $0$ a $5$ estrellas). Debido a que el método de detección utilizado no necesita fechas, el campo perteneciente a la \textit{timestamp} no ha sido rellenado. Posteriormente, se ha asignado la máxima puntuación a los ítems objetivo (\textit{push attack}).

En el caso del ataque \textit{average}, el procedimiento ha sido el mismo, solo que en este caso las puntuaciones de los ítems de relleno son más representativas. En lugar de seguir una normal parametrizada por las características del sistema a nivel global, se ha calculado para cada película su media y su desviación, y se ha asignado una valoración aleatoria que sigue esta distribución. Es decir, cada ítem de relleno recibe una puntuación aleatoria que sigue una distribución normal con media la correspondiente a ese ítem en concreto, y con su respectiva desviación. En caso de que se escoja una película nunca antes valorada, la media utilizada es la media del rango (por ejemplo, 2.5 estrellas) y la desviación es $0$.

Por último, el ataque \textit{bandwagon}. Este ataque se realiza exactamente igual que el \textit{random} solo que, además, se añade un conjunto nuevo, los <<ítems seleccionados>> o $I_s$. En este caso, se escogen los $k$ ítems más populares de la base de datos (se entiende por más <<popular>> aquel ítem que posea más valoraciones). Evidentemente, este conjunto se excluye (además de los ítems objetivo) a la hora de escoger los ítems de relleno. La valoración asignada a $I_s$ ha sido o bien la máxima, o bien la mínima (en función de su nota media).

\subsubsection{Generación de conjuntos de entrenamiento y \textit{test}. Parámetros.}

Para generar el conjunto de entrenamiento, se ha utilizado el mismo proceso que el descrito en el \textit{paper} de Zhou y Duan~\cite{zhou2021SemisupervisedRecommendationAttack}. La distribución de los datos utilizados se muestra en la tabla~\ref{tbl:entrenamiento_ML10M}.

En primer lugar, se han seleccionado 1000 perfiles aleatorios verdaderos y se han extraído sus vectores de características como se ha indicado previamente. Posteriormente, se han generado reseñas para perfiles de atacantes, y se han extraído sus vectores.

\begin{table}
	\begin{centering}
		\begin{tabular}{@{} p{9em} p{7em} p{3em} p{3em} p{3em} p{3em} @{}}
			\toprule
			\multirow{2}{*}{\hfil \textbf{Tipo}} & \multirow{2}{*}{\hfil \textbf{Número}} & \multicolumn{4}{c}{\hfil \textbf{Tamaño del relleno}} \\ \cmidrule{3-6}
			&\hfil   &\hfil \textbf{1\%} &\hfil \textbf{3\%} & \hfil \textbf{5\%} & \hfil \textbf{10\%}\\ 
			\toprule
			Genuino &1000&\hfil -	& \hfil -  & \hfil - & \hfil -\\
			\textit{Random attack} &-	&\hfil 10 & \hfil 10	&  \hfil 10 & \hfil 10\\
			\textit{Average attack} &-	& \hfil 10 & \hfil 10 & \hfil 10 & \hfil 10 \\
			\textit{Bandwagon attack} &- & \hfil 10 & \hfil 10 & \hfil 10 & \hfil10 \\
			\\ \bottomrule
		\end{tabular}
	\end{centering}
	\caption[Sistemas de recomendación: descripción de los conjuntos]{Número y distribución del conjunto de entrenamiento.}
	\label{tbl:entrenamiento_ML10M}	
\end{table}

En cuanto al conjunto de test, se han generado $10$ conjuntos distintos para garantizar que los resultados de los experimentos no son fruto de una partición concreta de los datos, sino media de una cantidad aceptable. Para ello, se han realizado ficheros \texttt{.csv} para distintos porcentajes de tamaño de ataque ($1\%, 2\%, 5\%$ y $10\%$) y tamaño de relleno ($1\%, 3\%, 5\%$ y $10\%$) de los atacantes. El número de perfiles verdaderos en cada conjunto de \textit{test} equivale a $1000$ (y son excluyentes entre ellos y respecto al conjunto de entrenamiento).

En cuanto a los parámetros del algoritmo, se han establecido los mismos que en el \textit{paper} de Zhou y Duan~\cite{zhou2021SemisupervisedRecommendationAttack}. El tamaño de ventana ($J$) se ha establecido a 40 y el porcentaje de etiquetas en el conjunto de entrenamiento ($d$) equivale al $30\%$. Como el \textit{paper} no indica qué hacer en el caso del \textit{bandwagon}, se ha decidido que el número de ítems relevantes a evaluar ($k$) es 30. En cuanto al \textit{co-forest}, el umbral de confianza $\theta$ se ha fijado a $0$.$75$ y el número de árboles ($n$) utilizado es 6.

Cabe destacar que, debido a que es escaso el número de instancias positivas, se ha decidido utilizar como curva para calcular las AUC la curva \textit{precision-recall} (en lugar de la curva ROC).

\subsubsection{Resultados}

Los resultados se han desglosado en función del tipo de perfiles atacantes inyectados. Se ilustran en las respectivas gráficas: \textit{random attack}~\ref{5_random_attack}, \textit{average attack}~\ref{5_average_attack} y \textit{bandwagon attack}~\ref{5_bandwagon_attack}.

En la leyenda se puede comprobar que se han utilizado distintos algoritmos de ML. Para comparar el \textit{co-forest} con el \textit{random forest}, se han utilizado dos versiones de este mismo (etiquetadas como <<RF-A>> y <<RF-L>>). RF-A es un \textit{random forest} que ha sido entrenado con el conjunto de entrenamiento al completo (es decir, con el $100\%$ de las etiquetas disponibles). RF-L también es un \textit{random forest}, pero la diferencia reside en que, en este caso, únicamente se han utilizado un $30\%$ de las etiquetas disponibles en su entrenamiento (las mismas que se proporcionan al \textit{co-forest}). Este \textit{ensemble} permite deducir si el \textit{co-forest} (algoritmo semisupervisado) resulta verdaderamente útil en una situación de escasez de etiquetas, o si por el contrario es mejor utilizar la versión supervisada. Por último, también se ha incluído un \textit{tri-training} que utiliza como estimadores base un \textit{naive-bayes} gaussiano, un árbol de decisión y un \textit{K-neighbors}.

\begin{figure}[h]
	\caption[\textit{Random attack}: Detección.]{Gráfica que representa la detección de perfiles que utilizan \textit{random attack} en el \textit{dataset} MovieLens10M.}
	\centering
	\includegraphics[scale=0.45]{../img/memoria/5_resultados_random_attack}
	\label{5_random_attack}
\end{figure}

\begin{figure}[h]
	\caption[\textit{Average attack}: Detección.]{Gráfica que representa la detección de perfiles que utilizan \textit{average attack} en el \textit{dataset} MovieLens10M.}
	\centering
	\includegraphics[scale=0.45]{../img/memoria/5_resultados_average_attack}
	\label{5_average_attack}
\end{figure}

\begin{figure}[h]
	\caption[\textit{Bandwagon attack}: Detección.]{Gráfica que representa la detección de perfiles que utilizan \textit{bandwagon attack} en el \textit{dataset} MovieLens10M.}
	\centering
	\includegraphics[scale=0.45]{../img/memoria/5_resultados_bandwagon_attack}
	\label{5_bandwagon_attack}
\end{figure}

\subsubsection{Discusión de los resultados}

Puede parecer que los resultados son muy satisfactorios debido a que, en situaciones en las que el \textit{filler size} del atacante es mayor o igual que el $3\%$, el \textit{recall} (es decir, la cantidad de instancias positivas que se encuentran) para la mayoría de los algoritmos es muy alto y la precisión (de las instancias que se clasifican como positivas, cuántas lo son realmente) es generalmente buena (exceptuando tal vez, la del \textit{tri-training}, lo que es lógico porque también posee un \textit{recall} mayor).

Sin embargo, una de las fases del ciclo de vida del ML es el preanálisis de datos. Si se observa con detenimiento el \textit{dataset}, se puede comprobar que la media del \textit{filler size} de los usuarios genuinos es aproximadamente de un 1.34$\%$ y que únicamente un 10$\%$ de los usuarios tiene un \textit{filler size} superior al 3$\%$. Por ello y teniendo en cuenta que para cada conjunto (ya sea de entrenamiento o de \textit{test}) se selecciona aleatoriamente un 1.45\% del total los usuarios genuinos, es muy probable que esté formado por perfiles con un \textit{filler size} inferior al 3$\%$. Por lo tanto, la única <<columna>> verdaderamente significativa es la primera, y como se puede comprobar los resultados no son buenos. En otras palabras, es muy probable que el \textit{recall} sea tan bueno en la mayoría de los casos porque los perfiles inyectados tienen un número de valoraciones muy superior a los perfiles genuinos, no porque el método de extracción sea relevante y significativo.

Adicionalmente, se piensa que el método de extracción de vectores de características no es muy adecuado. El hecho de que se aplique directamente en bases de datos sin ningún tipo de ordenación implica que tiene que existir alguna relación subyacente en el orden <<por defecto>> de los datos y el comportamiento de los usuarios, lo que es una suposición que no puede extrapolarse a todos los conjuntos de datos. Si la base de datos estuviese, por ejemplo, ordenada por popularidad, sería natural que los usuarios votasen más en las primeras ventanas. Si estuviese ordenada por fechas, podría existir una relación entre la edad del usuario y las ventanas en las que vota (películas de su <<época>>). Sin embargo, al no existir ningún tipo de orden, es una hipótesis demasiado general para ser asumida. Por ello, se ha decidido cerrar esta línea de investigación.


\section{Detección de \textit{phishing}}
...

\subsection{Extracción de las URL del \textit{dataset}}

\begin{table}
	\begin{centering}
		\begin{tabular}{@{} p{10em} p{6em} p{6em}@{}}
			\toprule
			\textbf{\textit{Dataset}} &\raggedleft\textbf{Instancias} &\hfil\textbf{Categoría} \\ \midrule
			\textit{Phishtank} & \raggedleft 1\,528 &\hfil \textit{Phishing}\\
			\textit{Openphish} & \raggedleft 613 &\hfil \textit{Phishing}\\
			Alexa & \raggedleft 1\,600 &\hfil Genuino\\
			Plataforma de pago & \raggedleft 66 &\hfil Genuino\\
			Páginas de banca & \raggedleft 50 &\hfil Genuino\\
			\bottomrule
		\end{tabular}
		\caption[\textit{Phishing}: descripción del \textit{dataset}]{\textit{Dataset} de \textit{phishing}.}
		\label{tbl:dataset_phishing}	
	\end{centering}
\end{table}

Para extraer los vectores de características, en este caso, se necesita extraer el \texttt{html} de distintas páginas web (tanto verdaderas como de \textit{phishing}) mediante peticiones de código, por lo que se necesita conocer su dirección. Para garantizar el anonimato en las peticiones que se realizan a páginas de \textit{phishing}, se han utilizado \textit{proxies} con un protocolo \textit{SOCKS5}. Para levantarlos, se ha utilizado un \textit{script} de implementación propia descrito en la sección 4 de este proyecto.

Se ha intentado replicar el \textit{dataset} (procedencia y número) utilizado en el \textit{paper} de Jain y Gupta~\cite{featuresPhishing2018Gupta}, pero muchos de los enlaces facilitados no están disponibles actualmente. Por ello, se han buscado alternativas. El resultado final se muestra en la tabla~\ref{tbl:dataset_phishing}.

En el caso de \textit{Phish Tank}, la base de datos sigue disponible y es accesible en su página web~\cite{phishTankDB}. Debido a que se actualiza a diario, se recupera mediante una petición \textit{get}, aunque se ha tenido dificultades (solucionadas utilizando \textit{proxies} y los \textit{headers} adecuados) debido a que el sitio tiende a bloquear si se hacen unas pocas peticiones seguidas. También sigue accesible la base de \textit{Open Phish}~\cite{openFishDB}, aunque en este caso el número máximo de instancias obtenibles gratuitamente está limitado a 500 y se puede encontrar en un fichero en su página web~\cite{openFishFile}. Debido a que también se actualiza periódicamente, se recupera en peticiones mediante código.

Los sitios legítimos se han extraído del \textit{top} 1 millón páginas visitadas mediante Alexa, del \textit{top} de plataformas de pago disponibles y de algunos de los sitios de banca más populares. En el caso de los enlaces genuinos, ninguna de las direcciones facilitadas en el \textit{paper} original está disponible. Por ello, los sitios más consultados en Alexa se han obtenido de \textit{Expired domains}~\cite{AlexaTopWebsites}, las plataformas de pago más comunes de \textit{Shopify}~\cite{paymentGatewaysWebsites} y los sitios bancarios, al igual que en el \textit{paper} original, de \textit{Similar Web}~\cite{banksitesTop} (solo que el número está limitado a 50).

\subsection{Extracción de vectores de características}

Para caracterizar un enlace de \textit{phishing} desde el lado del cliente, es suficiente con fijarse en cinco tipos de atributos clasificados en función de lo que definen~\cite{featuresPhishing2018Gupta}: las características basadas en la URL, las basadas en la aparición del formulario de \textit{login}, las  basadas en los hiperenlaces contenidos, las basadas en el fichero \texttt{CSS} y, por último, las basadas en la identidad de la página web.


\begin{figure}[h]
	\caption[\textit{Phishing}: Anatomía de una URL.]{Ilustración que muestra la anatomía de una URL.}
	\centering
	\includegraphics[scale=1]{../img/memoria/5_url_anatomia.pdf}
	\label{img:5_url_anatomia}
\end{figure}


\subsubsection{Características basadas en la URL}
Estas son aquellas que se extraen de una URL (cuya anatomía se muestra en la ilustración~\ref{img:5_url_anatomia}) y están definidas por parámetros como la longitud, tipo de caracteres contenidos, etc. En concreto, se extraen 8 características distintas enumeradas a continuación:

\begin{itemize}
	\item \textit{\textbf{F1:}} en general, los dominios legítimos no contienen más de tres puntos en la URL~\cite{featuresPhishing2018Gupta}. Por lo tanto, esta característica se establece a 1 si el número de puntos en la URL es mayor o igual que 4.
	
	\[F1 = \left\{ \begin{array}{lr} 1, & \text{puntos en URL} \ge 4\\ 
	0, & \text{cualquier otro caso} \label{eqn:phishing_f1} \end{array} \right. \] 
	
	\item \textit{\textbf{F2:}} determina la existencia de ciertos caracteres especiales en las URL. En concreto, el uso de <<@>> (provoca que se ignore todo lo escrito anteriormente al símbolo) y <<->> (utilizado para engañar a los usuarios en enlaces como por ejemplo www.paypal-india.com)~\cite{featuresPhishing2018Gupta}.
	
	\[F2 = \left\{ \begin{array}{lr} 1, & \text{URL contiene <<@>> o <<->>}\\ 
	0, & \text{cualquier otro caso} \label{eqn:phishing_f2} \end{array} \right. \]
	
	\item \textit{\textbf{F3}}: normalmente, los dominios oficiales son cortos y significativos. Sin embargo, aquellos sitios de \textit{phishing} suelen ser más largos (con el fin de confundir al usuario u ocultar información).
	
	\[F3 = \left\{ \begin{array}{lr} 1, & \text{si la longitud de la URL} \ge 74\\ 
	0, & \text{cualquier otro caso} \label{eqn:phishing_f3} \end{array} \right. \]
	
	\item \textit{\textbf{F4}}: según~\cite{featuresPhishing2018Gupta}, es común que las páginas de \textit{phishing} añadan palabras clave en los enlaces para ganar la confianza de sus víctimas. En concreto, estas palabras son: \textit{security}, \textit{login}, \textit{signin}, \textit{bank}, \textit{account}, \textit{update}, \textit{include}, \textit{webs} y \textit{online}.
	
	\[F4 = \left\{ \begin{array}{lr} 1, & \text{si la URL contiene palabras sospechosas}\\ 
	0, & \text{cualquier otro caso} \label{eqn:phishing_f4} \end{array} \right. \]

	\item \textit{\textbf{F5}}: en los dominios legítimos, el \textit{TDL} no está presente en la parte perteneciente al dominio base, ni ocurre más de una vez en la dirección.
	
	\[F5 = \left\{ \begin{array}{lr} 1, & \text{si el TDL está presente en la zona del dominio}\\ 
	1, & \text{si hay más de un TDL en la URL} \\
	0, & \text{cualquier otro caso} \label{eqn:phishing_f5} \end{array} \right. \]
	
	
	\item \textit{\textbf{F6}}: en sitios genuinos, la cadena <<http>> sólo se encuentra una vez en la sección del protocolo. Sin embargo, puede ser que ocurra más de una vez si se trata de un sitio \textit{phishing}.
	
	\[F6 = \left\{ \begin{array}{lr} 1, & \text{si la URL contiene más de una vez la cadena <<http>>}\\ 
	0, & \text{cualquier otro caso} \label{eqn:phishing_f6} \end{array} \right. \]

	\item \textit{\textbf{F7}}: la gran mayoría de los sitios de \textit{phishing} contienen el nombre de la marca objetivo en la URL. Por ello, se han seleccionado algunos de los objetivos más comunes para los atacantes (por ejemplo, \textit{Google} o \textit{PayPal}) y, si se encuentra el nombre en una posición incorrecta, se asume que se trata de un intento de estafa.
	
	\[F7 = \left\{ \begin{array}{lr} 1, & \text{si la URL contiene el nombre de una marca famosa en la}\\ & \text{URL y la posición no es la correcta}\\ 
	0, & \text{cualquier otro caso} \label{eqn:phishing_f7} \end{array} \right. \]
	
	\item \textit{\textbf{F8}}: según~\cite{featuresPhishing2018Gupta}, los ataques basados en la existencia de un \textit{Data URI} son muy comunes. Este esquema permite insertar datos en línea dentro de un documento. El peligro reside en que esos datos pueden codificar cualquier tipo de archivo (por ejemplo, un \textit{script} de \textit{javascript}), pudiendo extraer datos o incluso realizar ataques XSS~\cite{dataUri2020neoguias}. 
	
	\[F8 = \left\{ \begin{array}{lr} 1, & \text{si la página contiene algún \textit{Data URI}}\\ 
	0, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f8} \end{array} \right. \]
	\end{itemize}

\subsubsection{Características basadas en la aparición del formulario de \textit{login}}
Esta es aquella que se basa en la aparición de un formulario de inicio de sesión.

\begin{itemize}
	\item \textit{\textbf{F9}}: es común que los sitios de \textit{phishing} incluyan formularios de inicio de sesión debido a que es una forma común de introducir datos personales. En concreto, la diferencia reside en que en los sitios legítimos el campo de acción suele contener un enlace con el mismo dominio base que el sitio inicial. Sin embargo, en los sitios de \textit{phishing} esto no es así. Hay otras variaciones como campos vacíos, con enlaces nulos o archivos PHP (por ejemplo: login.php) que almacenen las credenciales. Por lo tanto:

	\[F9 = \left\{ \begin{array}{lr} 1, & \text{si el valor del campo de acción está vacío, <<\#>> o}\\ & \text{es} \texttt{javascript:void(0)}\\ 
	1, & \text{si el valor del campo de acción posee una sintáxis} \\ &  \text{compatible con <<fichero.php>>} \\
	0, & \text{cualquier otro caso} \label{eqn:phishing_f9} \end{array} \right. \]
\end{itemize}

\subsubsection{Características basadas en los hiperenlaces contenidos}

\begin{itemize}
	\item \textit{\textbf{F10}}: normalmente, los sitios \textit{phishing} contienen menos páginas (por ejemplo, un enlace a una página de \textit{login}) que los legítimos. Estos se encuentran contenidos en el atributo <<\textit{src}>> de las etiquetas pertenecientes a imágenes, \textit{scripts}, \textit{frames}, etc., además del atributo <<\textit{href}>> de la etiqueta ancla~\cite{anclaMozilla}.
	
	\begin{equation}\label{eqn:phishing_f10} F10 = \text{enlaces presentes en el sitio web} \end{equation}
		
	\item \textit{\textbf{F11}}: por el contrario, también es muy sospechoso que una página web no contenga ningún hiperenlace debido a que se podrían estar utilizando técnicas de ocultación de sitios peligrosos para esquivar sistemas \textit{anti-phishing}~\cite{hiperlinkHidingTechniques}.

	\[F11 = \left\{ \begin{array}{lr} 1, & \text{si la página no contiene enlaces}\\ 
	0, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f11} \end{array}\right.\]
	
	\item \textit{\textbf{F12}}: debido a que los sitios atacantes suelen imitar la estética de sus objetivos, es común que posean múltiples hiperenlaces que apunten a sitios externos.

	\[F12 = \left\{ \begin{array}{lr} 1, & \text{si el ratio } \frac{\text{enlaces externos}}{\text{enlaces totales}} \text{> 0.5 y el número de enlaces > 0} \\
	0, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f12} \end{array}\right.\]


	\item \textit{\textbf{F13}}: cuando un enlace está vacío, si el usuario pulsa, es redirigido a la misma página de la que se parte (es decir, no hay redirección a un sitio distinto), lo que incrementa las posibilidades de que la víctima caiga en el ataque. Además, también se pueden utilizar otro tipo de vulnerabilidades existentes en los navegadores para aumentar la tasa de éxito. Algunos ejemplos son~\cite{featuresPhishing2018Gupta}: \texttt{<a href = “\#”>, <a href = “\#content”>} o \texttt{<a href = “javascript::void(0)”>}.

	\[F13 = \left\{ \begin{array}{lr} 1, & \text{si el ratio } \frac{\text{enlaces vacíos}}{\text{enlaces totales}} \text{> 0.34 y el número de enlaces > 0} \\
	0, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f13} \end{array}\right.\]

	\item \textit{\textbf{F14}}: se considera un enlace erróneo aquel que devuelve un código 403 o 404 cuando se pulsa en él.

	\[F14 = \left\{ \begin{array}{lr} 1, & \text{si el ratio } \frac{\text{enlaces erróneos}}{\text{enlaces totales}} \text{> 0.3 y el número de enlaces > 0} \\
	0, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f14} \end{array}\right.\]

	\item \textit{\textbf{F15}}: es común que los atacantes traten de confundir al usuario redirigiendo su solicitud a lugares externos. Una redirección se identifica gracias a su código de respuesta, que es un 301 o un 302.

	\[F15 = \left\{ \begin{array}{lr} 1, & \text{si el ratio } \frac{\text{enlaces que redirigen}}{\text{enlaces totales}} \text{> 0.3 y el número de enlaces > 0} \\
	0, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f15} \end{array}\right.\]
\end{itemize}


\subsubsection{Características basadas en el fichero \texttt{CSS}}

\begin{itemize}
	\item \textit{\textbf{F16}}: para imitar la estética de un sitio legítimo, los atacantes podrían utilizar su fichero \texttt{CSS}. Un \texttt{CSS} es una hoja de estilos que define el aspecto visual de una página web, y puede estar incrustado en el propio HTML de la página o ser un fichero externo~\cite{cssExternos}. En el caso de ser único y externo, se entiende que puede tratarse de un intento de estafa.

	\[F16 = \left\{ \begin{array}{lr} 1, & \text{si existe un fichero \texttt{CSS} y es externo}\\
	0, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f16} \end{array}\right.\]
\end{itemize}


\subsubsection{Características basadas en la identidad de la página web}

\begin{itemize}
	\item \textit{\textbf{F17}}: las páginas legítimas suelen contener el nombre del dominio en la sección dedicada a \textit{copyright} (que se ubica por encontrarse a continuación de los símbolos <<@>>, <<©>>, o de las frases \textit{\& copy}, \textit{copyright} o \textit{all right reserved}).

	\[F17 = \left\{ \begin{array}{lr} 0, & \text{si las palabras del \textit{copyright} están en el dominio base}\\
	1, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f17} \end{array}\right.\]
	
	\item \textit{\textbf{F18}}: para cada página web, se ha construido un conjunto de \textit{keywords} compuesto por las palabras contenidas en el título, en las etiquetas \textit{meta} (cuyo campo \textit{name} equivalga a \textit{description} o \textit{keywords}) y por las más relevantes del cuerpo del sitio (extraídas mediante el algoritmo TF-IDF~\cite{cantinatfidf}). Lo más común es que los sitios legítimos contengan al menos una de estas palabras en el dominio base. En caso contrario, se considera un intento de \textit{phishing}.
	
	\[F18 = \left\{ \begin{array}{lr} 0, & \text{si una \textit{keyword} coincide con el dominio base}\\
	1, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f18} \end{array}\right.\]
	
	\item \textit{\textbf{F19}}: un \textit{favicon} es una miniatura asociada a una página web. Por ello, los atacantes pueden plagiar los iconos de los sitios legítimos para ganarse la confianza de los usuarios. De este modo, se considera intento de estafa cualquier icono que contenga un enlace externo. Para localizarlos, se ubica el atributo <<\textit{rel}>> dentro de las etiquetas <<\textit{link}>> y se comprueba que su valor sea la cadena \textit{shortcut icon} o \textit{icon}  (por ejemplo: \texttt{<link type='image/png' href='<<enlace>>' rel='shortcut icon'>}).
	
	\[F19 = \left\{ \begin{array}{lr} 1, & \text{si se encuentra un dominio externo en el \textit{favicon}}\\
	0, & \text{\raggedright cualquier otro caso} \label{eqn:phishing_f19} \end{array}\right.\]
\end{itemize}




