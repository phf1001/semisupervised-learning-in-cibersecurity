{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **üêç CO-FOREST PYTONIZADO** \n",
    "\n",
    "##### **Autora: Patricia Hernando Fern√°ndez**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Co_Forest:\n",
    "\n",
    "    def __init__(self, L, y, U, n, sigma, classes, max_features='sqrt'):\n",
    "        \"\"\"\n",
    "        L, U, y: numpy array\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n\n",
    "        self.sigma = sigma\n",
    "        self.classes = classes\n",
    "\n",
    "        self.L = L\n",
    "        self.y = y\n",
    "        self.U = U\n",
    "        self.U_pseudo_tags = ( np.ones(shape=((self.U.shape[0]), self.n)) * -1 )\n",
    "\n",
    "        self.mask_L = np.zeros(shape=((self.L.shape[0]), self.n), dtype=int, order='C') \n",
    "        self.mask_U = np.zeros(shape=((self.U.shape[0]), self.n), dtype=int, order='C') \n",
    "\n",
    "        self.ensemble = self.create_trees(max_features) \n",
    "\n",
    "        #self.fit()\n",
    "\n",
    "\n",
    "    def create_trees(self, max_features) -> dict:\n",
    "        \"\"\"Generates a dict -> {key: int, value: Tree}\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_features: number of features to consider \n",
    "                      when looking for the best split\n",
    "                      'sqrt', 'log2', None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            dict containing the trees of co-forest\n",
    "        \"\"\"\n",
    "\n",
    "        ensemble = {}\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            rand_rows = np.random.choice(a = np.arange(start=0, stop=self.L.shape[0]), replace = True, size=(int(0.5*self.L.shape[0])) )\n",
    "            self.mask_L[rand_rows, i] = 1\n",
    "            h = DecisionTreeClassifier(max_features=max_features, random_state=1)\n",
    "            ensemble[i] = h.fit(self.L[rand_rows, :], self.y[rand_rows])\n",
    "\n",
    "        return ensemble\n",
    "\n",
    "\n",
    "    def get_rows_training(self, i, both = True):\n",
    "        \"\"\"\"\n",
    "        Devuelve las filas modo vector, NO n√∫meros\n",
    "        \"\"\"\n",
    "        if both:\n",
    "            return np.concatenate( (self.L[self.mask_L[:, i] == 1], self.U[self.mask_U[:, i] == 1]) )\n",
    "        else:\n",
    "            return self.L[self.mask_L[:, i] == 1]\n",
    "\n",
    "\n",
    "    def get_tags_training(self, i, both = True):\n",
    "\n",
    "        if both:\n",
    "            U_tags_i = self.U_pseudo_tags[:, i]\n",
    "            return np.concatenate( (self.y[self.mask_L[:, i] == 1], U_tags_i[self.mask_U[:, i] == 1]) )\n",
    "        \n",
    "        else:\n",
    "            return self.y[self.mask_L[:, i] == 1]\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \n",
    "        e_anterior = [0.5 for i in range(self.n)]\n",
    "        W_anterior = [min(0.1*len(self.L), 100) for i in range(self.n)]\n",
    "\n",
    "        t = W = 0\n",
    "        new_data = True\n",
    "        \n",
    "        while new_data:\n",
    "\n",
    "            t += 1\n",
    "            tree_changes = [False for i in range(self.n)]\n",
    "\n",
    "            for i, hi in self.ensemble.items():\n",
    "\n",
    "                e = self.calculate_e(hi)\n",
    "\n",
    "                if e < e_anterior[i]:\n",
    "\n",
    "                    (lambda x: 0.000001 if x <= 0 else x)(e)\n",
    "                    U_subsampled = self.subsample(hi, ((e_anterior[i]*W_anterior[i])/e) )\n",
    "                    W = 0\n",
    "\n",
    "                    for u in U_subsampled:\n",
    "                        confidence, selected_class = self.confidence(hi, self.U[u, :])\n",
    "\n",
    "                        if confidence > self.sigma:\n",
    "                            tree_changes[i] = True\n",
    "                            self.mask_U[u, i] = 1\n",
    "                            self.U_pseudo_tags[u, i] = selected_class\n",
    "                            W += confidence\n",
    "\n",
    "                e_anterior[i] = e\n",
    "                W_anterior[i] = W\n",
    "\n",
    "            new_data = self.retrain_ensemble(np.array(tree_changes))\n",
    "\n",
    "\n",
    "    def retrain_ensemble(self, tree_changes: np.array) -> bool:\n",
    "        \"\"\"Retrains from scratch those trees that have \n",
    "        received new data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tree_changes : boolean numpy array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            True if one or more trees have chanded, False if not.\n",
    "        \"\"\"\n",
    "\n",
    "        if tree_changes.sum() == 0:\n",
    "            return False\n",
    "\n",
    "        for i in np.fromiter(self.ensemble.keys(), dtype=int)[tree_changes]:\n",
    "            self.ensemble[i] = self.ensemble[i].fit(self.get_rows_training(i), self.get_tags_training(i))\n",
    "        \n",
    "        return True\n",
    "        \n",
    "\n",
    "\n",
    "    def subsample(self, hi: DecisionTreeClassifier, Wmax: float) -> np.array:\n",
    "        \"\"\"Samples from U uniformly at random until \n",
    "        the sum of the sample weights reaches Wmax.\n",
    "        Bootstraping is applied.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hi : DecisionTreeClassifier\n",
    "        Wmax: float\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Array containing the index of the chosen\n",
    "            samples from U\n",
    "        \"\"\"\n",
    "\n",
    "        W = 0\n",
    "        U_subsampled = []\n",
    "\n",
    "        while (W < Wmax):\n",
    "\n",
    "            rand_row = np.random.choice(a = np.arange(start=0, stop=self.U.shape[0]))\n",
    "            W += self.confidence(hi, self.U[rand_row, :])[0]\n",
    "            U_subsampled.append(rand_row)\n",
    "\n",
    "        return np.array(U_subsampled)\n",
    "\n",
    "        \n",
    "    def calculate_e(self, hi: DecisionTreeClassifier) -> float:\n",
    "        \"\"\"Calculates the Out of Bag Error of the concomitant \n",
    "        ensemble of hi for the whole labeled data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hi : DecisionTreeClassifier\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            OOBE\n",
    "        \"\"\"\n",
    "\n",
    "        error_sum = total_samples_voted = 0\n",
    "\n",
    "        for sample, tag in zip(self.L, self.y):\n",
    "            \n",
    "            n_votes = n_hits = 0 \n",
    "\n",
    "            for prediction in (tree.predict([sample])[0] for i, tree in self.ensemble.items() if tree != hi and sample not in self.get_rows_training(i, both = False)):\n",
    "\n",
    "                if prediction == tag:\n",
    "                    n_hits += 1\n",
    "                n_votes +=1\n",
    "\n",
    "            if (n_votes > 0):\n",
    "                error_sum += 1 - (n_hits/n_votes)\n",
    "                total_samples_voted += 1\n",
    "\n",
    "        if total_samples_voted > 0:\n",
    "            return error_sum/total_samples_voted\n",
    "\n",
    "        return 1 #No data was voted (Raise Exception instead)\n",
    "\n",
    "\n",
    "    def confidence(self, hi: DecisionTreeClassifier, sample: np.array) -> tuple:\n",
    "        \"\"\"Calculates the number of coincidences during\n",
    "        prediction of the hi concomitant ensemble for a\n",
    "        data sample.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hi : DecisionTreeClassifier\n",
    "        sample: sample's features array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple (float, int)\n",
    "            float: confidence for the sample\n",
    "            int: most agreed class\n",
    "        \"\"\"\n",
    "\n",
    "        count = { **dict.fromkeys([i for i in self.classes], 0)} \n",
    "        for i in (tree.predict([sample])[0] for tree in self.ensemble.values() if tree != hi):\n",
    "            count[i]+= 1\n",
    "\n",
    "        max_agreement = max(count.values())\n",
    "        most_agreed_class = list(count.values()).index(max_agreement)\n",
    "        return max_agreement/(len(self.ensemble) -1), most_agreed_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "total_data = np.array(iris.data)\n",
    "total_tags = np.array(iris.target)\n",
    "\n",
    "n_class_types = len(iris.target_names)\n",
    "\n",
    "L, U, L_tags, U_tags = train_test_split(total_data, total_tags, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coforest = Co_Forest(L, L_tags, U, 5, 0.75, [0,1,2])\n",
    "coforest.subsample(coforest.ensemble[0], 50)\n",
    "coforest.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = np.array([\n",
    "#     [1, 1, 1, 2],\n",
    "#     [2, 2, 2, 2],\n",
    "#     [3, 3, 3, 3],\n",
    "#     [4, 4, 4, 4],\n",
    "#     [5, 5, 5, 5],\n",
    "#     [6, 6, 6, 6]\n",
    "# ])\n",
    "\n",
    "# y = np.array([1,2,3,4,5,6])\n",
    "\n",
    "# U = np.array([\n",
    "#     [7, 7, 7, 7],\n",
    "#     [8, 8, 8, 8],\n",
    "#     [9, 9, 9,9]\n",
    "# ])\n",
    "\n",
    "# coforest = Co_Forest(L, y, U, 5, 0.75, [1,2,3,4,5,6])\n",
    "# coforest.subsample(coforest.ensemble[0], 50)\n",
    "# coforest.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
