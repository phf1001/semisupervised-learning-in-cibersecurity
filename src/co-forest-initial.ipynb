{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå≥ **CO-FOREST** üå≥\n",
    "\n",
    "##### **Autora: Patricia Hernando Fern√°ndez**\n",
    "\n",
    "\n",
    "**‚úçüèΩ TO-DO:**\n",
    "\n",
    "- Revisar si dataframes, arrays... mejorar estructuras (definici√≥n)\n",
    "- Complejidades. Intentar hashear las listas y usar conjuntos para hacer comprobaciones en O(1)\n",
    "- Espacio, ocupa mucho\n",
    "- Cambiar todos los samples en los √°rboles por bootstrap (falta)\n",
    "- Documentar\n",
    "- Hacer m√°s tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Co_Forest:\n",
    "\n",
    "    def __init__(self, DL, U, n, sigma, n_class_types):\n",
    "        \"\"\"\n",
    "        objetos de pandas, tanto L, como L_tags, como U\n",
    "        DL -> Tupla (L, L_tags)\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n\n",
    "        self.sigma = sigma\n",
    "        self.n_class_types = n_class_types\n",
    "\n",
    "        self.ensemble = self.create_trees(DL) \n",
    "        self.fit(DL, U)\n",
    "\n",
    "\n",
    "    def create_trees(self, DL):\n",
    "        # keys: id, values: (tree, L ignored during training)\n",
    "        ensemble = {}\n",
    "        L, L_tags = DL\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            #cambiar valores tama√±o a entrenar (est√° forzado para entrenar con pocos y que salte el error)\n",
    "            X_train_h, X_ignore_h, y_train_h, y_ignore_h = train_test_split(L, L_tags, test_size=random.uniform(0.30, 0.50)) #CAMBIAR POR BOOTSTRAP\n",
    "            h = DecisionTreeClassifier()\n",
    "            h.fit(X_train_h.values, y_train_h.values)\n",
    "\n",
    "            ensemble[i] = (h, X_ignore_h.values) #Cambiar X ignore a tuplas y hacer conjunto? hasheable para O(1)...\n",
    "\n",
    "        return ensemble\n",
    "\n",
    "\n",
    "    def fit(self, DL, U):\n",
    "\n",
    "        # x = U.sample().values[0]\n",
    "        # print(\"Error (todo L para los no entrenados con esos L): {}; Confidence (en una muestra de U): {}\".format(self.calculate_e(hi, DL), self.confidence(hi, x, self.n_class_types)))\n",
    "        \n",
    "        L = DL[0]\n",
    "        e_anterior = []\n",
    "        W_anterior = []\n",
    "        DLP_i_t = []\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            e_anterior.append(0.5)\n",
    "            W_anterior.append(min(0.1*len(L), 100))\n",
    "            DLP_i_t.append(([], []))\n",
    "\n",
    "        t = 0\n",
    "        new_data = True\n",
    "        \n",
    "        while new_data:\n",
    "\n",
    "            t += 1\n",
    "\n",
    "            for i in range(self.n):\n",
    "\n",
    "                hi = self.ensemble[i][0]\n",
    "                e = self.calculate_e(hi, DL)\n",
    "                LP = []\n",
    "                LP_tags = [] #Ojo con los sets porque se desordenan (en python??)\n",
    "\n",
    "                if e < e_anterior[i]:\n",
    "\n",
    "                    #Si tienes un error de 0?!\n",
    "                    if e <= 0:\n",
    "                        e = 0.0000001\n",
    "\n",
    "                    UP = self.subsample(U.values, hi, ((e_anterior[i]*W_anterior[i])/e))\n",
    "                    W = 0\n",
    "\n",
    "                    for x in UP:\n",
    "                        confidence, selected_class = self.confidence(hi, x)\n",
    "\n",
    "                        if confidence > self.sigma:\n",
    "                            LP.append(x)\n",
    "                            LP_tags.append(selected_class)\n",
    "                            W += confidence\n",
    "\n",
    "                DLP_i_t[i] = ((LP, LP_tags)) #a√±ade aunque vac√≠o\n",
    "                e_anterior[i] = e\n",
    "                W_anterior[i] = W\n",
    "\n",
    "            #Abajo\n",
    "            changed_t = False\n",
    "\n",
    "            for i in range(self.n):\n",
    "\n",
    "                if len(DLP_i_t[i][0]) > 0:\n",
    "                    changed_t = True\n",
    "                    self.retrain_tree(i, DL, DLP_i_t[i])\n",
    "\n",
    "            if not changed_t:\n",
    "                new_data = False\n",
    "\n",
    "    def retrain_tree(self, i, DL, DLP):\n",
    "        \n",
    "        hi = self.ensemble[i][0]\n",
    "        X_ignored = self.ensemble[i][1]\n",
    "\n",
    "        L = DL[0].values\n",
    "        L_tags = DL[1].values\n",
    "\n",
    "        LP, LP_tags = DLP\n",
    "\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "\n",
    "        for i in range(len(L)):\n",
    "\n",
    "            if L[i] not in X_ignored:\n",
    "                X_train.append(L[i])\n",
    "                y_train.append(L_tags[i])\n",
    "\n",
    "        for i in range(len(LP)):\n",
    "            X_train.append(LP[i])\n",
    "            y_train.append(LP_tags[i])\n",
    "\n",
    "        hi.fit(X_train, y_train)\n",
    "\n",
    "        self.ensemble[i] = (hi, X_ignored)\n",
    "\n",
    "\n",
    "    def subsample(self, U, hi, Wmax):\n",
    "        # U‚Ä≤ is then determined by sampling from U uniformly at random until the sum of\n",
    "        # the sample weights reaches Wmax.\n",
    "\n",
    "        W_U = 0\n",
    "        UP = []\n",
    "        U_left = []\n",
    "\n",
    "        for x in U:\n",
    "            U_left.append(x)\n",
    "\n",
    "        while (W_U < Wmax and len(U_left) > 0): #Cambiar por lectura adelantada\n",
    "\n",
    "            i = random.randint(0, len(U_left)-1)\n",
    "            x = U_left[i]\n",
    "\n",
    "            confidence, selected_class = self.confidence(hi, x)\n",
    "\n",
    "            W_U += confidence\n",
    "            UP.append(x)\n",
    "\n",
    "            U_left.pop(i)\n",
    "\n",
    "        return UP\n",
    "\n",
    "        \n",
    "    def calculate_e(self, hi, DL):\n",
    "\n",
    "        sum_errores = total_dl_voted = 0\n",
    "        DL_zip = zip(DL[0].values, DL[1].values) #Tuplas ([array features], int clase)\n",
    "\n",
    "        for d in DL_zip:\n",
    "\n",
    "            x, tag = d\n",
    "            n_votes = n_hits = 0 \n",
    "\n",
    "            for key, value in self.ensemble.items():\n",
    "                tree, ignored = value\n",
    "\n",
    "                if tree != hi and x in ignored:\n",
    "\n",
    "                    pred = hi.predict([x])[0]\n",
    "\n",
    "                    if pred == tag:\n",
    "                        n_hits += 1\n",
    "                    n_votes +=1\n",
    "\n",
    "            if (n_votes > 0):\n",
    "                ex = 1 - (n_hits/n_votes)\n",
    "                sum_errores += ex\n",
    "                total_dl_voted += 1\n",
    "\n",
    "        if total_dl_voted > 0:\n",
    "            return sum_errores/total_dl_voted\n",
    "\n",
    "        else:\n",
    "            return 1 #No se ha votado, se repite -> CAMBIAR POR EXCEPCI√ìN\n",
    "\n",
    "\n",
    "    def confidence(self, hi, x):\n",
    "\n",
    "        count = {}\n",
    "\n",
    "        for i in range(self.n_class_types):\n",
    "            count[i] = 0\n",
    "\n",
    "        for key, value in self.ensemble.items():\n",
    "            tree, ignored = value\n",
    "\n",
    "            if tree != hi:\n",
    "                prediction = tree.predict([x])[0]\n",
    "                count[prediction] += 1\n",
    "\n",
    "        #max_agreement = max(count.values())\n",
    "\n",
    "        max_agreement = most_agreed_class = -1\n",
    "\n",
    "        for key, value in count.items():\n",
    "            if value > max_agreement:\n",
    "                most_agreed_class = key\n",
    "                max_agreement = value\n",
    "\n",
    "        confidence = max_agreement/(len(self.ensemble) -1)\n",
    "\n",
    "        return confidence, most_agreed_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "data=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "\n",
    "#data.head()\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']] \n",
    "y=data['species']\n",
    "n_class_types = len(iris.target_names)\n",
    "\n",
    "#X_train, X_test, y_train, y_test\n",
    "L, U, L_tags, U_tags = train_test_split(X, y, test_size=0.2)\n",
    "DL = (L, L_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "coforest = Co_Forest(DL, U, 5, 0.75, n_class_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
