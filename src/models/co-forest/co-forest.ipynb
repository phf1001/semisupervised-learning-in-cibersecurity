{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ² **CO-FOREST** \n",
    "\n",
    "##### **Autora: Patricia Hernando FernÃ¡ndez**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Co_Forest:\n",
    "\n",
    "\n",
    "    def __init__(self, L, y, U, n, theta, classes, random_state=None, max_features='log2'):\n",
    "        \"\"\"\"\n",
    "        Constructor. Creates and trains the Co-Forest.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            labeled data used for training\n",
    "        y: np.array\n",
    "            tags of the labeled data used for training\n",
    "        U: np.array\n",
    "            unlabeled data used for training\n",
    "        n: int\n",
    "            number of trees in the ensemble\n",
    "        theta: float\n",
    "            tolerance\n",
    "        random_state:\n",
    "            random object to create deterministic experiments\n",
    "        max_features: string\n",
    "            log2, sqrt, None\n",
    "        \"\"\"\n",
    "\n",
    "        self.random_state = self.check_random_state(random_state)\n",
    "        self.n = n\n",
    "        self.theta = theta\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        self.U = U\n",
    "        self.L = L\n",
    "        self.y = y\n",
    "        self.mask_L = np.zeros(shape=((self.L.shape[0]), self.n), dtype=int, order='C')\n",
    "\n",
    "        self.ensemble = self.create_trees(max_features)\n",
    "        \n",
    "\n",
    "    def create_trees(self, max_features) -> dict:\n",
    "        \"\"\"Generates a dict containing co-forest's trees.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_features: number of features to consider \n",
    "                      when looking for the best split\n",
    "                      'sqrt', 'log2', None\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            {key: int, value: Tree}\n",
    "        \"\"\"\n",
    "\n",
    "        ensemble = {}\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            rand_rows = self.random_state.choice(a = np.arange(start=0, stop=self.L.shape[0]), replace = True, size=(int(0.7*self.L.shape[0])) )\n",
    "            self.mask_L[rand_rows, i] = 1\n",
    "            h = DecisionTreeClassifier(max_features=max_features, random_state=self.random_state)\n",
    "            ensemble[i] = h.fit(self.L[rand_rows, :], self.y[rand_rows])\n",
    "\n",
    "        return ensemble\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fits the ensemble using both labeled and\n",
    "        pseudo-labeled data.\n",
    "        \"\"\"\n",
    "\n",
    "        e = [0 for i in range(self.n)]\n",
    "        W = [0 for i in range(self.n)]\n",
    "        previous_e = [0.5 for i in range(self.n)]\n",
    "        previous_W = [min(0.1*len(self.L), 100) for i in range(self.n)]\n",
    "\n",
    "        new_data = True\n",
    "        t = 0\n",
    "\n",
    "        while new_data:\n",
    "\n",
    "            t += 1\n",
    "            tree_changes = np.array([False for i in range(self.n)])\n",
    "            tree_pseudo_updates = [() for i in range(self.n)]\n",
    "\n",
    "            for i, hi in self.ensemble.items():\n",
    "\n",
    "                e[i] = self.concomitant_oob_error(hi)\n",
    "                W[i] = previous_W[i]\n",
    "                pseudo_labeled_data = []\n",
    "                pseudo_labeled_tags = []\n",
    "\n",
    "                if e[i] < previous_e[i]:\n",
    "\n",
    "                    if e[i] == 0:\n",
    "                        Wmax = self.theta * self.U.shape[0]\n",
    "                    else:\n",
    "                        Wmax = min(self.theta * self.U.shape[0], ((previous_e[i]*previous_W[i])/e[i]) )\n",
    "\n",
    "                    U_subsampled = self.subsample(hi, Wmax) \n",
    "                    W[i] = 0\n",
    "\n",
    "                    for u in U_subsampled:\n",
    "                        concomitant_confidence, selected_class = self.concomitant_confidence(hi, self.U[u, :])\n",
    "\n",
    "                        if concomitant_confidence > self.theta:\n",
    "                            tree_changes[i] = True\n",
    "                            pseudo_labeled_data.append(self.U[u, :])\n",
    "                            pseudo_labeled_tags.append(selected_class)\n",
    "                            W[i] += concomitant_confidence\n",
    "\n",
    "                tree_pseudo_updates[i] = ( (np.array(pseudo_labeled_data), np.array(pseudo_labeled_tags) ) )\n",
    "\n",
    "            for i in np.fromiter(self.ensemble.keys(), dtype=int)[tree_changes]:\n",
    "                if e[i] * W[i] < previous_e[i] * previous_W[i]:\n",
    "                    self.retrain_tree(i, tree_pseudo_updates[i][0], tree_pseudo_updates[i][1])\n",
    "\n",
    "            previous_e = deepcopy(e)\n",
    "            previous_W = deepcopy(W)\n",
    "\n",
    "            if tree_changes.sum() == 0:\n",
    "                new_data = False\n",
    "        \n",
    "        \n",
    "    def retrain_tree(self, i, pseudo_labeled_data, pseudo_labeled_tags):\n",
    "        \"\"\"\n",
    "        Retrains a tree given new pseudo-labeled data.\n",
    "        \"\"\"\n",
    "\n",
    "        pseudo_labeled_data = (lambda x: np.expand_dims(x, axis=0) if x.ndim == 1 else x)(pseudo_labeled_data)\n",
    "        X_train = np.concatenate( (self.L[self.mask_L[:, i] == 1], pseudo_labeled_data) )\n",
    "        y_train = np.concatenate( (self.y[self.mask_L[:, i] == 1], pseudo_labeled_tags) )\n",
    "        self.ensemble[i] = self.ensemble[i].fit(X_train, y_train)\n",
    "\n",
    "        \n",
    "    def subsample(self, hi: DecisionTreeClassifier, Wmax: float) -> np.array:\n",
    "        \"\"\"Samples from U uniformly at random until \n",
    "        the sum of the sample weights reaches Wmax.\n",
    "        Bootstraping is applied.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hi : DecisionTreeClassifier\n",
    "        Wmax: float\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Array containing the index of the chosen\n",
    "            samples from U\n",
    "        \"\"\"\n",
    "\n",
    "        W = 0\n",
    "        U_subsampled = []\n",
    "\n",
    "        while (W < Wmax):\n",
    "\n",
    "            rand_row = self.random_state.choice(a = np.arange(start=0, stop=self.U.shape[0]))\n",
    "            W += self.concomitant_confidence(hi, self.U[rand_row, :])[0]\n",
    "            U_subsampled.append(rand_row)\n",
    "\n",
    "        return np.array(U_subsampled)\n",
    "\n",
    "        \n",
    "    def concomitant_oob_error(self, hi: DecisionTreeClassifier) -> float:\n",
    "        \"\"\"Calculates the Out of Bag Error of the concomitant \n",
    "        ensemble of hi for the whole labeled data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hi : DecisionTreeClassifier\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            OOBE if trees voted, nan if not\n",
    "        \"\"\"\n",
    "\n",
    "        errors = []\n",
    "\n",
    "        for sample, tag in zip(self.L, self.y):\n",
    "            n_votes = n_hits = 0 \n",
    "\n",
    "            for i, tree in self.ensemble.items():\n",
    "\n",
    "                rows_training = self.L[self.mask_L[:, i] == 1]\n",
    "                used_training = np.any(np.all(sample == rows_training, axis=1))\n",
    "\n",
    "                if tree is not hi and not used_training:\n",
    "                    if tree.predict([sample])[0] == tag:\n",
    "                        n_hits += 1\n",
    "                    n_votes +=1\n",
    "\n",
    "            if (n_votes > 0):\n",
    "                errors.append(1 - (n_hits/n_votes))\n",
    "\n",
    "        return np.mean(a=errors)\n",
    "\n",
    "    def concomitant_confidence(self, hi: DecisionTreeClassifier, sample: np.array) -> tuple:\n",
    "        \"\"\"Calculates the number of coincidences during\n",
    "        prediction of the hi concomitant ensemble for a\n",
    "        data sample.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        hi : DecisionTreeClassifier\n",
    "        sample: sample's features array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple (float, int)\n",
    "            float: confidence for the sample\n",
    "            int: most agreed class\n",
    "        \"\"\"\n",
    "\n",
    "        count = { **dict.fromkeys([i for i in self.classes], 0)} \n",
    "\n",
    "        for tree in self.ensemble.values():\n",
    "            if tree is not hi:\n",
    "                count[tree.predict([sample])[0]] += 1\n",
    "\n",
    "        max_agreement = max(count.values())\n",
    "        most_agreed_class = list(count.keys())[list(count.values()).index(max_agreement)]\n",
    "\n",
    "        return max_agreement/(len(self.ensemble) -1), most_agreed_class\n",
    "\n",
    "\n",
    "    def single_predict(self, sample: np.array): \n",
    "        \"\"\"Returns the class predicted by coforest\n",
    "        for a given sample. Majority voting is used.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample: np_array\n",
    "            sample to predict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array:\n",
    "            label predicted by coforest.\n",
    "        \"\"\"\n",
    "\n",
    "        count = { **dict.fromkeys([i for i in self.classes], 0)} \n",
    "        for i in (tree.predict([sample])[0] for tree in self.ensemble.values()):\n",
    "                count[i]+= 1\n",
    "\n",
    "        max_agreement = max(count.values())\n",
    "        return list(count.keys())[list(count.values()).index(max_agreement)]\n",
    "\n",
    "\n",
    "    def predict(self, samples: np.array) -> np.array:\n",
    "        \"\"\"Returns the labels predicted by the coforest\n",
    "        for a given data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        samples: np_array\n",
    "            samples to predict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array:\n",
    "            labels predicted by the coforest.\n",
    "        \"\"\"\n",
    "        \n",
    "        samples = (lambda x: np.expand_dims(x, axis=0) if x.ndim == 1 else x)(samples)\n",
    "        return np.array([self.single_predict(sample) for sample in samples])\n",
    "\n",
    "\n",
    "    def score(self, X_test: np.array, y_test: np.array) -> float:\n",
    "        \"\"\"Calculates the number of hits by coforest\n",
    "        given a training set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_test: np_array\n",
    "            Samples used during testing\n",
    "        y_test: np_array\n",
    "            Samples' tags\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float:\n",
    "            percentage of hits.\n",
    "        \"\"\"\n",
    "        y_predictions = self.predict(X_test)\n",
    "        return np.count_nonzero(y_predictions==y_test)/len(y_test)\n",
    "\n",
    "    def check_random_state(self, seed):\n",
    "        \"\"\"\n",
    "        Source: SkLearn\n",
    "        Turn seed into a np.random.RandomState instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : None, int or instance of RandomState\n",
    "            If seed is None, return the RandomState singleton used by np.random.\n",
    "            If seed is an int, return a new RandomState instance seeded with seed.\n",
    "            If seed is already a RandomState instance, return it.\n",
    "            Otherwise raise ValueError.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        :class:`numpy:numpy.random.RandomState`\n",
    "            The random state object based on `seed` parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        if seed is None or seed is np.random:\n",
    "            return np.random.mtrand._rand\n",
    "\n",
    "        if isinstance(seed, numbers.Integral):\n",
    "            return np.random.RandomState(seed)\n",
    "\n",
    "        if isinstance(seed, np.random.RandomState):\n",
    "            return seed\n",
    "            \n",
    "        raise ValueError(\"%r cannot be used to seed a numpy.random.RandomState instance\" % seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
