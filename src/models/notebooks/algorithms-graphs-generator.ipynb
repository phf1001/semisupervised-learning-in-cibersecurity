{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ **GRAPHS ALGORITHMS GENERATOR** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from math import floor, ceil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#Fallaba por la barra al final\n",
    "src_path = Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.parent\n",
    "sys.path.append(str(src_path)  + os.sep)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append( (src_path + os.sep) )\n",
    "\n",
    "from models.classifiers.CoForestClassifier import CoForest\n",
    "from models.classifiers.TriTrainingClassifier import TriTraining\n",
    "from models.classifiers.DemocraticCoClassifier import DemocraticCo\n",
    "from models.classifiers.utils import *\n",
    "from models.notebooks.graphs_utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **CLASSES**\n",
    "\n",
    "Fit methods needs to be overwritten since graphs are generated while training, so inheritance is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoForest_graphs(CoForest):\n",
    "\n",
    "    def fit(self, L, y, U, X_test, y_test, w_init_criteria='percentage_L', file_name=\"file.csv\"):\n",
    "        \"\"\"\n",
    "        Fits the ensemble using both labeled and\n",
    "        pseudo-labeled data. Generates graphs to show \n",
    "        how score evolves during training.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Tags of the labeled data used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "\n",
    "        mask_L = self.create_trees(L, y)\n",
    "        scores = [self.score(X_test, y_test)]\n",
    "\n",
    "        e = [0 for i in range(self.n)]\n",
    "        W = [0 for i in range(self.n)]\n",
    "\n",
    "        previous_e = [0.5 for i in range(self.n)]\n",
    "        previous_W = previous_W = self.initialize_previous_W(L, w_init_criteria)\n",
    "        print(\"Method: {}. Previous W: {}\".format(w_init_criteria, [ '%.2f' % elem for elem in previous_W ]))\n",
    "        \n",
    "        new_data = True\n",
    "        t = 0\n",
    "\n",
    "        while new_data:\n",
    "\n",
    "            t += 1\n",
    "            tree_changes = np.array([False for i in range(self.n)])\n",
    "            tree_pseudo_updates = [() for i in range(self.n)]\n",
    "\n",
    "            for i, hi in self.ensemble.items():\n",
    "\n",
    "                e[i] = self.concomitant_oob_error(hi, L, y, mask_L)\n",
    "                W[i] = previous_W[i]\n",
    "                pseudo_labeled_data = []\n",
    "                pseudo_labeled_tags = []\n",
    "\n",
    "                if e[i] < previous_e[i]:\n",
    "\n",
    "                    if e[i] == 0:\n",
    "                        Wmax = self.theta * U.shape[0]\n",
    "                    else:\n",
    "                        Wmax = min(\n",
    "                            self.theta * U.shape[0], ((previous_e[i]*previous_W[i])/e[i]))\n",
    "\n",
    "                    U_subsampled = self.subsample(hi, U, Wmax)\n",
    "                    W[i] = 0\n",
    "\n",
    "                    for u in U_subsampled:\n",
    "                        concomitant_confidence, selected_class = self.concomitant_confidence(\n",
    "                            hi, U[u, :])\n",
    "\n",
    "                        if concomitant_confidence > self.theta:\n",
    "                            tree_changes[i] = True\n",
    "                            pseudo_labeled_data.append(U[u, :])\n",
    "                            pseudo_labeled_tags.append(selected_class)\n",
    "                            W[i] += concomitant_confidence\n",
    "\n",
    "                tree_pseudo_updates[i] = (\n",
    "                    (np.array(pseudo_labeled_data), np.array(pseudo_labeled_tags)))\n",
    "\n",
    "            for i in np.fromiter(self.ensemble.keys(), dtype=int)[tree_changes]:\n",
    "                if e[i] * W[i] < previous_e[i] * previous_W[i]:\n",
    "                    self.retrain_tree(\n",
    "                        i, L, y, tree_pseudo_updates[i][0], tree_pseudo_updates[i][1], mask_L)\n",
    "\n",
    "            previous_e = deepcopy(e)\n",
    "            previous_W = deepcopy(W)\n",
    "\n",
    "            if tree_changes.sum() == 0:\n",
    "                new_data = False\n",
    "\n",
    "            scores.append(self.score(X_test, y_test))\n",
    "\n",
    "        append_to_csv(file_name, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTraining_graphs(TriTraining):\n",
    "\n",
    "    def fit(self, L, y, U, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Trains the tri-training ensemble using Zhi-Hua Zhou\n",
    "        Algorithm. Generates graphs to show how score\n",
    "        evolves during training.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Labeled data tags used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "\n",
    "        self.initialize_classifiers(L, y)\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        previous_e = [0.5 for i in range(self.n)]\n",
    "        previous_l = [0.0 for i in range(self.n)]\n",
    "        e = [0.0 for i in range(self.n)]\n",
    "        new_data = True\n",
    "\n",
    "        t = 0\n",
    "        scores = [self.score(X_test, y_test)]\n",
    "\n",
    "        while new_data:\n",
    "\n",
    "            t += 1\n",
    "            cls_changes = np.array([False for i in range(self.n)])\n",
    "            cls_pseudo_updates = [() for i in range(self.n)]\n",
    "\n",
    "            for i in range(self.n):\n",
    "\n",
    "                e[i] = self.measure_error(i, L, y)\n",
    "\n",
    "                if e[i] < previous_e[i]:\n",
    "                    cls_pseudo_updates[i] = self.create_pseudolabeled_set(i, U)\n",
    "\n",
    "                    if previous_l[i] == 0:\n",
    "                        previous_l[i] = floor(\n",
    "                            (e[i] / (previous_e[i]-e[i])) + 1)\n",
    "\n",
    "                    L_i_size = cls_pseudo_updates[i][0].shape[0]\n",
    "\n",
    "                    if previous_l[i] < L_i_size:\n",
    "\n",
    "                        if e[i] * L_i_size < previous_e[i] * previous_l[i]:\n",
    "                            cls_changes[i] = True\n",
    "\n",
    "                        elif previous_l[i] > (e[i] / (previous_e[i] - e[i])):\n",
    "\n",
    "                            L_index = self.rd.choice(L_i_size, ceil(\n",
    "                                (previous_e[i] * previous_l[i] / e[i]) - 1))\n",
    "                            cls_pseudo_updates[i] = (\n",
    "                                cls_pseudo_updates[i][0][L_index, :], cls_pseudo_updates[i][1][L_index])\n",
    "                            cls_changes[i] = True\n",
    "\n",
    "            if cls_changes.sum() == 0:\n",
    "                new_data = False\n",
    "\n",
    "            else:\n",
    "\n",
    "                for i in np.fromiter(self.classifiers.keys(), dtype=int)[cls_changes]:\n",
    "\n",
    "                    X_train = np.concatenate((L, cls_pseudo_updates[i][0]))\n",
    "                    y_train = np.concatenate((y, cls_pseudo_updates[i][1]))\n",
    "                    self.classifiers[i] = self.classifiers[i].fit(\n",
    "                        X_train, y_train)\n",
    "\n",
    "                    previous_e[i] = e[i]\n",
    "                    # TamaÃ±o de Li anterior\n",
    "                    previous_l[i] = cls_pseudo_updates[i][0].shape[0]\n",
    "\n",
    "                scores.append(self.score(X_test, y_test))\n",
    "\n",
    "        append_to_csv(\"file.csv\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemocraticCo_graphs(DemocraticCo):\n",
    "\n",
    "    def fit(self, L, y, U, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Trains the democratic-Co.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Labeled data tags used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "        classes = np.unique(y)\n",
    "        self.classes = classes\n",
    "        changes = True\n",
    "\n",
    "        e = [0] * self.n\n",
    "        L_ = [(list(L), list(y)) for i in range(self.n)]\n",
    "        U_in_L_ = [dict() for i in range(self.n)]\n",
    "        cls_changes = np.ones(self.n, dtype=bool)\n",
    "\n",
    "        t = 0\n",
    "        scores = []\n",
    "\n",
    "        while changes:\n",
    "\n",
    "            for i in np.arange(self.n)[cls_changes]:\n",
    "                self.classifiers[i] = self.classifiers[i].fit(*L_[i])\n",
    "            cls_changes = np.zeros(self.n, dtype=bool)\n",
    "\n",
    "            U_tag_votes = [{i: set() for i in self.classes} for x in U]\n",
    "            U_y = []\n",
    "\n",
    "            for x_id, x in enumerate(U):\n",
    "                for id_cls, cls in self.classifiers.items():\n",
    "                    prediction = cls.predict([x])[0]\n",
    "                    U_tag_votes[x_id][prediction].add(id_cls)\n",
    "\n",
    "                U_y.append(\n",
    "                    max(U_tag_votes[x_id], key=lambda k: len(U_tag_votes[x_id].get(k))))\n",
    "\n",
    "            # Choose which exs to propose for labeling\n",
    "            w = [self.get_w(cls, L, y) for cls in self.classifiers.values()]\n",
    "            L_prime = [([], []) for i in range(self.n)]\n",
    "            Li_prime_ids = [[] for i in range(self.n)]\n",
    "\n",
    "            for x_id, x in enumerate(U):\n",
    "\n",
    "                most_voted_tag = U_y[x_id]\n",
    "                cls_agree_tag = U_tag_votes[x_id][most_voted_tag]\n",
    "\n",
    "                exp_1 = 0\n",
    "                for cls in cls_agree_tag:\n",
    "                    exp_1 += w[cls]\n",
    "\n",
    "                exp_2 = 0\n",
    "                for tag in classes:\n",
    "                    if tag != most_voted_tag:\n",
    "                        weight_tag = 0\n",
    "                        for cls in U_tag_votes[x_id][tag]:\n",
    "                            weight_tag += w[cls]\n",
    "                        exp_2 = max(exp_2, weight_tag)\n",
    "\n",
    "                if exp_1 > exp_2:\n",
    "                    for id_cls in (set(self.classifiers.keys()) - cls_agree_tag):\n",
    "                        Li_prime, y_Li_prime = L_prime[id_cls]\n",
    "                        Li_prime.append(x)\n",
    "                        y_Li_prime.append(U_y[x_id])\n",
    "                        Li_prime_ids[id_cls].append(x_id)\n",
    "\n",
    "            # Estimate if adding this is better\n",
    "            l_mean = 0\n",
    "            for id_cls, cls in self.classifiers.items():\n",
    "                l_mean += confidence_interval(cls,\n",
    "                                              L_[id_cls][0], L_[id_cls][1])[0]\n",
    "            l_mean /= self.n\n",
    "\n",
    "            for i in range(self.n):\n",
    "\n",
    "                Li, y_Li = L_[i]\n",
    "                Li_prime, y_Li_prime = L_prime[i]\n",
    "                Li_union_Li_prime = Li + Li_prime\n",
    "\n",
    "                q_i = len(Li) * (1 - 2 * (e[i] / len(Li))) ** 2\n",
    "                e_i_prime = (1 - l_mean) * len(Li_prime)\n",
    "                q_i_prime = len(\n",
    "                    Li_union_Li_prime) * (1 - (2*(e[i] + e_i_prime) / len(Li_union_Li_prime))) ** 2\n",
    "\n",
    "                if q_i_prime > q_i:\n",
    "                    cls_changes[i] = True\n",
    "                    e[i] = e[i] + e_i_prime\n",
    "\n",
    "                    for x_id, x, y_x in zip(Li_prime_ids[i], Li_prime, y_Li_prime):\n",
    "                        if x_id in U_in_L_[i]:\n",
    "                            index = U_in_L_[i][x_id]\n",
    "                            y_Li[index] = y_x\n",
    "\n",
    "                        else:\n",
    "                            U_in_L_[i][x_id] = len(Li)\n",
    "                            Li.append(x)\n",
    "                            y_Li.append(y_x)\n",
    "\n",
    "            if cls_changes.sum() == 0:\n",
    "                changes = False\n",
    "                self.w = [self.get_w(cls, L, y)\n",
    "                          for cls in self.classifiers.values()]\n",
    "\n",
    "            self.w = [self.get_w(cls, L, y) for cls in self.classifiers.values()]\n",
    "            scores.append(self.score(X_test, y_test))\n",
    "            t += 1\n",
    "\n",
    "        append_to_csv(\"file.csv\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cls(algorithm, n=6, thetha=0.75, max_features='log2', base_cls=None, rd=np.random.RandomState(10)):\n",
    "\n",
    "    if base_cls is None:\n",
    "        base_cls = [DecisionTreeClassifier(), \n",
    "                    GaussianNB(),\n",
    "                    KNeighborsClassifier(n_neighbors=3)]\n",
    "\n",
    "    if algorithm == 'CF':\n",
    "        return CoForest(n, thetha, max_features, random_state=rd)\n",
    "\n",
    "    elif algorithm == 'CFG':\n",
    "        return CoForest_graphs(n, thetha, max_features, random_state=rd)\n",
    "\n",
    "    elif algorithm == 'TT':\n",
    "        return TriTraining(base_cls[0], base_cls[1], base_cls[2], rd)\n",
    "\n",
    "    elif algorithm == 'TTG':\n",
    "        return TriTraining_graphs(base_cls[0], base_cls[1], base_cls[2], rd)\n",
    "\n",
    "    elif algorithm == 'DC':\n",
    "        return DemocraticCo(base_cls, rd)\n",
    "\n",
    "    elif algorithm == 'DCG':\n",
    "        return DemocraticCo_graphs(base_cls, rd)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "# **GENERAL GRAPHS**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "### **score - nÃºmero de iteraciones (entrenamiento)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_score_iterations_train_mosaic(available, algorithm='CF', rd_number=5):\n",
    "\n",
    "    fig, ax = plt.subplot_mosaic(\n",
    "        \"AAABBCC;AAADDEE\", figsize=(10, 4.5), tight_layout=True)\n",
    "    ax['A'].set_ylabel('accuracy')\n",
    "    ax['A'].set_xlabel('iteraciones')\n",
    "\n",
    "    fig_2, ax_2 = plt.subplot_mosaic(\n",
    "        \"AAAAAAA;AAAAAAA\", figsize=(10, 4.5), tight_layout=True)\n",
    "    ax_2['A'].set_ylabel('accuracy')\n",
    "    ax_2['A'].set_xlabel('iteraciones')\n",
    "\n",
    "    max_iterations = 0\n",
    "\n",
    "    for dataset_info in available:\n",
    "\n",
    "        open('file.csv', 'w').close()\n",
    "        X, y = dataset_info[0]\n",
    "        rd = np.random.RandomState(rd_number)\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "                X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "            cls = create_base_cls(algorithm + 'G', n=20, rd=rd)\n",
    "            # Test used to evaluate how score changes during training\n",
    "            cls.fit(L_train, Ly_train, U_train, X_test, y_test)\n",
    "\n",
    "        mean = np.mean(create_graph_matrix(\"file.csv\"), axis=0)\n",
    "        std = np.std(create_graph_matrix(\"file.csv\"), axis=0)\n",
    "\n",
    "        x_ticks = [i for i in range(len(mean))]\n",
    "        ax['A'].plot(mean, color=dataset_info[3],\n",
    "                     linewidth=1, label=dataset_info[1]) #'-o',\n",
    "        ax_2['A'].plot(mean, color=dataset_info[3],\n",
    "                     linewidth=1, label=dataset_info[1]) #'-o',\n",
    "\n",
    "        ax_i = ax[dataset_info[2]]\n",
    "        ax_i.set_ylim([0.7, 1.05])\n",
    "        ax_i.set_ylabel('accuracy')\n",
    "        ax_i.set_xlabel('iteraciones')\n",
    "        ax_i.set_xticks(x_ticks)\n",
    "        ax_i.errorbar(x_ticks, mean, yerr=[std, np.minimum(\n",
    "            std, 1-mean)], color=dataset_info[3], linewidth=0.5, label=dataset_info[1]) #fmt='-o',\n",
    "        max_iterations = max(max_iterations, len(x_ticks))\n",
    "        \n",
    "        if len(mean) > 9:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(7))\n",
    "        elif len(mean) > 99:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(6))\n",
    "        elif len(mean) > 999:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "\n",
    "        break\n",
    "\n",
    "    ax['A'].set_xticks([i for i in range(max_iterations)])\n",
    "    ax_2['A'].set_xticks([i for i in range(max_iterations)])\n",
    "\n",
    "    if max_iterations > 9:\n",
    "        ax['A'].xaxis.set_major_locator(ticker.MaxNLocator(10))\n",
    "        ax_2['A'].xaxis.set_major_locator(ticker.MaxNLocator(20))\n",
    "    elif max_iterations > 99:\n",
    "        ax['A'].xaxis.set_major_locator(ticker.MaxNLocator(8))\n",
    "        ax_2['A'].xaxis.set_major_locator(ticker.MaxNLocator(16))\n",
    "    elif max_iterations > 999:\n",
    "        ax['A'].xaxis.set_major_locator(ticker.MaxNLocator(7))\n",
    "        ax_2['A'].xaxis.set_major_locator(ticker.MaxNLocator(14))\n",
    "\n",
    "    fig.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='lower center', ncol=4)\n",
    "\n",
    "    fig_2.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='lower center', ncol=4)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "### **nÃºmero elementos - tiempo entrenamiento**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_number_elem_training_time(algorithm='CF', rd_number=10):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "\n",
    "    instancias = []\n",
    "    tiempos = []\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "\n",
    "    for i in range(500, X.shape[0], 100):\n",
    "\n",
    "        indexes = rd.choice(X.shape[0], replace=False, size=i)\n",
    "        L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "            X[indexes], y[indexes], test_size=0.8, random_state=rd)\n",
    "\n",
    "        cls = create_base_cls(algorithm, n=20, rd=rd)\n",
    "        inicio = time.time()\n",
    "        cls.fit(L_train, Ly_train, U_train)\n",
    "        fin = time.time()\n",
    "        instancias.append(i)\n",
    "        tiempos.append((fin-inicio))\n",
    "\n",
    "    ax.scatter(instancias, tiempos, color='r')\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.array([[i] for i in instancias]), tiempos)\n",
    "    x_new = np.linspace(425, X.shape[0], 100)\n",
    "    y_new = model.predict(x_new[:, np.newaxis])\n",
    "\n",
    "    #plt.title(\"Instancias - Tiempo entrenamiento\")\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.plot(x_new, y_new, '--k')\n",
    "    ax.set_xlabel('instancias')\n",
    "    ax.set_ylabel('tiempo (s)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "### **score - % instancias entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_percentage_training_instances(available, algorithm='CF', rd_number=5, n_experiments=10):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "\n",
    "    for dataset_info in available:\n",
    "\n",
    "        matriz_scores = []\n",
    "        X, y = dataset_info[0]\n",
    "\n",
    "        for j in range(n_experiments):\n",
    "            scores_experimento = []\n",
    "\n",
    "            for i in np.arange(0.5, 1, 0.1):\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, train_size=i, random_state=rd, stratify=y)\n",
    "                L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "                    X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "                cls = create_base_cls(algorithm, n=20, rd=rd)\n",
    "                cls.fit(L_train, Ly_train, U_train)\n",
    "                scores_experimento.append(cls.score(X_test, y_test))\n",
    "            matriz_scores.append(scores_experimento)\n",
    "\n",
    "        ax.plot(np.arange(0.5, 1, 0.1), np.mean(np.array(matriz_scores), axis=0),\n",
    "                '-o', color=dataset_info[3], linewidth=1, label=dataset_info[1])\n",
    "\n",
    "    # plt.title(\"Score - % Instancias\")\n",
    "    ax.set_ylabel('score')\n",
    "    ax.set_xlabel('instancias (%)')\n",
    "    fig.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='upper center', ncol=4)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "### **coforest (especiales): scores & tiempo - nÃºmero de Ã¡rboles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_coforest_score_time(available):\n",
    "\n",
    "    fig, ax = plt.subplot_mosaic(\n",
    "        \"AABB;AABB\", figsize=(8, 4), tight_layout=True)\n",
    "\n",
    "    for dataset_info in available:\n",
    "\n",
    "        X, y = dataset_info[0]\n",
    "        rd = np.random.RandomState(5)\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "        matriz_scores = []\n",
    "        matriz_tiempos = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "                X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "            scores_fold = []\n",
    "            times_fold = []\n",
    "\n",
    "            for j in [2, 3, 6, 10, 20, 40]:\n",
    "                co_forest = CoForest(j, 0.75, 'log2', rd)\n",
    "                inicio = time.time()\n",
    "                co_forest.fit(L_train, Ly_train, U_train)\n",
    "                fin = time.time()\n",
    "                times_fold.append((fin-inicio))\n",
    "                scores_fold.append(co_forest.score(X_test, y_test))\n",
    "\n",
    "            matriz_scores.append(scores_fold)\n",
    "            matriz_tiempos.append(times_fold)\n",
    "\n",
    "        ax['A'].plot(np.array([2, 3, 6, 10, 20, 40]), np.mean(np.array(\n",
    "            matriz_scores), axis=0), '-o', color=dataset_info[3], linewidth=1, label=dataset_info[1])\n",
    "        ax['B'].plot(np.array([2, 3, 6, 10, 20, 40]), np.mean(np.array(\n",
    "            matriz_tiempos), axis=0), '-o', color=dataset_info[3], linewidth=1, label=dataset_info[1])\n",
    "\n",
    "    ax['A'].set_ylabel('accuracy')\n",
    "    ax['A'].set_xlabel('nÃºmero de Ã¡rboles')\n",
    "    ax['B'].set_ylabel('tiempo (s)')\n",
    "    ax['B'].set_xlabel('nÃºmero de Ã¡rboles')\n",
    "    fig.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='lower center', ncol=4)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "# **COMPARES**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **(CF) against KEEL** ðŸ£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_keel(file_root, random_number, algorithm):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(1, 11):\n",
    "\n",
    "        file_train = file_root + \"{}tra.csv\".format(i)\n",
    "        file_test = file_root + \"{}tst.csv\".format(i)\n",
    "\n",
    "        L, L_tags, U = extract_training_data(file_train)\n",
    "        X_test, y_test = extract_test_data(file_test)\n",
    "\n",
    "        cls = create_base_cls(\n",
    "            algorithm, rd=np.random.RandomState(random_number))\n",
    "        cls.fit(L, L_tags, U)\n",
    "        results.append(cls.score(X_test, y_test))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **(TT) against LAMDA and SSlearn** ðŸ£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sslearn.wrapper import TriTraining as TriTrainingSSLearn\n",
    "from sslearn.wrapper import DemocraticCoLearning as DemocraticCoSSLearn\n",
    "from sslearn.model_selection import artificial_ssl_dataset\n",
    "from sslearn.base import get_dataset\n",
    "\n",
    "\n",
    "def graph_score_fold_sslearn(algorithm='TT', rd_number=5):\n",
    "\n",
    "    labels = ['SSLearn', 'Media SSLearn',\n",
    "              'ImplementaciÃ³n propia', 'Media implementaciÃ³n propia']\n",
    "    x_labels = [i for i in range(1, 11)]\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3), tight_layout=True)\n",
    "    available = [(load_iris(return_X_y=True), 'Iris'),\n",
    "                 (load_digits(return_X_y=True), 'DÃ­gitos'),\n",
    "                 (load_breast_cancer(return_X_y=True), 'CÃ¡ncer de mama')]\n",
    "    i = 0\n",
    "\n",
    "    for dataset in available:\n",
    "\n",
    "        X, y = dataset[0]\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "        results = []\n",
    "        results_mine = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            X_train_labels, y_train_labels, U, U_labels = artificial_ssl_dataset(\n",
    "                X_train, y_train, label_rate=0.2)\n",
    "\n",
    "            # SSLearn\n",
    "            if algorithm == 'TT':\n",
    "                model = TriTrainingSSLearn(random_state=rd).fit(X_train_labels, y_train_labels)\n",
    "            elif algorithm == 'DC':\n",
    "                model = DemocraticCoSSLearn(random_state=rd).fit(X_train_labels, y_train_labels)\n",
    "\n",
    "            results.append(model.score(X_test, y_test))\n",
    "\n",
    "            # Mio (misma funciÃ³n que usa Ã©l internamente)\n",
    "            model_mine = create_base_cls(algorithm, rd=rd)\n",
    "            X_mine, y_mine, U_mine = get_dataset(\n",
    "                X_train_labels, y_train_labels)\n",
    "            model_mine.fit(X_mine, y_mine, U_mine)\n",
    "            results_mine.append(model_mine.score(X_test, y_test))\n",
    "\n",
    "        ax_i = ax[i]\n",
    "        ax_i.set_ylim([0.5, 1.05])\n",
    "\n",
    "        mean = np.mean(results)\n",
    "        ax_i.plot(x_labels, results, '-o', color='#9467bd', linewidth=1)\n",
    "        ax_i.plot(x_labels, [mean for i in range(10)],\n",
    "                  '--', linewidth=1, color='#9467bd')\n",
    "\n",
    "        mean = np.mean(results_mine)\n",
    "        ax_i.plot(x_labels, results_mine, 'c-o', linewidth=1)\n",
    "        ax_i.plot(x_labels, [mean for i in range(10)], 'c--', linewidth=1)\n",
    "\n",
    "        ax_i.set_ylim([0.5, 1.05])\n",
    "        ax_i.set_ylabel('accuracy')\n",
    "        ax_i.set_xlabel('fold')\n",
    "        ax_i.set_title(dataset[1])\n",
    "        i += 1\n",
    "\n",
    "        break\n",
    "\n",
    "    fig.legend(labels, bbox_to_anchor=(0.5, 1.0), loc='lower center', ncol=4)\n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from LAMDA_SSL.Algorithm.Classification.Tri_Training import Tri_Training as TriTrainingLamda\n",
    "\n",
    "# def graph_score_fold_lamda(algorithm = 'TT', rd_number = 5):\n",
    "\n",
    "#     labels = ['LAMDA', 'Media LAMDA', 'ImplementaciÃ³n propia', 'Media implementaciÃ³n propia']\n",
    "#     x_labels = [i for i in range(1,11)]\n",
    "#     rd = np.random.RandomState(rd_number)\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9,3), tight_layout=True)\n",
    "#     available = [   (load_iris(return_X_y=True), 'Iris'),\n",
    "#                     (load_digits(return_X_y=True), 'DÃ­gitos'),\n",
    "#                     (load_breast_cancer(return_X_y=True), 'CÃ¡ncer de mama')]\n",
    "#     i = 0\n",
    "\n",
    "#     for dataset in available:\n",
    "\n",
    "#         X, y = dataset[0]\n",
    "#         skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "#         results = []\n",
    "#         results_mine = []\n",
    "\n",
    "#         for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "#             X_train, X_test = X[train_index], X[test_index]\n",
    "#             y_train, y_test = y[train_index], y[test_index]\n",
    "#             L_train, U_train, Ly_train, Uy_train = train_test_split(X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "\n",
    "#             # LAMDA\n",
    "#             model = TriTrainingLamda(DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier())\n",
    "#             model.fit(L_train, Ly_train, U_train)\n",
    "#             results.append(model.score(X_test, y_test))\n",
    "\n",
    "#             # Mio\n",
    "#             model_mine = TriTraining(DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier())\n",
    "#             model_mine.fit(L_train, Ly_train, U_train)\n",
    "#             results_mine.append(model_mine.score(X_test, y_test))\n",
    "\n",
    "#         ax_i = ax[i]\n",
    "\n",
    "#         mean = np.mean(results)\n",
    "#         ax_i.plot(x_labels, results, '-o', color = '#ff7f0e', linewidth=1)\n",
    "#         ax_i.plot(x_labels, [mean for i in range(10)], '--', color = '#ff7f0e', linewidth=1)\n",
    "\n",
    "#         mean = np.mean(results_mine)\n",
    "#         ax_i.plot(x_labels, results_mine, 'c-o', linewidth=1)\n",
    "#         ax_i.plot(x_labels, [mean for i in range(10)], 'c--', linewidth=1)\n",
    "\n",
    "#         ax_i.set_ylim([0.6, 1.05])\n",
    "#         ax_i.set_ylabel('accuracy')\n",
    "#         ax_i.set_xlabel('fold')\n",
    "#         ax_i.set_title(dataset[1])\n",
    "#         i += 1\n",
    "\n",
    "#     fig.legend(labels, bbox_to_anchor=(0.5, 1.0), loc='lower center', ncol=4)\n",
    "#     plt.plot()\n",
    "\n",
    "# graph_score_fold_lamda()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "# **RUN ALL** ðŸƒðŸ¼â€â™€ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(algorithm='CF'):\n",
    "\n",
    "    available = [(load_iris(return_X_y=True), 'Iris', 'B', '#2ca02c'),\n",
    "                 (load_digits(return_X_y=True), 'DÃ­gitos', 'C', '#ff7f0e'),\n",
    "                 (load_wine(return_X_y=True), 'Vino', 'D', '#d62728'),\n",
    "                 (load_breast_cancer(return_X_y=True), 'CÃ¡ncer de mama', 'E', '#9467bd')]\n",
    "\n",
    "    # graph_number_elem_training_time(algorithm)\n",
    "    # score_percentage_training_instances(available, algorithm)\n",
    "    graph_score_iterations_train_mosaic(available, algorithm)\n",
    "\n",
    "    if algorithm == 'CF':\n",
    "        graph_coforest_score_time(available)\n",
    "        graph_init_w_compare(available, algorithm='CF', rd_number=5)\n",
    "        \n",
    "        results = graphs_keel(\"iris/iris-ssl-\", 5, 'CF')\n",
    "        print(\"IRIS vs KEEL: {}, mean: {}\".format(results, np.mean(results)))\n",
    "\n",
    "        results = graphs_keel(\"wine/wine-ssl10-10-\", 10, 'CF')\n",
    "        print(\"WINE vs KEEL: {}, mean: {}\".format(results, np.mean(results)))\n",
    "\n",
    "    else:\n",
    "        graph_score_fold_sslearn(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_all('DC')  # 'CF', 'TT, 'DC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def graph_init_w_compare(available, algorithm='CF', n_trees=6, rd_number=5):\n",
    "\n",
    "    fig, ax = plt.subplot_mosaic(\n",
    "        \"AAABBBCCC;AAABBBCCC\", figsize=(9, 3), tight_layout=True)\n",
    "    \n",
    "    letras = ['A', 'B', 'C']\n",
    "    metodos = ['percentage_L', 'confidence_L_all', 'confidence_L_thetha']\n",
    "    \n",
    "    max_iterations = 0\n",
    "    min_y = 1\n",
    "    max_y = 0\n",
    "\n",
    "    for dataset_info in available:\n",
    "\n",
    "        for letra in letras:\n",
    "            open('file_{}.csv'.format(letra), 'w').close()\n",
    "\n",
    "        X, y = dataset_info[0]\n",
    "        rd = { letra : deepcopy(np.random.RandomState(rd_number)) for letra in letras}\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=np.random.RandomState(rd_number))\n",
    "        fold_number = 0\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "            fold_number += 1\n",
    "            print(\"**Dataset: {}. Fold number: {}**\".format(dataset_info[1], fold_number))\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            for letra, metodo in zip(letras, metodos):\n",
    "                L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "                    X_train, y_train, test_size=0.8, random_state=rd[letra], stratify=y_train)\n",
    "                cls = create_base_cls(algorithm + 'G', n=n_trees, rd=rd[letra])\n",
    "\n",
    "                # Test used to evaluate how score changes during training\n",
    "                cls.fit(L_train, Ly_train, U_train, X_test, y_test, w_init_criteria=metodo, file_name='file_{}.csv'.format(letra))\n",
    "\n",
    "        for letra in letras:\n",
    "            mean = np.mean(create_graph_matrix(\"file_{}.csv\".format(letra)), axis=0)\n",
    "            ax[letra].plot(mean, color=dataset_info[3],\n",
    "                             linewidth=1, label=dataset_info[1])\n",
    "            max_iterations = max(max_iterations, len(mean))\n",
    "            min_y = min(min_y, min(mean))\n",
    "            max_y = max(max_y, max(mean))\n",
    "\n",
    "        break\n",
    "\n",
    "    for metodo, letra in zip(metodos, letras):\n",
    "        ax[letra].set_title('{}'.format(metodo))\n",
    "        ax[letra].set_xticks([i for i in range(max_iterations)])\n",
    "        ax[letra].set_ylabel('accuracy')\n",
    "        ax[letra].set_xlabel('iteraciones')\n",
    "        ax[letra].set_ylim([min_y - 0.02, max_y + 0.02])\n",
    "\n",
    "        if max_iterations > 9:\n",
    "            ax[letra].xaxis.set_major_locator(ticker.MaxNLocator(7, integer=True))\n",
    "        elif max_iterations > 99:\n",
    "            ax[letra].xaxis.set_major_locator(ticker.MaxNLocator(6, integer=True))\n",
    "\n",
    "    fig.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='lower center', ncol=4)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Dataset: Iris. Fold number: 1**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['24.40', '23.80', '24.80', '23.80', '24.20', '24.00']\n",
      "Method: confidence_L_thetha. Previous W: ['23.20', '21.40', '23.60', '21.40', '23.00', '22.80']\n",
      "**Dataset: Iris. Fold number: 2**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['24.40', '24.80', '25.00', '25.20', '24.40', '25.20']\n",
      "Method: confidence_L_thetha. Previous W: ['24.80', '24.60', '23.80', '23.80', '25.80', '23.80']\n",
      "**Dataset: Iris. Fold number: 3**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['26.00', '25.80', '25.60', '26.20', '25.80', '25.60']\n",
      "Method: confidence_L_thetha. Previous W: ['25.00', '24.20', '23.80', '23.80', '24.20', '24.60']\n",
      "**Dataset: Iris. Fold number: 4**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['25.40', '25.00', '25.20', '25.20', '25.40', '25.80']\n",
      "Method: confidence_L_thetha. Previous W: ['26.80', '26.80', '26.80', '27.00', '26.80', '26.80']\n",
      "**Dataset: Iris. Fold number: 5**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['26.40', '26.40', '26.80', '26.40', '26.60', '26.40']\n",
      "Method: confidence_L_thetha. Previous W: ['24.80', '23.00', '23.60', '23.20', '23.60', '24.60']\n",
      "**Dataset: Iris. Fold number: 6**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['25.20', '25.00', '25.20', '24.80', '24.80', '24.80']\n",
      "Method: confidence_L_thetha. Previous W: ['24.40', '24.40', '25.20', '25.00', '25.20', '24.40']\n",
      "**Dataset: Iris. Fold number: 7**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['25.80', '24.80', '24.40', '24.40', '24.40', '24.80']\n",
      "Method: confidence_L_thetha. Previous W: ['25.60', '26.00', '25.60', '25.60', '25.60', '25.60']\n",
      "**Dataset: Iris. Fold number: 8**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['24.80', '25.40', '24.80', '25.20', '25.20', '24.60']\n",
      "Method: confidence_L_thetha. Previous W: ['25.60', '26.80', '25.60', '25.60', '25.60', '26.40']\n",
      "**Dataset: Iris. Fold number: 9**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['26.00', '26.60', '26.00', '26.00', '26.40', '26.00']\n",
      "Method: confidence_L_thetha. Previous W: ['24.20', '24.20', '23.60', '24.60', '23.40', '24.20']\n",
      "**Dataset: Iris. Fold number: 10**\n",
      "Method: percentage_L. Previous W: ['2.70', '2.70', '2.70', '2.70', '2.70', '2.70']\n",
      "Method: confidence_L_all. Previous W: ['25.60', '25.60', '25.80', '25.60', '25.60', '25.40']\n",
      "Method: confidence_L_thetha. Previous W: ['19.60', '19.20', '19.40', '20.00', '21.60', '23.40']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "available = [(load_iris(return_X_y=True), 'Iris', 'B', '#2ca02c'),\n",
    "                (load_digits(return_X_y=True), 'DÃ­gitos', 'C', '#ff7f0e'),\n",
    "                (load_wine(return_X_y=True), 'Vino', 'D', '#d62728'),\n",
    "                (load_breast_cancer(return_X_y=True), 'CÃ¡ncer de mama', 'E', '#9467bd')]\n",
    "\n",
    "graph_init_w_compare(available, 'CF', n_trees=6)\n",
    "graph_init_w_compare(available, 'CF', n_trees=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aa2267a3633e362ab4cdc36738c6d0a45a450435ef5c859c0f11f93c27ebe6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
