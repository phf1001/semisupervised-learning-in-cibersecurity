{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📈 **GRAPHS ALGORITHMS GENERATOR** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, load_digits, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from math import floor, ceil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "#Fallaba por la barra al final\n",
    "src_path = Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.parent\n",
    "sys.path.append(str(src_path)  + os.sep)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append( (src_path + os.sep) )\n",
    "\n",
    "from models.classifiers.CoForestClassifier import CoForest\n",
    "from models.classifiers.TriTrainingClassifier import TriTraining\n",
    "from models.classifiers.DemocraticCoClassifier import DemocraticCo\n",
    "from models.classifiers.utils import *\n",
    "from models.notebooks.graphs_utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **CLASSES**\n",
    "\n",
    "Fit methods needs to be overwritten since graphs are generated while training, so inheritance is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoForest_graphs(CoForest):\n",
    "\n",
    "    def fit(self, L, y, U, X_test, y_test, w_init_criteria='percentage_L', file_name=\"file.csv\"):\n",
    "        \"\"\"\n",
    "        Fits the ensemble using both labeled and\n",
    "        pseudo-labeled data. Generates graphs to show \n",
    "        how score evolves during training.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Tags of the labeled data used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "\n",
    "        mask_L = self.create_trees(L, y)\n",
    "        scores = [self.score(X_test, y_test)]\n",
    "\n",
    "        e = [0 for i in range(self.n)]\n",
    "        W = [0 for i in range(self.n)]\n",
    "\n",
    "        previous_e = [0.5 for i in range(self.n)]\n",
    "        previous_W = previous_W = self.initialize_previous_W(L, w_init_criteria)\n",
    "        #print(\"Method: {}. Previous W: {}\".format(w_init_criteria, [ '%.2f' % elem for elem in previous_W ]))\n",
    "        \n",
    "        new_data = True\n",
    "        t = 0\n",
    "\n",
    "        while new_data:\n",
    "\n",
    "            t += 1\n",
    "            tree_changes = np.array([False for i in range(self.n)])\n",
    "            tree_pseudo_updates = [() for i in range(self.n)]\n",
    "\n",
    "            for i, hi in self.ensemble.items():\n",
    "\n",
    "                e[i] = self.concomitant_oob_error(hi, L, y, mask_L)\n",
    "                W[i] = previous_W[i]\n",
    "                pseudo_labeled_data = []\n",
    "                pseudo_labeled_tags = []\n",
    "\n",
    "                if e[i] < previous_e[i]:\n",
    "\n",
    "                    if e[i] == 0:\n",
    "                        Wmax = self.theta * U.shape[0]\n",
    "                    else:\n",
    "                        Wmax = min(\n",
    "                            self.theta * U.shape[0], ((previous_e[i]*previous_W[i])/e[i]))\n",
    "\n",
    "                    U_subsampled = self.subsample(hi, U, Wmax)\n",
    "                    W[i] = 0\n",
    "\n",
    "                    for u in U_subsampled:\n",
    "                        concomitant_confidence, selected_class = self.concomitant_confidence(\n",
    "                            hi, U[u, :])\n",
    "\n",
    "                        if concomitant_confidence > self.theta:\n",
    "                            tree_changes[i] = True\n",
    "                            pseudo_labeled_data.append(U[u, :])\n",
    "                            pseudo_labeled_tags.append(selected_class)\n",
    "                            W[i] += concomitant_confidence\n",
    "\n",
    "                tree_pseudo_updates[i] = (\n",
    "                    (np.array(pseudo_labeled_data), np.array(pseudo_labeled_tags)))\n",
    "\n",
    "            for i in np.fromiter(self.ensemble.keys(), dtype=int)[tree_changes]:\n",
    "                if e[i] * W[i] < previous_e[i] * previous_W[i]:\n",
    "                    self.retrain_tree(\n",
    "                        i, L, y, tree_pseudo_updates[i][0], tree_pseudo_updates[i][1], mask_L)\n",
    "\n",
    "            previous_e = deepcopy(e)\n",
    "            previous_W = deepcopy(W)\n",
    "\n",
    "            if tree_changes.sum() == 0:\n",
    "                new_data = False\n",
    "\n",
    "            scores.append(self.score(X_test, y_test))\n",
    "\n",
    "        append_to_csv(file_name, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTraining_graphs(TriTraining):\n",
    "\n",
    "    def fit(self, L, y, U, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Trains the tri-training ensemble using Zhi-Hua Zhou\n",
    "        Algorithm. Generates graphs to show how score\n",
    "        evolves during training.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Labeled data tags used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "\n",
    "        self.initialize_classifiers(L, y)\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        previous_e = [0.5 for i in range(self.n)]\n",
    "        previous_l = [0.0 for i in range(self.n)]\n",
    "        e = [0.0 for i in range(self.n)]\n",
    "        new_data = True\n",
    "\n",
    "        t = 0\n",
    "        scores = [self.score(X_test, y_test)]\n",
    "\n",
    "        while new_data:\n",
    "\n",
    "            t += 1\n",
    "            cls_changes = np.array([False for i in range(self.n)])\n",
    "            cls_pseudo_updates = [() for i in range(self.n)]\n",
    "\n",
    "            for i in range(self.n):\n",
    "\n",
    "                e[i] = self.measure_error(i, L, y)\n",
    "\n",
    "                if e[i] < previous_e[i]:\n",
    "                    cls_pseudo_updates[i] = self.create_pseudolabeled_set(i, U)\n",
    "\n",
    "                    if previous_l[i] == 0:\n",
    "                        previous_l[i] = floor(\n",
    "                            (e[i] / (previous_e[i]-e[i])) + 1)\n",
    "\n",
    "                    L_i_size = cls_pseudo_updates[i][0].shape[0]\n",
    "\n",
    "                    if previous_l[i] < L_i_size:\n",
    "\n",
    "                        if e[i] * L_i_size < previous_e[i] * previous_l[i]:\n",
    "                            cls_changes[i] = True\n",
    "\n",
    "                        elif previous_l[i] > (e[i] / (previous_e[i] - e[i])):\n",
    "\n",
    "                            L_index = self.rd.choice(L_i_size, ceil(\n",
    "                                (previous_e[i] * previous_l[i] / e[i]) - 1))\n",
    "                            cls_pseudo_updates[i] = (\n",
    "                                cls_pseudo_updates[i][0][L_index, :], cls_pseudo_updates[i][1][L_index])\n",
    "                            cls_changes[i] = True\n",
    "\n",
    "            if cls_changes.sum() == 0:\n",
    "                new_data = False\n",
    "\n",
    "            else:\n",
    "\n",
    "                for i in np.fromiter(self.classifiers.keys(), dtype=int)[cls_changes]:\n",
    "\n",
    "                    X_train = np.concatenate((L, cls_pseudo_updates[i][0]))\n",
    "                    y_train = np.concatenate((y, cls_pseudo_updates[i][1]))\n",
    "                    self.classifiers[i] = self.classifiers[i].fit(\n",
    "                        X_train, y_train)\n",
    "\n",
    "                    previous_e[i] = e[i]\n",
    "                    # Tamaño de Li anterior\n",
    "                    previous_l[i] = cls_pseudo_updates[i][0].shape[0]\n",
    "\n",
    "                scores.append(self.score(X_test, y_test))\n",
    "\n",
    "        append_to_csv(\"file.csv\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemocraticCo_graphs(DemocraticCo):\n",
    "\n",
    "    def fit(self, L, y, U, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Trains the democratic-Co.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Labeled data tags used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "        classes = np.unique(y)\n",
    "        self.classes = classes\n",
    "        changes = True\n",
    "\n",
    "        e = [0] * self.n\n",
    "        L_ = [(list(L), list(y)) for i in range(self.n)]\n",
    "        U_in_L_ = [dict() for i in range(self.n)]\n",
    "        cls_changes = np.ones(self.n, dtype=bool)\n",
    "\n",
    "        t = 0\n",
    "        scores = []\n",
    "\n",
    "        while changes:\n",
    "\n",
    "            for i in np.arange(self.n)[cls_changes]:\n",
    "                self.classifiers[i] = self.classifiers[i].fit(*L_[i])\n",
    "            cls_changes = np.zeros(self.n, dtype=bool)\n",
    "\n",
    "            U_tag_votes = [{i: set() for i in self.classes} for x in U]\n",
    "            U_y = []\n",
    "\n",
    "            for x_id, x in enumerate(U):\n",
    "                for id_cls, cls in self.classifiers.items():\n",
    "                    prediction = cls.predict([x])[0]\n",
    "                    U_tag_votes[x_id][prediction].add(id_cls)\n",
    "\n",
    "                U_y.append(\n",
    "                    max(U_tag_votes[x_id], key=lambda k: len(U_tag_votes[x_id].get(k))))\n",
    "\n",
    "            # Choose which exs to propose for labeling\n",
    "            w = [self.get_w(cls, L, y) for cls in self.classifiers.values()]\n",
    "            L_prime = [([], []) for i in range(self.n)]\n",
    "            Li_prime_ids = [[] for i in range(self.n)]\n",
    "\n",
    "            for x_id, x in enumerate(U):\n",
    "\n",
    "                most_voted_tag = U_y[x_id]\n",
    "                cls_agree_tag = U_tag_votes[x_id][most_voted_tag]\n",
    "\n",
    "                exp_1 = 0\n",
    "                for cls in cls_agree_tag:\n",
    "                    exp_1 += w[cls]\n",
    "\n",
    "                exp_2 = 0\n",
    "                for tag in classes:\n",
    "                    if tag != most_voted_tag:\n",
    "                        weight_tag = 0\n",
    "                        for cls in U_tag_votes[x_id][tag]:\n",
    "                            weight_tag += w[cls]\n",
    "                        exp_2 = max(exp_2, weight_tag)\n",
    "\n",
    "                if exp_1 > exp_2:\n",
    "                    for id_cls in (set(self.classifiers.keys()) - cls_agree_tag):\n",
    "                        Li_prime, y_Li_prime = L_prime[id_cls]\n",
    "                        Li_prime.append(x)\n",
    "                        y_Li_prime.append(U_y[x_id])\n",
    "                        Li_prime_ids[id_cls].append(x_id)\n",
    "\n",
    "            # Estimate if adding this is better\n",
    "            l_mean = 0\n",
    "            for id_cls, cls in self.classifiers.items():\n",
    "                l_mean += confidence_interval(cls,\n",
    "                                              L_[id_cls][0], L_[id_cls][1])[0]\n",
    "            l_mean /= self.n\n",
    "\n",
    "            for i in range(self.n):\n",
    "\n",
    "                Li, y_Li = L_[i]\n",
    "                Li_prime, y_Li_prime = L_prime[i]\n",
    "                Li_union_Li_prime = Li + Li_prime\n",
    "\n",
    "                q_i = len(Li) * (1 - 2 * (e[i] / len(Li))) ** 2\n",
    "                e_i_prime = (1 - l_mean) * len(Li_prime)\n",
    "                q_i_prime = len(\n",
    "                    Li_union_Li_prime) * (1 - (2*(e[i] + e_i_prime) / len(Li_union_Li_prime))) ** 2\n",
    "\n",
    "                if q_i_prime > q_i:\n",
    "                    cls_changes[i] = True\n",
    "                    e[i] = e[i] + e_i_prime\n",
    "\n",
    "                    for x_id, x, y_x in zip(Li_prime_ids[i], Li_prime, y_Li_prime):\n",
    "                        if x_id in U_in_L_[i]:\n",
    "                            index = U_in_L_[i][x_id]\n",
    "                            y_Li[index] = y_x\n",
    "\n",
    "                        else:\n",
    "                            U_in_L_[i][x_id] = len(Li)\n",
    "                            Li.append(x)\n",
    "                            y_Li.append(y_x)\n",
    "\n",
    "            if cls_changes.sum() == 0:\n",
    "                changes = False\n",
    "                self.w = [self.get_w(cls, L, y)\n",
    "                          for cls in self.classifiers.values()]\n",
    "\n",
    "            self.w = [self.get_w(cls, L, y) for cls in self.classifiers.values()]\n",
    "            scores.append(self.score(X_test, y_test))\n",
    "            t += 1\n",
    "\n",
    "        append_to_csv(\"file.csv\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cls(algorithm, n=6, thetha=0.75, max_features='log2', base_cls=None, rd=np.random.RandomState(10)):\n",
    "\n",
    "    if base_cls is None:\n",
    "        base_cls = [DecisionTreeClassifier(), \n",
    "                    GaussianNB(),\n",
    "                    KNeighborsClassifier(n_neighbors=3)]\n",
    "\n",
    "    if algorithm == 'CF':\n",
    "        return CoForest(n, thetha, max_features, random_state=rd)\n",
    "\n",
    "    elif algorithm == 'CFG':\n",
    "        return CoForest_graphs(n, thetha, max_features, random_state=rd)\n",
    "\n",
    "    elif algorithm == 'TT':\n",
    "        return TriTraining(base_cls[0], base_cls[1], base_cls[2], rd)\n",
    "\n",
    "    elif algorithm == 'TTG':\n",
    "        return TriTraining_graphs(base_cls[0], base_cls[1], base_cls[2], rd)\n",
    "\n",
    "    elif algorithm == 'DC':\n",
    "        return DemocraticCo(base_cls, rd)\n",
    "\n",
    "    elif algorithm == 'DCG':\n",
    "        return DemocraticCo_graphs(base_cls, rd)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "# **GENERAL GRAPHS**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "### **score - número de iteraciones (entrenamiento)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_score_iterations_train_mosaic(available, algorithm='CF', rd_number=5):\n",
    "\n",
    "    fig, ax = plt.subplot_mosaic(\n",
    "        \"AAABBCC;AAADDEE\", figsize=(10, 4.5), tight_layout=True)\n",
    "    ax['A'].set_ylabel('accuracy')\n",
    "    ax['A'].set_xlabel('iteraciones')\n",
    "\n",
    "    fig_2, ax_2 = plt.subplot_mosaic(\n",
    "        \"AAAAAAA;AAAAAAA\", figsize=(10, 4.5), tight_layout=True)\n",
    "    ax_2['A'].set_ylabel('accuracy')\n",
    "    ax_2['A'].set_xlabel('iteraciones')\n",
    "\n",
    "    max_iterations = 0\n",
    "\n",
    "    for dataset_info in available:\n",
    "\n",
    "        open('file.csv', 'w').close()\n",
    "        X, y = dataset_info[0]\n",
    "        rd = np.random.RandomState(rd_number)\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "                X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "            cls = create_base_cls(algorithm + 'G', n=20, rd=rd)\n",
    "            # Test used to evaluate how score changes during training\n",
    "            cls.fit(L_train, Ly_train, U_train, X_test, y_test)\n",
    "\n",
    "        mean = np.mean(create_graph_matrix(\"file.csv\"), axis=0)\n",
    "        std = np.std(create_graph_matrix(\"file.csv\"), axis=0)\n",
    "\n",
    "        x_ticks = [i for i in range(len(mean))]\n",
    "        ax['A'].plot(mean, color=dataset_info[3],\n",
    "                     linewidth=1, label=dataset_info[1]) #'-o',\n",
    "        ax_2['A'].plot(mean, color=dataset_info[3],\n",
    "                     linewidth=1, label=dataset_info[1]) #'-o',\n",
    "\n",
    "        ax_i = ax[dataset_info[2]]\n",
    "        ax_i.set_ylim([0.7, 1.05])\n",
    "        ax_i.set_ylabel('accuracy')\n",
    "        ax_i.set_xlabel('iteraciones')\n",
    "        ax_i.set_xticks(x_ticks)\n",
    "        ax_i.errorbar(x_ticks, mean, yerr=[std, np.minimum(\n",
    "            std, 1-mean)], color=dataset_info[3], linewidth=0.5, label=dataset_info[1]) #fmt='-o',\n",
    "        max_iterations = max(max_iterations, len(x_ticks))\n",
    "        \n",
    "        if len(mean) > 9:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(7))\n",
    "        elif len(mean) > 99:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(6))\n",
    "        elif len(mean) > 999:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "\n",
    "        break\n",
    "\n",
    "    ax['A'].set_xticks([i for i in range(max_iterations)])\n",
    "    ax_2['A'].set_xticks([i for i in range(max_iterations)])\n",
    "\n",
    "    if max_iterations > 9:\n",
    "        ax['A'].xaxis.set_major_locator(ticker.MaxNLocator(10))\n",
    "        ax_2['A'].xaxis.set_major_locator(ticker.MaxNLocator(20))\n",
    "    elif max_iterations > 99:\n",
    "        ax['A'].xaxis.set_major_locator(ticker.MaxNLocator(8))\n",
    "        ax_2['A'].xaxis.set_major_locator(ticker.MaxNLocator(16))\n",
    "    elif max_iterations > 999:\n",
    "        ax['A'].xaxis.set_major_locator(ticker.MaxNLocator(7))\n",
    "        ax_2['A'].xaxis.set_major_locator(ticker.MaxNLocator(14))\n",
    "\n",
    "    fig.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='lower center', ncol=4)\n",
    "\n",
    "    fig_2.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='lower center', ncol=4)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "### **número elementos - tiempo entrenamiento**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_number_elem_training_time(algorithm='CF', rd_number=10):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "\n",
    "    instancias = []\n",
    "    tiempos = []\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "\n",
    "    for i in range(500, X.shape[0], 100):\n",
    "\n",
    "        indexes = rd.choice(X.shape[0], replace=False, size=i)\n",
    "        L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "            X[indexes], y[indexes], test_size=0.8, random_state=rd)\n",
    "\n",
    "        cls = create_base_cls(algorithm, n=20, rd=rd)\n",
    "        inicio = time.time()\n",
    "        cls.fit(L_train, Ly_train, U_train)\n",
    "        fin = time.time()\n",
    "        instancias.append(i)\n",
    "        tiempos.append((fin-inicio))\n",
    "\n",
    "    ax.scatter(instancias, tiempos, color='r')\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.array([[i] for i in instancias]), tiempos)\n",
    "    x_new = np.linspace(425, X.shape[0], 100)\n",
    "    y_new = model.predict(x_new[:, np.newaxis])\n",
    "\n",
    "    #plt.title(\"Instancias - Tiempo entrenamiento\")\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.plot(x_new, y_new, '--k')\n",
    "    ax.set_xlabel('instancias')\n",
    "    ax.set_ylabel('tiempo (s)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "### **score - % instancias entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_percentage_training_instances(available, algorithm='CF', rd_number=5, n_experiments=10):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "\n",
    "    for dataset_info in available:\n",
    "\n",
    "        matriz_scores = []\n",
    "        X, y = dataset_info[0]\n",
    "\n",
    "        for j in range(n_experiments):\n",
    "            scores_experimento = []\n",
    "\n",
    "            for i in np.arange(0.5, 1, 0.1):\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, train_size=i, random_state=rd, stratify=y)\n",
    "                L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "                    X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "                cls = create_base_cls(algorithm, n=20, rd=rd)\n",
    "                cls.fit(L_train, Ly_train, U_train)\n",
    "                scores_experimento.append(cls.score(X_test, y_test))\n",
    "            matriz_scores.append(scores_experimento)\n",
    "\n",
    "        ax.plot(np.arange(0.5, 1, 0.1), np.mean(np.array(matriz_scores), axis=0),\n",
    "                '-o', color=dataset_info[3], linewidth=1, label=dataset_info[1])\n",
    "\n",
    "    # plt.title(\"Score - % Instancias\")\n",
    "    ax.set_ylabel('score')\n",
    "    ax.set_xlabel('instancias (%)')\n",
    "    fig.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='upper center', ncol=4)\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "### **coforest (especiales): scores & tiempo - número de árboles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_coforest_score_time(available):\n",
    "\n",
    "    fig, ax = plt.subplot_mosaic(\n",
    "        \"AABB;AABB\", figsize=(8, 4), tight_layout=True)\n",
    "\n",
    "    for dataset_info in available:\n",
    "\n",
    "        X, y = dataset_info[0]\n",
    "        rd = np.random.RandomState(5)\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "        matriz_scores = []\n",
    "        matriz_tiempos = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "                X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "            scores_fold = []\n",
    "            times_fold = []\n",
    "\n",
    "            for j in [2, 3, 6, 10, 20, 40]:\n",
    "                co_forest = CoForest(j, 0.75, 'log2', rd)\n",
    "                inicio = time.time()\n",
    "                co_forest.fit(L_train, Ly_train, U_train)\n",
    "                fin = time.time()\n",
    "                times_fold.append((fin-inicio))\n",
    "                scores_fold.append(co_forest.score(X_test, y_test))\n",
    "\n",
    "            matriz_scores.append(scores_fold)\n",
    "            matriz_tiempos.append(times_fold)\n",
    "\n",
    "        ax['A'].plot(np.array([2, 3, 6, 10, 20, 40]), np.mean(np.array(\n",
    "            matriz_scores), axis=0), '-o', color=dataset_info[3], linewidth=1, label=dataset_info[1])\n",
    "        ax['B'].plot(np.array([2, 3, 6, 10, 20, 40]), np.mean(np.array(\n",
    "            matriz_tiempos), axis=0), '-o', color=dataset_info[3], linewidth=1, label=dataset_info[1])\n",
    "\n",
    "    ax['A'].set_ylabel('accuracy')\n",
    "    ax['A'].set_xlabel('número de árboles')\n",
    "    ax['B'].set_ylabel('tiempo (s)')\n",
    "    ax['B'].set_xlabel('número de árboles')\n",
    "    fig.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='lower center', ncol=4)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "# **COMPARES**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **(CF) against KEEL** 🍣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_keel(file_root, random_number, algorithm):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(1, 11):\n",
    "\n",
    "        file_train = file_root + \"{}tra.csv\".format(i)\n",
    "        file_test = file_root + \"{}tst.csv\".format(i)\n",
    "\n",
    "        L, L_tags, U = extract_training_data(file_train)\n",
    "        X_test, y_test = extract_test_data(file_test)\n",
    "\n",
    "        cls = create_base_cls(\n",
    "            algorithm, rd=np.random.RandomState(random_number))\n",
    "        cls.fit(L, L_tags, U)\n",
    "        results.append(cls.score(X_test, y_test))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **(TT) against LAMDA and SSlearn** 🍣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sslearn.wrapper import TriTraining as TriTrainingSSLearn\n",
    "from sslearn.wrapper import DemocraticCoLearning as DemocraticCoSSLearn\n",
    "from sslearn.model_selection import artificial_ssl_dataset\n",
    "from sslearn.base import get_dataset\n",
    "\n",
    "\n",
    "def graph_score_fold_sslearn(algorithm='TT', rd_number=5):\n",
    "\n",
    "    labels = ['SSLearn', 'Media SSLearn',\n",
    "              'Implementación propia', 'Media implementación propia']\n",
    "    x_labels = [i for i in range(1, 11)]\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3), tight_layout=True)\n",
    "    available = [(load_iris(return_X_y=True), 'Iris'),\n",
    "                 (load_digits(return_X_y=True), 'Dígitos'),\n",
    "                 (load_breast_cancer(return_X_y=True), 'Cáncer de mama')]\n",
    "    i = 0\n",
    "\n",
    "    for dataset in available:\n",
    "\n",
    "        X, y = dataset[0]\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "        results = []\n",
    "        results_mine = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            X_train_labels, y_train_labels, U, U_labels = artificial_ssl_dataset(\n",
    "                X_train, y_train, label_rate=0.2)\n",
    "\n",
    "            # SSLearn\n",
    "            if algorithm == 'TT':\n",
    "                model = TriTrainingSSLearn(random_state=rd).fit(X_train_labels, y_train_labels)\n",
    "            elif algorithm == 'DC':\n",
    "                model = DemocraticCoSSLearn(random_state=rd).fit(X_train_labels, y_train_labels)\n",
    "\n",
    "            results.append(model.score(X_test, y_test))\n",
    "\n",
    "            # Mio (misma función que usa él internamente)\n",
    "            model_mine = create_base_cls(algorithm, rd=rd)\n",
    "            X_mine, y_mine, U_mine = get_dataset(\n",
    "                X_train_labels, y_train_labels)\n",
    "            model_mine.fit(X_mine, y_mine, U_mine)\n",
    "            results_mine.append(model_mine.score(X_test, y_test))\n",
    "\n",
    "        ax_i = ax[i]\n",
    "        ax_i.set_ylim([0.5, 1.05])\n",
    "\n",
    "        mean = np.mean(results)\n",
    "        ax_i.plot(x_labels, results, '-o', color='#9467bd', linewidth=1)\n",
    "        ax_i.plot(x_labels, [mean for i in range(10)],\n",
    "                  '--', linewidth=1, color='#9467bd')\n",
    "\n",
    "        mean = np.mean(results_mine)\n",
    "        ax_i.plot(x_labels, results_mine, 'c-o', linewidth=1)\n",
    "        ax_i.plot(x_labels, [mean for i in range(10)], 'c--', linewidth=1)\n",
    "\n",
    "        ax_i.set_ylim([0.5, 1.05])\n",
    "        ax_i.set_ylabel('accuracy')\n",
    "        ax_i.set_xlabel('fold')\n",
    "        ax_i.set_title(dataset[1])\n",
    "        i += 1\n",
    "\n",
    "        break\n",
    "\n",
    "    fig.legend(labels, bbox_to_anchor=(0.5, 1.0), loc='lower center', ncol=4)\n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from LAMDA_SSL.Algorithm.Classification.Tri_Training import Tri_Training as TriTrainingLamda\n",
    "\n",
    "# def graph_score_fold_lamda(algorithm = 'TT', rd_number = 5):\n",
    "\n",
    "#     labels = ['LAMDA', 'Media LAMDA', 'Implementación propia', 'Media implementación propia']\n",
    "#     x_labels = [i for i in range(1,11)]\n",
    "#     rd = np.random.RandomState(rd_number)\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9,3), tight_layout=True)\n",
    "#     available = [   (load_iris(return_X_y=True), 'Iris'),\n",
    "#                     (load_digits(return_X_y=True), 'Dígitos'),\n",
    "#                     (load_breast_cancer(return_X_y=True), 'Cáncer de mama')]\n",
    "#     i = 0\n",
    "\n",
    "#     for dataset in available:\n",
    "\n",
    "#         X, y = dataset[0]\n",
    "#         skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "#         results = []\n",
    "#         results_mine = []\n",
    "\n",
    "#         for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "#             X_train, X_test = X[train_index], X[test_index]\n",
    "#             y_train, y_test = y[train_index], y[test_index]\n",
    "#             L_train, U_train, Ly_train, Uy_train = train_test_split(X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "\n",
    "#             # LAMDA\n",
    "#             model = TriTrainingLamda(DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier())\n",
    "#             model.fit(L_train, Ly_train, U_train)\n",
    "#             results.append(model.score(X_test, y_test))\n",
    "\n",
    "#             # Mio\n",
    "#             model_mine = TriTraining(DecisionTreeClassifier(), DecisionTreeClassifier(), DecisionTreeClassifier())\n",
    "#             model_mine.fit(L_train, Ly_train, U_train)\n",
    "#             results_mine.append(model_mine.score(X_test, y_test))\n",
    "\n",
    "#         ax_i = ax[i]\n",
    "\n",
    "#         mean = np.mean(results)\n",
    "#         ax_i.plot(x_labels, results, '-o', color = '#ff7f0e', linewidth=1)\n",
    "#         ax_i.plot(x_labels, [mean for i in range(10)], '--', color = '#ff7f0e', linewidth=1)\n",
    "\n",
    "#         mean = np.mean(results_mine)\n",
    "#         ax_i.plot(x_labels, results_mine, 'c-o', linewidth=1)\n",
    "#         ax_i.plot(x_labels, [mean for i in range(10)], 'c--', linewidth=1)\n",
    "\n",
    "#         ax_i.set_ylim([0.6, 1.05])\n",
    "#         ax_i.set_ylabel('accuracy')\n",
    "#         ax_i.set_xlabel('fold')\n",
    "#         ax_i.set_title(dataset[1])\n",
    "#         i += 1\n",
    "\n",
    "#     fig.legend(labels, bbox_to_anchor=(0.5, 1.0), loc='lower center', ncol=4)\n",
    "#     plt.plot()\n",
    "\n",
    "# graph_score_fold_lamda()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "# **RUN ALL** 🏃🏼‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(algorithm='CF'):\n",
    "\n",
    "    available = [(load_iris(return_X_y=True), 'Iris', 'B', '#2ca02c'),\n",
    "                 (load_digits(return_X_y=True), 'Dígitos', 'C', '#ff7f0e'),\n",
    "                 (load_wine(return_X_y=True), 'Vino', 'D', '#d62728'),\n",
    "                 (load_breast_cancer(return_X_y=True), 'Cáncer de mama', 'E', '#9467bd')]\n",
    "\n",
    "    # graph_number_elem_training_time(algorithm)\n",
    "    # score_percentage_training_instances(available, algorithm)\n",
    "    graph_score_iterations_train_mosaic(available, algorithm)\n",
    "\n",
    "    if algorithm == 'CF':\n",
    "        graph_coforest_score_time(available)\n",
    "        graph_init_w_compare(available, algorithm='CF', rd_number=5)\n",
    "        \n",
    "        results = graphs_keel(\"iris/iris-ssl-\", 5, 'CF')\n",
    "        print(\"IRIS vs KEEL: {}, mean: {}\".format(results, np.mean(results)))\n",
    "\n",
    "        results = graphs_keel(\"wine/wine-ssl10-10-\", 10, 'CF')\n",
    "        print(\"WINE vs KEEL: {}, mean: {}\".format(results, np.mean(results)))\n",
    "\n",
    "    else:\n",
    "        graph_score_fold_sslearn(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_all('DC')  # 'CF', 'TT, 'DC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def graph_init_w_compare(available, algorithm='CF', n_trees=6, rd_number=10):\n",
    "\n",
    "    fig, ax = plt.subplot_mosaic(\n",
    "        \"AAABBBCCC;AAABBBCCC\", figsize=(9, 3), tight_layout=True)\n",
    "    \n",
    "    letras = ['A', 'B', 'C']\n",
    "    metodos = ['percentage_L', 'confidence_L_all', 'confidence_L_thetha']\n",
    "    \n",
    "    max_iterations = 0\n",
    "    min_y = 1\n",
    "    max_y = 0\n",
    "\n",
    "    for dataset_info in available:\n",
    "\n",
    "        for letra in letras:\n",
    "            open('file_{}.csv'.format(letra), 'w').close()\n",
    "\n",
    "        X, y = dataset_info[0]\n",
    "        rd = { letra : deepcopy(np.random.RandomState(rd_number)) for letra in letras}\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=np.random.RandomState(rd_number))\n",
    "        fold_number = 0\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "            fold_number += 1\n",
    "            #print(\"**Dataset: {}. Fold number: {}**\".format(dataset_info[1], fold_number))\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            for letra, metodo in zip(letras, metodos):\n",
    "                L_train, U_train, Ly_train, Uy_train = train_test_split(\n",
    "                    X_train, y_train, test_size=0.8, random_state=rd[letra], stratify=y_train)\n",
    "                cls = create_base_cls(algorithm + 'G', n=n_trees, rd=rd[letra])\n",
    "\n",
    "                # print(\"------\")\n",
    "                # print(L_train)\n",
    "\n",
    "                # Test used to evaluate how score changes during training\n",
    "                cls.fit(L_train, Ly_train, U_train, X_test, y_test, w_init_criteria=metodo, file_name='file_{}.csv'.format(letra))\n",
    "\n",
    "\n",
    "        for letra in letras:\n",
    "            mean = np.mean(create_graph_matrix(\"file_{}.csv\".format(letra)), axis=0)\n",
    "            ax[letra].plot(mean, color=dataset_info[3],\n",
    "                             linewidth=1, label=dataset_info[1])\n",
    "            max_iterations = max(max_iterations, len(mean))\n",
    "            min_y = min(min_y, min(mean))\n",
    "            max_y = max(max_y, max(mean))\n",
    "\n",
    "    for metodo, letra in zip(metodos, letras):\n",
    "        ax[letra].set_title('{}'.format(metodo))\n",
    "        ax[letra].set_xticks([i for i in range(max_iterations)])\n",
    "        ax[letra].set_ylabel('accuracy')\n",
    "        ax[letra].set_xlabel('iteraciones')\n",
    "        ax[letra].set_ylim([min_y - 0.02, max_y + 0.02])\n",
    "\n",
    "        if max_iterations > 9:\n",
    "            ax[letra].xaxis.set_major_locator(ticker.MaxNLocator(7, integer=True))\n",
    "        elif max_iterations > 99:\n",
    "            ax[letra].xaxis.set_major_locator(ticker.MaxNLocator(6, integer=True))\n",
    "\n",
    "    fig.legend([di[1] for di in available], bbox_to_anchor=(\n",
    "        0.5, 1.0), loc='lower center', ncol=4)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available = [(load_iris(return_X_y=True), 'Iris', 'B', '#2ca02c'),\n",
    "                (load_digits(return_X_y=True), 'Dígitos', 'C', '#ff7f0e'),\n",
    "                (load_wine(return_X_y=True), 'Vino', 'D', '#d62728'),\n",
    "                (load_breast_cancer(return_X_y=True), 'Cáncer de mama', 'E', '#9467bd')]\n",
    "\n",
    "# for f in [10, 19, 13, 6, 2]:\n",
    "#     graph_init_w_compare(available, 'CF', n_trees=6, rd_number=f)\n",
    "#     graph_init_w_compare(available, 'CF', n_trees=20, rd_number=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aa2267a3633e362ab4cdc36738c6d0a45a450435ef5c859c0f11f93c27ebe6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
