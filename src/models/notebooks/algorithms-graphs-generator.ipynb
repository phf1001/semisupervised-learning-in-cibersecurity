{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*-coding:utf-8 -*-\n",
    "\"\"\"\n",
    "@File    :   algorithms-graphs-generator.ipynb\n",
    "@Time    :   2023/03/30 20:54:23\n",
    "@Author  :   Patricia Hernando Fernández \n",
    "@Version :   1.0\n",
    "@Contact :   phf1001@alu.ubu.es\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📈 **GRAPHS ALGORITHMS GENERATOR** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import (\n",
    "    load_iris,\n",
    "    load_digits,\n",
    "    load_wine,\n",
    "    load_breast_cancer,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from math import floor, ceil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Fallaba por la barra al final\n",
    "src_path = Path(os.path.dirname(os.path.abspath(\"__file__\"))).parent.parent\n",
    "sys.path.append(str(src_path) + os.sep)\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append((src_path + os.sep))\n",
    "\n",
    "from models.classifiers.CoForestClassifier import CoForest\n",
    "from models.classifiers.TriTrainingClassifier import TriTraining\n",
    "from models.classifiers.DemocraticCoClassifier import DemocraticCo\n",
    "from models.classifiers.utils import *\n",
    "from models.notebooks.graphs_utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **CLASSES**\n",
    "\n",
    "Fit methods needs to be overwritten since graphs are generated while training, so inheritance is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoForest_graphs(CoForest):\n",
    "    def fit(\n",
    "        self,\n",
    "        L,\n",
    "        y,\n",
    "        U,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        w_init_criteria=\"percentage_L\",\n",
    "        file_name=\"file.csv\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fits the ensemble using both labeled and\n",
    "        pseudo-labeled data. Generates graphs to show\n",
    "        how score evolves during training.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Tags of the labeled data used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "\n",
    "        mask_L = self.create_trees(L, y)\n",
    "        scores = [self.score(X_test, y_test)]\n",
    "\n",
    "        e = [0 for i in range(self.n)]\n",
    "        W = [0 for i in range(self.n)]\n",
    "\n",
    "        previous_e = [0.5 for i in range(self.n)]\n",
    "        previous_W = previous_W = self.initialize_previous_W(L, w_init_criteria)\n",
    "        # print(\"Method: {}. Previous W: {}\".format(w_init_criteria, [ '%.2f' % elem for elem in previous_W ]))\n",
    "\n",
    "        new_data = True\n",
    "        t = 0\n",
    "\n",
    "        while new_data:\n",
    "            t += 1\n",
    "            tree_changes = np.array([False for i in range(self.n)])\n",
    "            tree_pseudo_updates = [() for i in range(self.n)]\n",
    "\n",
    "            for i, hi in self.ensemble.items():\n",
    "                e[i] = self.concomitant_oob_error(hi, L, y, mask_L)\n",
    "                W[i] = previous_W[i]\n",
    "                pseudo_labeled_data = []\n",
    "                pseudo_labeled_tags = []\n",
    "\n",
    "                if e[i] < previous_e[i]:\n",
    "                    if e[i] == 0:\n",
    "                        Wmax = self.theta * U.shape[0]\n",
    "                    else:\n",
    "                        Wmax = min(\n",
    "                            self.theta * U.shape[0],\n",
    "                            ((previous_e[i] * previous_W[i]) / e[i]),\n",
    "                        )\n",
    "\n",
    "                    U_subsampled = self.subsample(hi, U, Wmax)\n",
    "                    W[i] = 0\n",
    "\n",
    "                    for u in U_subsampled:\n",
    "                        (\n",
    "                            concomitant_confidence,\n",
    "                            selected_class,\n",
    "                        ) = self.concomitant_confidence(hi, U[u, :])\n",
    "\n",
    "                        if concomitant_confidence > self.theta:\n",
    "                            tree_changes[i] = True\n",
    "                            pseudo_labeled_data.append(U[u, :])\n",
    "                            pseudo_labeled_tags.append(selected_class)\n",
    "                            W[i] += concomitant_confidence\n",
    "\n",
    "                tree_pseudo_updates[i] = (\n",
    "                    np.array(pseudo_labeled_data),\n",
    "                    np.array(pseudo_labeled_tags),\n",
    "                )\n",
    "\n",
    "            for i in np.fromiter(self.ensemble.keys(), dtype=int)[tree_changes]:\n",
    "                if e[i] * W[i] < previous_e[i] * previous_W[i]:\n",
    "                    self.retrain_tree(\n",
    "                        i,\n",
    "                        L,\n",
    "                        y,\n",
    "                        tree_pseudo_updates[i][0],\n",
    "                        tree_pseudo_updates[i][1],\n",
    "                        mask_L,\n",
    "                    )\n",
    "\n",
    "            previous_e = deepcopy(e)\n",
    "            previous_W = deepcopy(W)\n",
    "\n",
    "            if tree_changes.sum() == 0:\n",
    "                new_data = False\n",
    "\n",
    "            scores.append(self.score(X_test, y_test))\n",
    "\n",
    "        append_to_csv(file_name, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriTraining_graphs(TriTraining):\n",
    "    def fit(self, L, y, U, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Trains the tri-training ensemble using Zhi-Hua Zhou\n",
    "        Algorithm. Generates graphs to show how score\n",
    "        evolves during training.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Labeled data tags used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "\n",
    "        self.initialize_classifiers(L, y)\n",
    "        self.classes = np.unique(y)\n",
    "\n",
    "        previous_e = [0.5 for i in range(self.n)]\n",
    "        previous_l = [0.0 for i in range(self.n)]\n",
    "        e = [0.0 for i in range(self.n)]\n",
    "        new_data = True\n",
    "\n",
    "        t = 0\n",
    "        scores = [self.score(X_test, y_test)]\n",
    "\n",
    "        while new_data:\n",
    "            t += 1\n",
    "            cls_changes = np.array([False for i in range(self.n)])\n",
    "            cls_pseudo_updates = [() for i in range(self.n)]\n",
    "\n",
    "            for i in range(self.n):\n",
    "                e[i] = self.measure_error(i, L, y)\n",
    "\n",
    "                if e[i] < previous_e[i]:\n",
    "                    cls_pseudo_updates[i] = self.create_pseudolabeled_set(i, U)\n",
    "\n",
    "                    if previous_l[i] == 0:\n",
    "                        previous_l[i] = floor(\n",
    "                            (e[i] / (previous_e[i] - e[i])) + 1\n",
    "                        )\n",
    "\n",
    "                    L_i_size = cls_pseudo_updates[i][0].shape[0]\n",
    "\n",
    "                    if previous_l[i] < L_i_size:\n",
    "                        if e[i] * L_i_size < previous_e[i] * previous_l[i]:\n",
    "                            cls_changes[i] = True\n",
    "\n",
    "                        elif previous_l[i] > (e[i] / (previous_e[i] - e[i])):\n",
    "                            L_index = self.rd.choice(\n",
    "                                L_i_size,\n",
    "                                ceil(\n",
    "                                    (previous_e[i] * previous_l[i] / e[i]) - 1\n",
    "                                ),\n",
    "                            )\n",
    "                            cls_pseudo_updates[i] = (\n",
    "                                cls_pseudo_updates[i][0][L_index, :],\n",
    "                                cls_pseudo_updates[i][1][L_index],\n",
    "                            )\n",
    "                            cls_changes[i] = True\n",
    "\n",
    "            if cls_changes.sum() == 0:\n",
    "                new_data = False\n",
    "\n",
    "            else:\n",
    "                for i in np.fromiter(self.classifiers.keys(), dtype=int)[\n",
    "                    cls_changes\n",
    "                ]:\n",
    "                    X_train = np.concatenate((L, cls_pseudo_updates[i][0]))\n",
    "                    y_train = np.concatenate((y, cls_pseudo_updates[i][1]))\n",
    "                    self.classifiers[i] = self.classifiers[i].fit(\n",
    "                        X_train, y_train\n",
    "                    )\n",
    "\n",
    "                    previous_e[i] = e[i]\n",
    "                    # Tamaño de Li anterior\n",
    "                    previous_l[i] = cls_pseudo_updates[i][0].shape[0]\n",
    "\n",
    "                scores.append(self.score(X_test, y_test))\n",
    "\n",
    "        append_to_csv(\"file.csv\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemocraticCo_graphs(DemocraticCo):\n",
    "    def fit(self, L, y, U, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Trains the democratic-Co.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Labeled data tags used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        X_test: np.array\n",
    "            samples to check evolution\n",
    "        y_test: np.array\n",
    "            labels of samples to check evolution\n",
    "        \"\"\"\n",
    "        classes = np.unique(y)\n",
    "        self.classes = classes\n",
    "        changes = True\n",
    "\n",
    "        e = [0] * self.n\n",
    "        L_ = [(list(L), list(y)) for i in range(self.n)]\n",
    "        U_in_L_ = [dict() for i in range(self.n)]\n",
    "        cls_changes = np.ones(self.n, dtype=bool)\n",
    "\n",
    "        t = 0\n",
    "        scores = []\n",
    "\n",
    "        while changes:\n",
    "            for i in np.arange(self.n)[cls_changes]:\n",
    "                self.classifiers[i] = self.classifiers[i].fit(*L_[i])\n",
    "            cls_changes = np.zeros(self.n, dtype=bool)\n",
    "\n",
    "            U_tag_votes = [{i: set() for i in self.classes} for x in U]\n",
    "            U_y = []\n",
    "\n",
    "            for x_id, x in enumerate(U):\n",
    "                for id_cls, cls in self.classifiers.items():\n",
    "                    prediction = cls.predict([x])[0]\n",
    "                    U_tag_votes[x_id][prediction].add(id_cls)\n",
    "\n",
    "                U_y.append(\n",
    "                    max(\n",
    "                        U_tag_votes[x_id],\n",
    "                        key=lambda k: len(U_tag_votes[x_id].get(k)),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Choose which exs to propose for labeling\n",
    "            w = [self.get_w(cls, L, y) for cls in self.classifiers.values()]\n",
    "            L_prime = [([], []) for i in range(self.n)]\n",
    "            Li_prime_ids = [[] for i in range(self.n)]\n",
    "\n",
    "            for x_id, x in enumerate(U):\n",
    "                most_voted_tag = U_y[x_id]\n",
    "                cls_agree_tag = U_tag_votes[x_id][most_voted_tag]\n",
    "\n",
    "                exp_1 = 0\n",
    "                for cls in cls_agree_tag:\n",
    "                    exp_1 += w[cls]\n",
    "\n",
    "                exp_2 = 0\n",
    "                for tag in classes:\n",
    "                    if tag != most_voted_tag:\n",
    "                        weight_tag = 0\n",
    "                        for cls in U_tag_votes[x_id][tag]:\n",
    "                            weight_tag += w[cls]\n",
    "                        exp_2 = max(exp_2, weight_tag)\n",
    "\n",
    "                if exp_1 > exp_2:\n",
    "                    for id_cls in set(self.classifiers.keys()) - cls_agree_tag:\n",
    "                        Li_prime, y_Li_prime = L_prime[id_cls]\n",
    "                        Li_prime.append(x)\n",
    "                        y_Li_prime.append(U_y[x_id])\n",
    "                        Li_prime_ids[id_cls].append(x_id)\n",
    "\n",
    "            # Estimate if adding this is better\n",
    "            l_mean = 0\n",
    "            for id_cls, cls in self.classifiers.items():\n",
    "                l_mean += confidence_interval(\n",
    "                    cls, L_[id_cls][0], L_[id_cls][1]\n",
    "                )[0]\n",
    "            l_mean /= self.n\n",
    "\n",
    "            for i in range(self.n):\n",
    "                Li, y_Li = L_[i]\n",
    "                Li_prime, y_Li_prime = L_prime[i]\n",
    "                Li_union_Li_prime = Li + Li_prime\n",
    "\n",
    "                q_i = len(Li) * (1 - 2 * (e[i] / len(Li))) ** 2\n",
    "                e_i_prime = (1 - l_mean) * len(Li_prime)\n",
    "                q_i_prime = (\n",
    "                    len(Li_union_Li_prime)\n",
    "                    * (1 - (2 * (e[i] + e_i_prime) / len(Li_union_Li_prime)))\n",
    "                    ** 2\n",
    "                )\n",
    "\n",
    "                if q_i_prime > q_i:\n",
    "                    cls_changes[i] = True\n",
    "                    e[i] = e[i] + e_i_prime\n",
    "\n",
    "                    for x_id, x, y_x in zip(\n",
    "                        Li_prime_ids[i], Li_prime, y_Li_prime\n",
    "                    ):\n",
    "                        if x_id in U_in_L_[i]:\n",
    "                            index = U_in_L_[i][x_id]\n",
    "                            y_Li[index] = y_x\n",
    "\n",
    "                        else:\n",
    "                            U_in_L_[i][x_id] = len(Li)\n",
    "                            Li.append(x)\n",
    "                            y_Li.append(y_x)\n",
    "\n",
    "            if cls_changes.sum() == 0:\n",
    "                changes = False\n",
    "                self.w = [\n",
    "                    self.get_w(cls, L, y) for cls in self.classifiers.values()\n",
    "                ]\n",
    "\n",
    "            self.w = [\n",
    "                self.get_w(cls, L, y) for cls in self.classifiers.values()\n",
    "            ]\n",
    "            scores.append(self.score(X_test, y_test))\n",
    "            t += 1\n",
    "\n",
    "        append_to_csv(\"file.csv\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_cls(\n",
    "    algorithm,\n",
    "    n=6,\n",
    "    thetha=0.75,\n",
    "    max_features=\"log2\",\n",
    "    base_cls=None,\n",
    "    rd=np.random.RandomState(10),\n",
    "):\n",
    "    if base_cls is None:\n",
    "        base_cls = [\n",
    "            DecisionTreeClassifier(),\n",
    "            GaussianNB(),\n",
    "            KNeighborsClassifier(n_neighbors=3),\n",
    "        ]\n",
    "\n",
    "    if algorithm == \"CF\":\n",
    "        return CoForest(n, thetha, max_features, random_state=rd)\n",
    "\n",
    "    elif algorithm == \"CFG\":\n",
    "        return CoForest_graphs(n, thetha, max_features, random_state=rd)\n",
    "\n",
    "    elif algorithm == \"TT\":\n",
    "        return TriTraining(base_cls[0], base_cls[1], base_cls[2], rd)\n",
    "\n",
    "    elif algorithm == \"TTG\":\n",
    "        return TriTraining_graphs(base_cls[0], base_cls[1], base_cls[2], rd)\n",
    "\n",
    "    elif algorithm == \"DC\":\n",
    "        return DemocraticCo(base_cls, rd)\n",
    "\n",
    "    elif algorithm == \"DCG\":\n",
    "        return DemocraticCo_graphs(base_cls, rd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "# **GENERAL GRAPHS**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "### **score - número de iteraciones (entrenamiento)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_score_iterations_train_mosaic(available, algorithm=\"CF\", rd_number=5):\n",
    "    \"\"\"Graphs the evolution of the accuracy during the training phase.\n",
    "\n",
    "    Args:\n",
    "        available (list): List of tuples with the datasets to use.\n",
    "        algorithm (str, optional): Algorithm string. Defaults to \"CF\".\n",
    "        rd_number (int, optional): Random seed. Defaults to 5.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplot_mosaic(\n",
    "        \"AAABBCC;AAADDEE\", figsize=(10, 4.5), tight_layout=True\n",
    "    )\n",
    "    ax[\"A\"].set_ylabel(\"accuracy\")\n",
    "    ax[\"A\"].set_xlabel(\"iteraciones\")\n",
    "\n",
    "    fig_2, ax_2 = plt.subplot_mosaic(\n",
    "        \"AAAAAAA;AAAAAAA\", figsize=(10, 4.5), tight_layout=True\n",
    "    )\n",
    "    ax_2[\"A\"].set_ylabel(\"accuracy\")\n",
    "    ax_2[\"A\"].set_xlabel(\"iteraciones\")\n",
    "\n",
    "    max_iterations = 0\n",
    "\n",
    "    for dataset_info in available:\n",
    "        open(\"file.csv\", \"w\").close()\n",
    "        X, y = dataset_info[0]\n",
    "        rd = np.random.RandomState(rd_number)\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            L_train, U_train, Ly_train, _ = train_test_split(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                test_size=0.8,\n",
    "                random_state=rd,\n",
    "                stratify=y_train,\n",
    "            )\n",
    "            cls = create_base_cls(algorithm + \"G\", n=20, rd=rd)\n",
    "            # Test used to evaluate how score changes during training\n",
    "            cls.fit(L_train, Ly_train, U_train, X_test, y_test)\n",
    "\n",
    "        mean = np.mean(create_graph_matrix(\"file.csv\"), axis=0)\n",
    "        std = np.std(create_graph_matrix(\"file.csv\"), axis=0)\n",
    "\n",
    "        x_ticks = [i for i in range(len(mean))]\n",
    "        ax[\"A\"].plot(\n",
    "            mean, color=dataset_info[3], linewidth=1, label=dataset_info[1]\n",
    "        )  #'-o',\n",
    "        ax_2[\"A\"].plot(\n",
    "            mean, color=dataset_info[3], linewidth=1, label=dataset_info[1]\n",
    "        )  #'-o',\n",
    "\n",
    "        ax_i = ax[dataset_info[2]]\n",
    "        ax_i.set_ylim([0.7, 1.05])\n",
    "        ax_i.set_ylabel(\"accuracy\")\n",
    "        ax_i.set_xlabel(\"iteraciones\")\n",
    "        ax_i.set_xticks(x_ticks)\n",
    "        ax_i.errorbar(\n",
    "            x_ticks,\n",
    "            mean,\n",
    "            yerr=[std, np.minimum(std, 1 - mean)],\n",
    "            color=dataset_info[3],\n",
    "            linewidth=0.5,\n",
    "            label=dataset_info[1],\n",
    "        )  # fmt='-o',\n",
    "        max_iterations = max(max_iterations, len(x_ticks))\n",
    "\n",
    "        if len(mean) > 9:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(7))\n",
    "        elif len(mean) > 99:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(6))\n",
    "        elif len(mean) > 999:\n",
    "            ax_i.xaxis.set_major_locator(ticker.MaxNLocator(5))\n",
    "\n",
    "    ax[\"A\"].set_xticks([i for i in range(max_iterations)])\n",
    "    ax_2[\"A\"].set_xticks([i for i in range(max_iterations)])\n",
    "\n",
    "    if max_iterations > 9:\n",
    "        ax[\"A\"].xaxis.set_major_locator(ticker.MaxNLocator(10))\n",
    "        ax_2[\"A\"].xaxis.set_major_locator(ticker.MaxNLocator(20))\n",
    "    elif max_iterations > 99:\n",
    "        ax[\"A\"].xaxis.set_major_locator(ticker.MaxNLocator(8))\n",
    "        ax_2[\"A\"].xaxis.set_major_locator(ticker.MaxNLocator(16))\n",
    "    elif max_iterations > 999:\n",
    "        ax[\"A\"].xaxis.set_major_locator(ticker.MaxNLocator(7))\n",
    "        ax_2[\"A\"].xaxis.set_major_locator(ticker.MaxNLocator(14))\n",
    "\n",
    "    fig.legend(\n",
    "        [di[1] for di in available],\n",
    "        bbox_to_anchor=(0.5, 1.0),\n",
    "        loc=\"lower center\",\n",
    "        ncol=4,\n",
    "    )\n",
    "\n",
    "    fig_2.legend(\n",
    "        [di[1] for di in available],\n",
    "        bbox_to_anchor=(0.5, 1.0),\n",
    "        loc=\"lower center\",\n",
    "        ncol=4,\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "### **número elementos - tiempo entrenamiento**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_number_elem_training_time(algorithm=\"CF\", rd_number=10):\n",
    "    \"\"\"Graphs the evolution of time with respect to the number of instances.\n",
    "\n",
    "    Args:\n",
    "        algorithm (str, optional): algorithm to use. Defaults to \"CF\".\n",
    "        rd_number (int, optional): random seed. Defaults to 10.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "\n",
    "    instancias = []\n",
    "    tiempos = []\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "\n",
    "    for i in range(500, X.shape[0], 100):\n",
    "        indexes = rd.choice(X.shape[0], replace=False, size=i)\n",
    "        L_train, U_train, Ly_train, _ = train_test_split(\n",
    "            X[indexes], y[indexes], test_size=0.8, random_state=rd\n",
    "        )\n",
    "\n",
    "        cls = create_base_cls(algorithm, n=20, rd=rd)\n",
    "        inicio = time.time()\n",
    "        cls.fit(L_train, Ly_train, U_train)\n",
    "        fin = time.time()\n",
    "        instancias.append(i)\n",
    "        tiempos.append((fin - inicio))\n",
    "\n",
    "    ax.scatter(instancias, tiempos, color=\"r\")\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.array([[i] for i in instancias]), tiempos)\n",
    "    x_new = np.linspace(425, X.shape[0], 100)\n",
    "    y_new = model.predict(x_new[:, np.newaxis])\n",
    "\n",
    "    # plt.title(\"Instancias - Tiempo entrenamiento\")\n",
    "    ax.set_ylim(bottom=0)\n",
    "    ax.plot(x_new, y_new, \"--k\")\n",
    "    ax.set_xlabel(\"instancias\")\n",
    "    ax.set_ylabel(\"tiempo (s)\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------\n",
    "### **score - % instancias entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_percentage_training_instances(\n",
    "    available, algorithm=\"CF\", rd_number=5, n_experiments=10\n",
    "):\n",
    "    \"\"\"Plots the evolution of accurary depending on the percentage\n",
    "    of the dataset used for training.\n",
    "\n",
    "    Args:\n",
    "        available (list): datasets to use.\n",
    "        algorithm (str, optional): algorithm to test. Defaults to \"CF\".\n",
    "        rd_number (int, optional): random seed. Defaults to 5.\n",
    "        n_experiments (int, optional): number of times. Defaults to 10.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "\n",
    "    for dataset_info in available:\n",
    "        matriz_scores = []\n",
    "        X, y = dataset_info[0]\n",
    "\n",
    "        for j in range(n_experiments):\n",
    "            scores_experimento = []\n",
    "\n",
    "            for i in np.arange(0.5, 1, 0.1):\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, train_size=i, random_state=rd, stratify=y\n",
    "                )\n",
    "                L_train, U_train, Ly_train, _ = train_test_split(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    test_size=0.8,\n",
    "                    random_state=rd,\n",
    "                    stratify=y_train,\n",
    "                )\n",
    "                cls = create_base_cls(algorithm, n=20, rd=rd)\n",
    "                cls.fit(L_train, Ly_train, U_train)\n",
    "                scores_experimento.append(cls.score(X_test, y_test))\n",
    "            matriz_scores.append(scores_experimento)\n",
    "\n",
    "        ax.plot(\n",
    "            np.arange(0.5, 1, 0.1),\n",
    "            np.mean(np.array(matriz_scores), axis=0),\n",
    "            \"-o\",\n",
    "            color=dataset_info[3],\n",
    "            linewidth=1,\n",
    "            label=dataset_info[1],\n",
    "        )\n",
    "\n",
    "    # plt.title(\"Score - % Instancias\")\n",
    "    ax.set_ylabel(\"score\")\n",
    "    ax.set_xlabel(\"instancias (%)\")\n",
    "    fig.legend(\n",
    "        [di[1] for di in available],\n",
    "        bbox_to_anchor=(0.5, 1.0),\n",
    "        loc=\"upper center\",\n",
    "        ncol=4,\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "### **coforest (especiales): scores & tiempo - número de árboles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_coforest_score_time(available):\n",
    "    \"\"\"Graphs coforest evolution changing the number of trees.\n",
    "\n",
    "    Args:\n",
    "        available (list): datasets information.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplot_mosaic(\"AABB;AABB\", figsize=(8, 4), tight_layout=True)\n",
    "\n",
    "    for dataset_info in available:\n",
    "        X, y = dataset_info[0]\n",
    "        rd = np.random.RandomState(5)\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "        matriz_scores = []\n",
    "        matriz_tiempos = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            L_train, U_train, Ly_train, _ = train_test_split(\n",
    "                X_train,\n",
    "                y_train,\n",
    "                test_size=0.8,\n",
    "                random_state=rd,\n",
    "                stratify=y_train,\n",
    "            )\n",
    "            scores_fold = []\n",
    "            times_fold = []\n",
    "\n",
    "            for j in [2, 3, 6, 10, 20, 40]:\n",
    "                co_forest = CoForest(j, 0.75, \"log2\", rd)\n",
    "                inicio = time.time()\n",
    "                co_forest.fit(L_train, Ly_train, U_train)\n",
    "                fin = time.time()\n",
    "                times_fold.append((fin - inicio))\n",
    "                scores_fold.append(co_forest.score(X_test, y_test))\n",
    "\n",
    "            matriz_scores.append(scores_fold)\n",
    "            matriz_tiempos.append(times_fold)\n",
    "\n",
    "        ax[\"A\"].plot(\n",
    "            np.array([2, 3, 6, 10, 20, 40]),\n",
    "            np.mean(np.array(matriz_scores), axis=0),\n",
    "            \"-o\",\n",
    "            color=dataset_info[3],\n",
    "            linewidth=1,\n",
    "            label=dataset_info[1],\n",
    "        )\n",
    "        ax[\"B\"].plot(\n",
    "            np.array([2, 3, 6, 10, 20, 40]),\n",
    "            np.mean(np.array(matriz_tiempos), axis=0),\n",
    "            \"-o\",\n",
    "            color=dataset_info[3],\n",
    "            linewidth=1,\n",
    "            label=dataset_info[1],\n",
    "        )\n",
    "\n",
    "    ax[\"A\"].set_ylabel(\"accuracy\")\n",
    "    ax[\"A\"].set_xlabel(\"número de árboles\")\n",
    "    ax[\"B\"].set_ylabel(\"tiempo (s)\")\n",
    "    ax[\"B\"].set_xlabel(\"número de árboles\")\n",
    "    fig.legend(\n",
    "        [di[1] for di in available],\n",
    "        bbox_to_anchor=(0.5, 1.0),\n",
    "        loc=\"lower center\",\n",
    "        ncol=4,\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "### **coforest (especiales): inicialización de previous w**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def graph_init_w_compare(available, algorithm=\"CF\", n_trees=6, rd_number=10):\n",
    "    \"\"\"Plots the evolution of the accuracy during training using different\n",
    "    ways of initializing the w vector.\n",
    "\n",
    "    Args:\n",
    "        available (list): dataset information.\n",
    "        algorithm (str, optional): defaults to \"CF\".\n",
    "        n_trees (int, optional): number of trees. Defaults to 6.\n",
    "        rd_number (int, optional): random seed. Defaults to 10.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplot_mosaic(\n",
    "        \"AAABBBCCC;AAABBBCCC\", figsize=(9, 3), tight_layout=True\n",
    "    )\n",
    "\n",
    "    letras = [\"A\", \"B\", \"C\"]\n",
    "    metodos = [\"percentage_L\", \"confidence_L_all\", \"confidence_L_thetha\"]\n",
    "\n",
    "    max_iterations = 0\n",
    "    min_y = 1\n",
    "    max_y = 0\n",
    "\n",
    "    for dataset_info in available:\n",
    "        for letra in letras:\n",
    "            open(\"file_{}.csv\".format(letra), \"w\").close()\n",
    "\n",
    "        X, y = dataset_info[0]\n",
    "        rd = {\n",
    "            letra: deepcopy(np.random.RandomState(rd_number))\n",
    "            for letra in letras\n",
    "        }\n",
    "        skf = StratifiedKFold(\n",
    "            n_splits=10,\n",
    "            shuffle=True,\n",
    "            random_state=np.random.RandomState(rd_number),\n",
    "        )\n",
    "        fold_number = 0\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            fold_number += 1\n",
    "            # print(\"**Dataset: {}. Fold number: {}**\".format(dataset_info[1], fold_number))\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            for letra, metodo in zip(letras, metodos):\n",
    "                L_train, U_train, Ly_train, _ = train_test_split(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    test_size=0.8,\n",
    "                    random_state=rd[letra],\n",
    "                    stratify=y_train,\n",
    "                )\n",
    "                cls = create_base_cls(algorithm + \"G\", n=n_trees, rd=rd[letra])\n",
    "\n",
    "                # print(\"------\")\n",
    "                # print(L_train)\n",
    "\n",
    "                # Test used to evaluate how score changes during training\n",
    "                cls.fit(\n",
    "                    L_train,\n",
    "                    Ly_train,\n",
    "                    U_train,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    w_init_criteria=metodo,\n",
    "                    file_name=\"file_{}.csv\".format(letra),\n",
    "                )\n",
    "\n",
    "        for letra in letras:\n",
    "            mean = np.mean(\n",
    "                create_graph_matrix(\"file_{}.csv\".format(letra)), axis=0\n",
    "            )\n",
    "            ax[letra].plot(\n",
    "                mean, color=dataset_info[3], linewidth=1, label=dataset_info[1]\n",
    "            )\n",
    "            max_iterations = max(max_iterations, len(mean))\n",
    "            min_y = min(min_y, min(mean))\n",
    "            max_y = max(max_y, max(mean))\n",
    "\n",
    "    for metodo, letra in zip(metodos, letras):\n",
    "        ax[letra].set_title(\"{}\".format(metodo))\n",
    "        ax[letra].set_xticks([i for i in range(max_iterations)])\n",
    "        ax[letra].set_ylabel(\"accuracy\")\n",
    "        ax[letra].set_xlabel(\"iteraciones\")\n",
    "        ax[letra].set_ylim([min_y - 0.02, max_y + 0.02])\n",
    "\n",
    "        if max_iterations > 9:\n",
    "            ax[letra].xaxis.set_major_locator(\n",
    "                ticker.MaxNLocator(7, integer=True)\n",
    "            )\n",
    "        elif max_iterations > 99:\n",
    "            ax[letra].xaxis.set_major_locator(\n",
    "                ticker.MaxNLocator(6, integer=True)\n",
    "            )\n",
    "\n",
    "    fig.legend(\n",
    "        [di[1] for di in available],\n",
    "        bbox_to_anchor=(0.5, 1.0),\n",
    "        loc=\"lower center\",\n",
    "        ncol=4,\n",
    "    )\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "# **COMPARES**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **(CF) against KEEL** 🍣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_keel(file_root, random_number, algorithm):\n",
    "    \"\"\"Prints the scores against KEEL.\n",
    "\n",
    "    Args:\n",
    "        file_root (str): file's first name string\n",
    "        random_number (int): random number\n",
    "        algorithm (str): algorithm's name\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for i in range(1, 11):\n",
    "        file_train = file_root + \"{}tra.csv\".format(i)\n",
    "        file_test = file_root + \"{}tst.csv\".format(i)\n",
    "\n",
    "        L, L_tags, U = extract_training_data(file_train)\n",
    "        X_test, y_test = extract_test_data(file_test)\n",
    "\n",
    "        cls = create_base_cls(\n",
    "            algorithm, rd=np.random.RandomState(random_number)\n",
    "        )\n",
    "        cls.fit(L, L_tags, U)\n",
    "        results.append(cls.score(X_test, y_test))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **(TT) against LAMDA and SSlearn** 🍣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sslearn.wrapper import TriTraining as TriTrainingSSLearn\n",
    "from sslearn.wrapper import DemocraticCoLearning as DemocraticCoSSLearn\n",
    "from sslearn.model_selection import artificial_ssl_dataset\n",
    "from sslearn.base import get_dataset\n",
    "\n",
    "\n",
    "def graph_score_fold_sslearn(algorithm=\"TT\", rd_number=5):\n",
    "    \"\"\"Plots the comparation graph against sslearn.\n",
    "\n",
    "    Args:\n",
    "        algorithm (str, optional): Algorithm string. Defaults to \"TT\".\n",
    "        rd_number (int, optional): Random seed. Defaults to 5.\n",
    "    \"\"\"\n",
    "    labels = [\n",
    "        \"SSLearn\",\n",
    "        \"Media SSLearn\",\n",
    "        \"Implementación propia\",\n",
    "        \"Media implementación propia\",\n",
    "    ]\n",
    "    x_labels = [i for i in range(1, 11)]\n",
    "    rd = np.random.RandomState(rd_number)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3), tight_layout=True)\n",
    "    available = [\n",
    "        (load_iris(return_X_y=True), \"Iris\"),\n",
    "        (load_digits(return_X_y=True), \"Dígitos\"),\n",
    "        (load_breast_cancer(return_X_y=True), \"Cáncer de mama\"),\n",
    "    ]\n",
    "    i = 0\n",
    "\n",
    "    for dataset in available:\n",
    "        X, y = dataset[0]\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "        results = []\n",
    "        results_mine = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            (\n",
    "                X_train_labels,\n",
    "                y_train_labels,\n",
    "                U,\n",
    "                U_labels,\n",
    "            ) = artificial_ssl_dataset(X_train, y_train, label_rate=0.2)\n",
    "\n",
    "            # SSLearn\n",
    "            if algorithm == \"TT\":\n",
    "                model = TriTrainingSSLearn(random_state=rd).fit(\n",
    "                    X_train_labels, y_train_labels\n",
    "                )\n",
    "            elif algorithm == \"DC\":\n",
    "                model = DemocraticCoSSLearn(random_state=rd).fit(\n",
    "                    X_train_labels, y_train_labels\n",
    "                )\n",
    "\n",
    "            results.append(model.score(X_test, y_test))\n",
    "\n",
    "            # Mio (misma función que usa él internamente)\n",
    "            model_mine = create_base_cls(algorithm, rd=rd)\n",
    "            X_mine, y_mine, U_mine = get_dataset(X_train_labels, y_train_labels)\n",
    "            model_mine.fit(X_mine, y_mine, U_mine)\n",
    "            results_mine.append(model_mine.score(X_test, y_test))\n",
    "\n",
    "        ax_i = ax[i]\n",
    "        ax_i.set_ylim([0.5, 1.05])\n",
    "\n",
    "        mean = np.mean(results)\n",
    "        ax_i.plot(x_labels, results, \"-o\", color=\"#9467bd\", linewidth=1)\n",
    "        ax_i.plot(\n",
    "            x_labels,\n",
    "            [mean for i in range(10)],\n",
    "            \"--\",\n",
    "            linewidth=1,\n",
    "            color=\"#9467bd\",\n",
    "        )\n",
    "\n",
    "        mean = np.mean(results_mine)\n",
    "        ax_i.plot(x_labels, results_mine, \"c-o\", linewidth=1)\n",
    "        ax_i.plot(x_labels, [mean for i in range(10)], \"c--\", linewidth=1)\n",
    "\n",
    "        ax_i.set_ylim([0.5, 1.05])\n",
    "        ax_i.set_ylabel(\"accuracy\")\n",
    "        ax_i.set_xlabel(\"fold\")\n",
    "        ax_i.set_title(dataset[1])\n",
    "        i += 1\n",
    "\n",
    "    fig.legend(labels, bbox_to_anchor=(0.5, 1.0), loc=\"lower center\", ncol=4)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from LAMDA_SSL.Algorithm.Classification.Tri_Training import (\n",
    "#     Tri_Training as TriTrainingLamda,\n",
    "# )\n",
    "\n",
    "\n",
    "# def graph_score_fold_lamda(algorithm=\"TT\", rd_number=5):\n",
    "#     \"\"\"Plots the comparation graph against LAMDA.\n",
    "\n",
    "#     Args:\n",
    "#         algorithm (str, optional): Algorithm string. Defaults to \"TT\".\n",
    "#         rd_number (int, optional): Random seed. Defaults to 5.\n",
    "#     \"\"\"\n",
    "#     labels = [\n",
    "#         \"LAMDA\",\n",
    "#         \"Media LAMDA\",\n",
    "#         \"Implementación propia\",\n",
    "#         \"Media implementación propia\",\n",
    "#     ]\n",
    "#     x_labels = [i for i in range(1, 11)]\n",
    "#     rd = np.random.RandomState(rd_number)\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3), tight_layout=True)\n",
    "#     available = [\n",
    "#         (load_iris(return_X_y=True), \"Iris\"),\n",
    "#         (load_digits(return_X_y=True), \"Dígitos\"),\n",
    "#         (load_breast_cancer(return_X_y=True), \"Cáncer de mama\"),\n",
    "#     ]\n",
    "#     i = 0\n",
    "\n",
    "#     for dataset in available:\n",
    "#         X, y = dataset[0]\n",
    "#         skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "#         results = []\n",
    "#         results_mine = []\n",
    "\n",
    "#         for train_index, test_index in skf.split(X, y):\n",
    "#             X_train, X_test = X[train_index], X[test_index]\n",
    "#             y_train, y_test = y[train_index], y[test_index]\n",
    "#             L_train, U_train, Ly_train, _ = train_test_split(\n",
    "#                 X_train,\n",
    "#                 y_train,\n",
    "#                 test_size=0.8,\n",
    "#                 random_state=rd,\n",
    "#                 stratify=y_train,\n",
    "#             )\n",
    "\n",
    "#             # LAMDA\n",
    "#             model = TriTrainingLamda(\n",
    "#                 DecisionTreeClassifier(),\n",
    "#                 DecisionTreeClassifier(),\n",
    "#                 DecisionTreeClassifier(),\n",
    "#             )\n",
    "#             model.fit(L_train, Ly_train, U_train)\n",
    "#             results.append(model.score(X_test, y_test))\n",
    "\n",
    "#             # Mio\n",
    "#             model_mine = TriTraining(\n",
    "#                 DecisionTreeClassifier(),\n",
    "#                 DecisionTreeClassifier(),\n",
    "#                 DecisionTreeClassifier(),\n",
    "#             )\n",
    "#             model_mine.fit(L_train, Ly_train, U_train)\n",
    "#             results_mine.append(model_mine.score(X_test, y_test))\n",
    "\n",
    "#         ax_i = ax[i]\n",
    "\n",
    "#         mean = np.mean(results)\n",
    "#         ax_i.plot(x_labels, results, \"-o\", color=\"#ff7f0e\", linewidth=1)\n",
    "#         ax_i.plot(\n",
    "#             x_labels,\n",
    "#             [mean for i in range(10)],\n",
    "#             \"--\",\n",
    "#             color=\"#ff7f0e\",\n",
    "#             linewidth=1,\n",
    "#         )\n",
    "\n",
    "#         mean = np.mean(results_mine)\n",
    "#         ax_i.plot(x_labels, results_mine, \"c-o\", linewidth=1)\n",
    "#         ax_i.plot(x_labels, [mean for i in range(10)], \"c--\", linewidth=1)\n",
    "\n",
    "#         ax_i.set_ylim([0.6, 1.05])\n",
    "#         ax_i.set_ylabel(\"accuracy\")\n",
    "#         ax_i.set_xlabel(\"fold\")\n",
    "#         ax_i.set_title(dataset[1])\n",
    "#         i += 1\n",
    "\n",
    "#     fig.legend(labels, bbox_to_anchor=(0.5, 1.0), loc=\"lower center\", ncol=4)\n",
    "#     plt.plot()\n",
    "\n",
    "\n",
    "# graph_score_fold_lamda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "# **RUN ALL** 🏃🏼‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(algorithm=\"CF\"):\n",
    "    \"\"\"Runs all the graphs.\n",
    "\n",
    "    Args:\n",
    "        algorithm (str, optional): Algorithm string. Defaults to \"CF\".\n",
    "    \"\"\"\n",
    "    available = [\n",
    "        (load_iris(return_X_y=True), \"Iris\", \"B\", \"#2ca02c\"),\n",
    "        (load_digits(return_X_y=True), \"Dígitos\", \"C\", \"#ff7f0e\"),\n",
    "        (load_wine(return_X_y=True), \"Vino\", \"D\", \"#d62728\"),\n",
    "        (load_breast_cancer(return_X_y=True), \"Cáncer de mama\", \"E\", \"#9467bd\"),\n",
    "    ]\n",
    "\n",
    "    # graph_number_elem_training_time(algorithm)\n",
    "    # score_percentage_training_instances(available, algorithm)\n",
    "    graph_score_iterations_train_mosaic(available, algorithm)\n",
    "\n",
    "    if algorithm == \"CF\":\n",
    "        graph_coforest_score_time(available)\n",
    "        # graph_init_w_compare(available, 'CF', n_trees=6, rd_number=f)\n",
    "        # graph_init_w_compare(available, 'CF', n_trees=20, rd_number=f)\n",
    "\n",
    "        results = graphs_keel(\"iris/iris-ssl-\", 5, \"CF\")\n",
    "        print(\"IRIS vs KEEL: {}, mean: {}\".format(results, np.mean(results)))\n",
    "\n",
    "        results = graphs_keel(\"wine/wine-ssl10-10-\", 10, \"CF\")\n",
    "        print(\"WINE vs KEEL: {}, mean: {}\".format(results, np.mean(results)))\n",
    "\n",
    "    else:\n",
    "        graph_score_fold_sslearn(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_all('DC')  # 'CF', 'TT, 'DC'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aa2267a3633e362ab4cdc36738c6d0a45a450435ef5c859c0f11f93c27ebe6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
