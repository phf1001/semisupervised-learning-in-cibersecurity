{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numbers\n",
    "from copy import deepcopy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_digits, load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemocraticCo:  \n",
    "\n",
    "    def __init__(self, base_cls, random_state=None):\n",
    "        \"\"\"\n",
    "        Constructor. Creates the co-training instance.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        base_cls:\n",
    "            Classifiers\n",
    "        random_state:\n",
    "            Random object or seed\n",
    "        \"\"\"\n",
    "        \n",
    "        self.n = len(base_cls)\n",
    "        self.classes = []\n",
    "        self.rd = self.check_random_state(random_state)\n",
    "        self.classifiers = {i: base_cls[i] for i in range(self.n)}\n",
    "\n",
    "\n",
    "    def fit(self, L, y, U):\n",
    "        \"\"\"\n",
    "        Trains the Democratic-Co.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Labeled data tags used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        \"\"\"\n",
    "\n",
    "        classes = np.unique(y)\n",
    "        self.classes = classes\n",
    "\n",
    "        e = [0.0 for i in range(self.n)]\n",
    "        q = [0.0 for i in range(self.n)]\n",
    "        e_prime = [0.0 for i in range(self.n)]\n",
    "        q_prime = [0.0 for i in range(self.n)]\n",
    "\n",
    "        cls_updates = [(list(L), list(y)) for i in range(self.n)]\n",
    "        cls_proposed_updates = [([], []) for i in range(self.n)]\n",
    "        changes = True\n",
    "\n",
    "        while changes:\n",
    "\n",
    "            hyps = deepcopy(self.classifiers)\n",
    "            cls_changes = np.array([False for i in range(self.n)])\n",
    "\n",
    "            for i in range(self.n):\n",
    "                X_train, y_train = cls_updates[i]\n",
    "                hyps[i] = hyps[i].fit(X_train, y_train)\n",
    "\n",
    "            matrix = [[set() for j in range(len(self.classes))] for x in range(len(U))]\n",
    "\n",
    "            for x in range(len(U)):\n",
    "                for i in range(self.n):\n",
    "                    j = hyps[i].predict([U[x]])[0]\n",
    "                    c = matrix[x][j]\n",
    "                    c.add(i)\n",
    "                    matrix[x][j] = c\n",
    "\n",
    "            y_U = []\n",
    "            for x in matrix:\n",
    "                x = [len(c) for c in x]\n",
    "                n_max = np.amax(x)\n",
    "                y_U.append(x.index(n_max))\n",
    "\n",
    "            # Choose which exs to propose for labeling\n",
    "            w = []\n",
    "            for i in range(self.n):\n",
    "                li, hi = self.confidence_interval(hyps[i], L, y)\n",
    "                w.append((li + hi) / 2)\n",
    "                \n",
    "            cls_proposed_updates = [([], []) for i in range(self.n)]\n",
    "\n",
    "            for x in range(len(U)):\n",
    "\n",
    "                voted_tag = y_U[x]\n",
    "                index = np.where(classes == voted_tag)[0][0]\n",
    "                cls_agree_tag = matrix[x][index]\n",
    "\n",
    "                a1 = 0  #sumatorio de los que coinciden por sus pesos\n",
    "                for cls in cls_agree_tag:\n",
    "                    a1 += w[cls]\n",
    "\n",
    "                a2 = 0\n",
    "                for tag in classes:\n",
    "                    if tag != voted_tag:\n",
    "                        index = np.where(classes == tag)[0][0]\n",
    "\n",
    "                        weight_tag = 0\n",
    "                        for cls in matrix[x][index]:\n",
    "                            weight_tag += w[cls]\n",
    "                        a2 = max(a2, weight_tag)\n",
    "\n",
    "                if a1 > a2:\n",
    "                    for cls in (set(self.classifiers.keys()) - cls_agree_tag):\n",
    "                        Li_prime, y_Li_prime = cls_proposed_updates[i]\n",
    "                        Li_prime.append(U[x])\n",
    "                        y_Li_prime.append(y_U[x])\n",
    "                        cls_proposed_updates[i] = (Li_prime, y_Li_prime)\n",
    "\n",
    "\n",
    "            # Estimate if adding this is better\n",
    "            for i in range(self.n):\n",
    "\n",
    "                l = []\n",
    "                for j in range(self.n):\n",
    "                    Lj, y_Lj = cls_updates[j]\n",
    "                    lj, hj = self.confidence_interval(hyps[j], Lj, y_Lj)\n",
    "                    l.append(lj)\n",
    "\n",
    "                Li, y_Li = cls_updates[i]\n",
    "                Li_prime, y_Li_prime = cls_proposed_updates[i]\n",
    "\n",
    "                if len(Li_prime) > 0:\n",
    "                    Li_union_Li_prime = Li + Li_prime\n",
    "                else:\n",
    "                    Li_union_Li_prime = Li\n",
    "\n",
    "                q[i] = len(Li) * (1 - 2 * (e[i] / len(Li))) ** 2\n",
    "                e_prime[i] = (1 - np.mean(l)) * len(Li_prime)\n",
    "                q_prime[i] = len(Li_union_Li_prime) * ( 1 - (2*(e[i] + e_prime[i]) / len(Li_union_Li_prime)) ) ** 2\n",
    "\n",
    "                if q_prime[i] > q[i]:\n",
    "                    cls_changes[i] = True\n",
    "                    cls_updates[i] = (Li_union_Li_prime, y_Li + y_Li_prime)\n",
    "                    e[i] = e[i] + e_prime[i]\n",
    "\n",
    "        \n",
    "            if cls_changes.sum() == 0:\n",
    "                changes = False\n",
    "\n",
    "    def confidence_interval(self, cls, L, y):\n",
    "        \n",
    "        y_pred = cls.predict(L)\n",
    "        hits = (y_pred == y)\n",
    "\n",
    "        n_total = len(y)\n",
    "        n_hits = hits.sum()\n",
    "        p_hat = n_hits / n_total\n",
    "        margin = 1.96 * math.sqrt( p_hat * (1 - p_hat) / n_total)\n",
    "\n",
    "        return (p_hat - margin, p_hat + margin)\n",
    "\n",
    "\n",
    "    def check_random_state(self, seed=None):\n",
    "        \"\"\"\n",
    "        Turn seed into a np.random.RandomState instance.\n",
    "        Source: SkLearn\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : None, int or instance of RandomState\n",
    "            If None, return the RandomState singleton.\n",
    "            If int, return a new RandomState seeded with seed.\n",
    "            If RandomState instance, return it.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.random.RandomState\n",
    "            The random state object based on seed parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        if seed is None or seed is np.random:\n",
    "            return np.random.mtrand._rand\n",
    "\n",
    "        if isinstance(seed, numbers.Integral):\n",
    "            return np.random.RandomState(seed)\n",
    "\n",
    "        if isinstance(seed, np.random.RandomState):\n",
    "            return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0 = DecisionTreeClassifier()\n",
    "h_1 = GaussianNB()\n",
    "h_2 = KNeighborsClassifier()\n",
    "\n",
    "dataset = load_wine()\n",
    "\n",
    "X = np.array(dataset.data)\n",
    "y = np.array(dataset.target)\n",
    "\n",
    "rd = np.random.RandomState(5)\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        L_train, U_train, Ly_train, Uy_train = train_test_split(X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m democratic_co \u001b[39m=\u001b[39m DemocraticCo([h_0, h_1, h_2], random_state\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m democratic_co\u001b[39m.\u001b[39;49mfit(L_train, Ly_train, U_train)\n",
      "Cell \u001b[1;32mIn [48], line 113\u001b[0m, in \u001b[0;36mDemocraticCo.fit\u001b[1;34m(self, L, y, U)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn):\n\u001b[0;32m    112\u001b[0m     Lj, y_Lj \u001b[39m=\u001b[39m cls_updates[j]\n\u001b[1;32m--> 113\u001b[0m     lj, hj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfidence_interval(hyps[j], Lj, y_Lj)\n\u001b[0;32m    114\u001b[0m     l\u001b[39m.\u001b[39mappend(lj)\n\u001b[0;32m    116\u001b[0m Li, y_Li \u001b[39m=\u001b[39m cls_updates[i]\n",
      "Cell \u001b[1;32mIn [48], line 139\u001b[0m, in \u001b[0;36mDemocraticCo.confidence_interval\u001b[1;34m(self, cls, L, y)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfidence_interval\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mcls\u001b[39m, L, y):\n\u001b[1;32m--> 139\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(L)\n\u001b[0;32m    140\u001b[0m     hits \u001b[39m=\u001b[39m (y_pred \u001b[39m==\u001b[39m y)\n\u001b[0;32m    142\u001b[0m     n_total \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(y)\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\sklearn\\tree\\_classes.py:505\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    504\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[0;32m    506\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m    507\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\sklearn\\tree\\_classes.py:471\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> 471\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    472\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    473\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[0;32m    474\u001b[0m     ):\n\u001b[0;32m    475\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "democratic_co = DemocraticCo([h_0, h_1, h_2], random_state=5)\n",
    "democratic_co.fit(L_train, Ly_train, U_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
