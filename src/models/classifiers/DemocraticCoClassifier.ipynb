{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numbers\n",
    "from copy import deepcopy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_digits, load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DemocraticCo:\n",
    "\n",
    "    def __init__(self, base_cls, random_state=None):\n",
    "        \"\"\"\n",
    "        Constructor. Creates the democratic-co instance.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_cls:\n",
    "            Classifiers\n",
    "        random_state:\n",
    "            Random object or seed\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = len(base_cls)\n",
    "        self.classes = []\n",
    "        self.rd = self.check_random_state(random_state)\n",
    "        self.classifiers = {i: base_cls[i] for i in range(self.n)}\n",
    "        self.w = []\n",
    "\n",
    "    def fit(self, L, y, U):\n",
    "        \"\"\"\n",
    "        Trains the democratic-Co.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        L: np.array\n",
    "            Labeled data used for training\n",
    "        y: np.array\n",
    "            Labeled data tags used for training\n",
    "        U: np.array\n",
    "            Unlabeled data used for training\n",
    "        \"\"\"\n",
    "\n",
    "        classes = np.unique(y)\n",
    "        self.classes = classes\n",
    "        changes = True\n",
    "\n",
    "        e = [0.0 for i in range(self.n)]\n",
    "        q = [0.0 for i in range(self.n)]\n",
    "        e_prime = [0.0 for i in range(self.n)]\n",
    "        q_prime = [0.0 for i in range(self.n)]\n",
    "        cls_updates = [(list(L), list(y)) for i in range(self.n)]\n",
    "\n",
    "        while changes:\n",
    "\n",
    "            cls_changes = np.array([False for i in range(self.n)])\n",
    "\n",
    "            for i in range(self.n):\n",
    "                X_train, y_train = cls_updates[i]\n",
    "                self.classifiers[i] = self.classifiers[i].fit(X_train, y_train)\n",
    "\n",
    "            U_tag_votes = [{i: set() for i in self.classes} for x in U]\n",
    "            U_y = []\n",
    "\n",
    "            for x in range(len(U)):\n",
    "                for id_cls, cls in self.classifiers.items():\n",
    "                    prediction = cls.predict([U[x]])[0]\n",
    "                    U_tag_votes[x][prediction].add(id_cls)\n",
    "\n",
    "                U_y.append(max(U_tag_votes[x], key=lambda k: len(U_tag_votes[x].get(k))))\n",
    "\n",
    "            # Choose which exs to propose for labeling\n",
    "            w = [self.get_w(cls, L, y) for cls in self.classifiers.values()]\n",
    "            cls_proposed_updates = [([], []) for i in range(self.n)]\n",
    "\n",
    "            for x in range(len(U)):\n",
    "\n",
    "                most_voted_tag = U_y[x]\n",
    "                cls_agree_tag = U_tag_votes[x][most_voted_tag]\n",
    "\n",
    "                exp_1 = 0\n",
    "                for cls in cls_agree_tag:\n",
    "                    exp_1 += w[cls]\n",
    "\n",
    "                exp_2 = 0\n",
    "                for tag in classes:\n",
    "                    if tag != most_voted_tag:\n",
    "                        weight_tag = 0\n",
    "                        for cls in U_tag_votes[x][tag]:\n",
    "                            weight_tag += w[cls]\n",
    "                        exp_2 = max(exp_2, weight_tag)\n",
    "\n",
    "                if exp_1 > exp_2:\n",
    "                    for id_cls in (set(self.classifiers.keys()) - cls_agree_tag):\n",
    "                        Li_prime, y_Li_prime = cls_proposed_updates[id_cls]\n",
    "                        Li_prime.append(U[x])\n",
    "                        y_Li_prime.append(U_y[x])\n",
    "                        cls_proposed_updates[id_cls] = (Li_prime, y_Li_prime)\n",
    "\n",
    "            # Estimate if adding this is better\n",
    "            for i in range(self.n):\n",
    "\n",
    "                l = [self.confidence_interval_cesar(cls, cls_updates[id_cls][0], cls_updates[id_cls][1])[\n",
    "                    0] for id_cls, cls in self.classifiers.items()]\n",
    "\n",
    "                Li, y_Li = cls_updates[i]\n",
    "                Li_prime, y_Li_prime = cls_proposed_updates[i]\n",
    "                Li_union_Li_prime = Li + Li_prime\n",
    "\n",
    "                q[i] = len(Li) * (1 - 2 * (e[i] / len(Li))) ** 2\n",
    "                e_prime[i] = (1 - np.mean(l)) * len(Li_prime)\n",
    "                q_prime[i] = len(\n",
    "                    Li_union_Li_prime) * (1 - (2*(e[i] + e_prime[i]) / len(Li_union_Li_prime))) ** 2\n",
    "\n",
    "                if q_prime[i] > q[i]:\n",
    "                    cls_changes[i] = True\n",
    "                    cls_updates[i] = (Li_union_Li_prime, y_Li + y_Li_prime)\n",
    "                    e[i] = e[i] + e_prime[i]\n",
    "\n",
    "            if cls_changes.sum() == 0:\n",
    "                changes = False\n",
    "                self.w = [self.get_w(cls, L, y)\n",
    "                          for cls in self.classifiers.values()]\n",
    "                \n",
    "\n",
    "    def get_w(self, cls, L, y):\n",
    "        \"\"\"\n",
    "        Returns the weight of a given classifier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cls:\n",
    "            classifier\n",
    "        L: np.array\n",
    "            Labeled data\n",
    "        y: np.array\n",
    "            Labeled data tags\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            weight of the classifier\n",
    "        \"\"\"\n",
    "        \n",
    "        li, hi = self.confidence_interval_cesar(cls, L, y)\n",
    "        return ((li + hi) / 2)\n",
    "\n",
    "\n",
    "    def confidence_interval_cesar(self, cls, L, y):\n",
    "        \"\"\"\n",
    "        Returns the 95% confidence interval for a classifier\n",
    "        given certain data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cls:\n",
    "            classifier\n",
    "        L: np.array\n",
    "            Labeled data\n",
    "        y: np.array\n",
    "            Labeled data tags\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple\n",
    "            Confidence interval\n",
    "        \"\"\"\n",
    "\n",
    "        y_pred = cls.predict(L)\n",
    "        n_total = len(y)\n",
    "        n_hits = (y_pred == y).sum()\n",
    "        p_hat = n_hits / n_total\n",
    "        margin = 1.96 * math.sqrt(p_hat * (1 - p_hat) / n_total)\n",
    "\n",
    "        return (p_hat - margin, p_hat + margin)\n",
    "\n",
    "\n",
    "    def confidence_interval_alvar(self, cls, L, y):\n",
    "        \"\"\"\n",
    "        Returns the 95% confidence interval for a classifier\n",
    "        given certain data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cls:\n",
    "            classifier\n",
    "        L: np.array\n",
    "            Labeled data\n",
    "        y: np.array\n",
    "            Labeled data tags\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple\n",
    "            Confidence interval\n",
    "        \"\"\"\n",
    "\n",
    "        y_pred = cls.predict(L)\n",
    "        n_total = len(y)\n",
    "        n_hits = (y_pred == y).sum()\n",
    "\n",
    "        zSq = 1.96 * 1.96\n",
    "        f = n_hits / n_total\n",
    "\n",
    "        left = f + (zSq / (2 * n_total))\n",
    "        div = 1 + (zSq / n_total)\n",
    "        sq = 1.96 * math.sqrt((f / n_total) -\n",
    "                              ((f * f) / n_total) + (zSq / (4 * n_total ** 2)))\n",
    "\n",
    "        return ((left - sq) / div, (left + sq) / div)\n",
    "\n",
    "\n",
    "    def check_random_state(self, seed=None):\n",
    "        \"\"\"\n",
    "        Turn seed into a np.random.RandomState instance.\n",
    "        Source: SkLearn\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        seed : None, int or instance of RandomState\n",
    "            If None, return the RandomState singleton.\n",
    "            If int, return a new RandomState seeded with seed.\n",
    "            If RandomState instance, return it.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        numpy.random.RandomState\n",
    "            The random state object based on seed parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        if seed is None or seed is np.random:\n",
    "            return np.random.mtrand._rand\n",
    "\n",
    "        if isinstance(seed, numbers.Integral):\n",
    "            return np.random.RandomState(seed)\n",
    "\n",
    "        if isinstance(seed, np.random.RandomState):\n",
    "            return seed\n",
    "\n",
    "\n",
    "    def predict(self, samples):\n",
    "        \"\"\"\n",
    "        Returns the labels predicted by the democratic-co\n",
    "        for a given data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        samples: np_array\n",
    "            samples to predict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array:\n",
    "            labels predicted by democratic-co\n",
    "        \"\"\"\n",
    "\n",
    "        samples = (lambda x: np.expand_dims(x, axis=0)\n",
    "                   if x.ndim == 1 else x)(samples)\n",
    "        return np.array([self.single_predict(sample) for sample in samples])\n",
    "\n",
    "\n",
    "    def single_predict(self, sample):\n",
    "        \"\"\"\n",
    "        Returns the class predicted by democratic-co.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample: np_array\n",
    "            sample to predict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array:\n",
    "            label predicted by democratic-co\n",
    "        \"\"\"\n",
    "\n",
    "        groups = {i: set() for i in self.classes}\n",
    "\n",
    "        for id_cls, cls in self.classifiers.items():\n",
    "            if self.w[id_cls] > 0.5:\n",
    "                prediction = cls.predict([sample])[0]\n",
    "                groups[prediction].add(id_cls)\n",
    "\n",
    "        max_confidence = -1\n",
    "        chosen_tag = None\n",
    "\n",
    "        for j, group in groups.items():\n",
    "\n",
    "            n_cls = len(group)\n",
    "            if n_cls > 0:\n",
    "                group_weight = 0\n",
    "                for id_cls in group:\n",
    "                    group_weight += self.w[id_cls]\n",
    "\n",
    "                average_confidence = (\n",
    "                    (n_cls + 0.5) / (n_cls + 1)) * (group_weight / n_cls)\n",
    "\n",
    "                if average_confidence > max_confidence:\n",
    "                    max_confidence = average_confidence\n",
    "                    chosen_tag = j\n",
    "\n",
    "        return chosen_tag\n",
    "\n",
    "\n",
    "    def single_predict_proba(self, sample):\n",
    "        \"\"\"\n",
    "        Returns the probability for each class \n",
    "        predicted by democratic-co for a given sample.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sample: np_array\n",
    "            sample to predict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array:\n",
    "            array containing probability for each class.\n",
    "        \"\"\"\n",
    "\n",
    "        count = {i: 0 for i in self.classes}\n",
    "\n",
    "        for id_cls, cls in self.classifiers.items():\n",
    "            if self.w[id_cls] > 0.5:\n",
    "                prediction = cls.predict([sample])[0]\n",
    "                count[prediction] += 1\n",
    "\n",
    "        votes = np.array(list(count.values()))\n",
    "        return votes / self.n\n",
    "\n",
    "\n",
    "    def predict_proba(self, samples: np.array):\n",
    "        \"\"\"\n",
    "        Returns the probabilities predicted by \n",
    "        democratic-co for a given data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        samples: np_array\n",
    "            samples to predict\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array:\n",
    "            array containing one array for each\n",
    "            sample with probabilities for each \n",
    "            class.\n",
    "        \"\"\"\n",
    "\n",
    "        samples = (lambda x: np.expand_dims(x, axis=0)\n",
    "                   if x.ndim == 1 else x)(samples)\n",
    "        return np.array([self.single_predict_proba(sample) for sample in samples])\n",
    "\n",
    "\n",
    "    def score(self, X, y_true):\n",
    "        \"\"\"\n",
    "        Calculates the number of hits by democratic-co.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np_array\n",
    "            Samples to predict\n",
    "        y: np_array\n",
    "            True tags\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float:\n",
    "            percentage of hits.\n",
    "        \"\"\"\n",
    "        y_predictions = self.predict(X)\n",
    "        return np.count_nonzero(y_predictions == y_true)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0 = DecisionTreeClassifier()\n",
    "h_1 = GaussianNB()\n",
    "h_2 = KNeighborsClassifier()\n",
    "\n",
    "dataset = load_wine()\n",
    "\n",
    "X = np.array(dataset.data)\n",
    "y = np.array(dataset.target)\n",
    "\n",
    "rd = np.random.RandomState(5)\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=rd)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        L_train, U_train, Ly_train, Uy_train = train_test_split(X_train, y_train, test_size=0.8, random_state=rd, stratify=y_train)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "democratic_co = DemocraticCo([h_0, h_1, h_2], random_state=5)\n",
    "democratic_co.fit(L_train, Ly_train, U_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.33333333, 0.66666667, 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.66666667, 0.33333333, 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.33333333, 0.66666667],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.66666667, 0.33333333],\n",
       "       [0.        , 0.33333333, 0.66666667],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "democratic_co.predict(X_test)\n",
    "democratic_co.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
