{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå≥ **CO-FOREST** üå≥\n",
    "\n",
    "##### **Autora: Patricia Hernando Fern√°ndez**\n",
    "\n",
    "En proceso..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Co_Forest:\n",
    "\n",
    "    def __init__(self, DL, U, n, sigma, n_class_types):\n",
    "        \"\"\"\n",
    "        objetos de pandas, tanto L, como L_tags, como U\n",
    "        DL -> Tupla (L, L_tags)\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n\n",
    "        self.sigma = sigma\n",
    "        self.n_class_types = n_class_types\n",
    "\n",
    "        self.ensemble = self.create_trees(DL) \n",
    "        self.fit(DL, U)\n",
    "\n",
    "\n",
    "    def create_trees(self, DL):\n",
    "        # keys: trees, values: L ignored during training\n",
    "        ensemble = {}\n",
    "        L, L_tags = DL\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            #cambiar valores tama√±o a entrenar (est√° forzado para entrenar con pocos y que salte el error)\n",
    "            X_train_h, X_ignore_h, y_train_h, y_ignore_h = train_test_split(L, L_tags, test_size=random.uniform(0.30, 0.50)) #CAMBIAR POR BOOTSTRAP\n",
    "            h = DecisionTreeClassifier()\n",
    "            h.fit(X_train_h.values, y_train_h.values)\n",
    "            ensemble[h] = X_ignore_h.values #Cambiar a tuplas y hacer conjunto? hasheable para O(1)...\n",
    "\n",
    "        return ensemble\n",
    "\n",
    "\n",
    "    def fit(self, DL, U):\n",
    "\n",
    "                # x = U.sample().values[0]\n",
    "                # print(\"Error (todo L para los no entrenados con esos L): {}; Confidence (en una muestra de U): {}\".format(self.calculate_e(hi, DL), self.confidence(hi, x, self.n_class_types)))\n",
    "        L = DL[0]\n",
    "        e_anterior = [0.5 for i in range(self.n)]\n",
    "        W_anterior = [ min(0.1*len(L), 100) for i in range(self.n) ]\n",
    "\n",
    "        \n",
    "\n",
    "        t = 0\n",
    "        new_data = True\n",
    "        \n",
    "        #ojito claves diccionario movidas de sitio (conc ensm)\n",
    "        while new_data:\n",
    "            t += 1\n",
    "            DLP_i_t = []\n",
    "\n",
    "            for hi in self.ensemble.keys():\n",
    "\n",
    "                e = self.calculate_e(hi, DL)\n",
    "                LP = set()\n",
    "                LP_tags = set()\n",
    "\n",
    "                if e < e_anterior[i]:\n",
    "                    UP = self.subsamble(U, hi, 0.5)\n",
    "                    W = 0\n",
    "\n",
    "                    for x in UP:\n",
    "                        confidence, selected_class = self.confidence(hi, x)\n",
    "\n",
    "                        if confidence > self.sigma:\n",
    "                            LP.add(x)\n",
    "                            LP_tags.add(selected_class)\n",
    "                            W += confidence\n",
    "\n",
    "                    DLP_i_t.append((LP, LP_tags))\n",
    "            \n",
    "\n",
    "            for i in range(self.n):\n",
    "\n",
    "                if len(DLP_i_t[i][0]) > 0:\n",
    "                    self.retrain_tree(hi, DL, DLP_i_t[i])\n",
    "\n",
    "\n",
    "    def retrain_tree(self, hi, DL, DLP):\n",
    "        \n",
    "        X_ignored = self.ensemble[hi]\n",
    "\n",
    "        L = DL[0].values\n",
    "        L_tags = DL[1].values\n",
    "\n",
    "        LP, LP_tags = DLP\n",
    "\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "\n",
    "        for i in range(len(L)):\n",
    "\n",
    "            if L[i] not in X_ignored:\n",
    "                X_train.append(L[i])\n",
    "                y_train.append(L_tags[i])\n",
    "\n",
    "        for i in range(len(LP)):\n",
    "            X_train.append(LP[i])\n",
    "            y_train.append(LP_tags[i])\n",
    "\n",
    "        hi.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    def subsample(self, U, hi, size):\n",
    "        #TO-DO\n",
    "        return train_test_split(U, test_size=size)\n",
    "\n",
    "\n",
    "    def calculate_e(self, hi, DL):\n",
    "\n",
    "        sum_errores = total_dl_voted = 0\n",
    "        DL_zip = zip(DL[0].values, DL[1].values) #Tuplas ([array features], int clase)\n",
    "\n",
    "        for d in DL_zip:\n",
    "\n",
    "            x, tag = d\n",
    "            n_votes = n_hits = 0 \n",
    "\n",
    "            for tree, ignored in self.ensemble.items():\n",
    "\n",
    "                if tree != hi and x in ignored:\n",
    "\n",
    "                    pred = hi.predict([x])[0]\n",
    "\n",
    "                    if pred == tag:\n",
    "                        n_hits += 1\n",
    "                    n_votes +=1\n",
    "\n",
    "            if (n_votes > 0):\n",
    "                ex = 1 - (n_hits/n_votes)\n",
    "                sum_errores += ex\n",
    "                total_dl_voted += 1\n",
    "\n",
    "        if total_dl_voted > 0:\n",
    "            return sum_errores/total_dl_voted\n",
    "\n",
    "        else:\n",
    "            return 1 #No se ha votado, se repite -> CAMBIAR POR EXCEPCI√ìN\n",
    "\n",
    "\n",
    "    def confidence(self, hi, x):\n",
    "\n",
    "        count = {}\n",
    "\n",
    "        for i in range(self.n_class_types):\n",
    "            count[i] = 0\n",
    "\n",
    "        for tree in self.ensemble.keys():\n",
    "\n",
    "            if tree != hi:\n",
    "                prediction = tree.predict([x])[0]\n",
    "                count[prediction] += 1\n",
    "\n",
    "        #max_agreement = max(count.values())\n",
    "\n",
    "        max_agreement = most_agreed_class = -1\n",
    "\n",
    "        for key, value in count.items():\n",
    "            if value > max_agreement:\n",
    "                most_agreed_class = key\n",
    "                max_agreement = value\n",
    "\n",
    "        confidence = max_agreement/(len(self.ensemble) -1)\n",
    "\n",
    "        return confidence, most_agreed_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "data=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "\n",
    "#data.head()\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']] \n",
    "y=data['species']\n",
    "n_class_types = len(iris.target_names)\n",
    "\n",
    "#X_train, X_test, y_train, y_test\n",
    "L, U, L_tags, U_tags = train_test_split(X, y, test_size=0.2)\n",
    "DL = (L, L_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n",
      "hola\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m coforest \u001b[39m=\u001b[39m Co_Forest(DL, U, \u001b[39m5\u001b[39;49m, \u001b[39m0.75\u001b[39;49m, n_class_types)\n",
      "Cell \u001b[1;32mIn [18], line 14\u001b[0m, in \u001b[0;36mCo_Forest.__init__\u001b[1;34m(self, DL, U, n, sigma, n_class_types)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_class_types \u001b[39m=\u001b[39m n_class_types\n\u001b[0;32m     13\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensemble \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_trees(DL) \n\u001b[1;32m---> 14\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(DL, U)\n",
      "Cell \u001b[1;32mIn [18], line 51\u001b[0m, in \u001b[0;36mCo_Forest.fit\u001b[1;34m(self, DL, U)\u001b[0m\n\u001b[0;32m     47\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m hi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensemble\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m---> 51\u001b[0m     ei_actual \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_e(hi, DL)\n\u001b[0;32m     52\u001b[0m     LP \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m ei_actual \u001b[39m<\u001b[39m e_anterior[i]:\n",
      "Cell \u001b[1;32mIn [18], line 72\u001b[0m, in \u001b[0;36mCo_Forest.calculate_e\u001b[1;34m(self, hi, DL)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m tree, ignored \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensemble\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m tree \u001b[39m!=\u001b[39m hi \u001b[39mand\u001b[39;00m x \u001b[39min\u001b[39;00m ignored:\n\u001b[1;32m---> 72\u001b[0m         pred \u001b[39m=\u001b[39m hi\u001b[39m.\u001b[39;49mpredict([x])[\u001b[39m0\u001b[39m]\n\u001b[0;32m     74\u001b[0m         \u001b[39mif\u001b[39;00m pred \u001b[39m==\u001b[39m tag:\n\u001b[0;32m     75\u001b[0m             n_hits \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\sklearn\\tree\\_classes.py:505\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    504\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[0;32m    506\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m    507\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\sklearn\\tree\\_classes.py:471\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> 471\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    472\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    473\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[0;32m    474\u001b[0m     ):\n\u001b[0;32m    475\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "coforest = Co_Forest(DL, U, 5, 0.75, n_class_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
