{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ³ **CO-FOREST** ðŸŒ³\n",
    "\n",
    "##### **Autora: Patricia Hernando FernÃ¡ndez**\n",
    "\n",
    "En proceso..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "### **IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CLASS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Co_Forest:\n",
    "\n",
    "    def __init__(self, DL, U, n, sigma, n_class_types):\n",
    "        \"\"\"\n",
    "        objetos de pandas, tanto L, como L_tags, como U\n",
    "        DL -> Tupla (L, L_tags)\n",
    "        \"\"\"\n",
    "\n",
    "        self.n = n\n",
    "        self.sigma = sigma\n",
    "        self.n_class_types = n_class_types\n",
    "\n",
    "        self.ensemble = self.create_trees(DL) \n",
    "        self.fit(DL, U)\n",
    "\n",
    "\n",
    "    def create_trees(self, DL):\n",
    "        # keys: trees, values: L ignored during training\n",
    "        ensemble = {}\n",
    "        L, L_tags = DL\n",
    "\n",
    "        for i in range(self.n):\n",
    "\n",
    "            #cambiar valores tamaÃ±o a entrenar (estÃ¡ forzado para entrenar con pocos y que salte el error)\n",
    "            X_train_h, X_ignore_h, y_train_h, y_ignore_h = train_test_split(L, L_tags, test_size=random.uniform(0.30, 0.50)) #CAMBIAR POR BOOTSTRAP\n",
    "            h = DecisionTreeClassifier()\n",
    "            h.fit(X_train_h.values, y_train_h.values)\n",
    "            ensemble[h] = X_ignore_h.values #Cambiar a tuplas y hacer conjunto? hasheable para O(1)...\n",
    "\n",
    "        return ensemble\n",
    "\n",
    "\n",
    "    def fit(self, DL, U):\n",
    "\n",
    "        L = DL[0]\n",
    "        e_anterior = [0.5 for i in range(self.n)]\n",
    "        W = [ min(0.1*len(L), 100) for i in range(self.n) ]\n",
    "\n",
    "        t = 0\n",
    "        new_data = True\n",
    "        \n",
    "        #ojito claves diccionario movidas de sitio (conc ensm)\n",
    "        while new_data:\n",
    "            t += 1\n",
    "            i = 0\n",
    "\n",
    "            for hi in self.ensemble.keys():\n",
    "\n",
    "                x = U.sample().values[0]\n",
    "                print(\"Error (todo L para los no entrenados con esos L): {}; Confidence (en una muestra de U): {}\".format(self.calculate_e(hi, DL), self.confidence(hi, x, self.n_class_types)))\n",
    "        \n",
    "            break #QUITAR\n",
    "\n",
    "\n",
    "    def calculate_e(self, hi, DL):\n",
    "\n",
    "        sum_errores = total_dl_voted = 0\n",
    "        DL_zip = zip(DL[0].values, DL[1].values) #Tuplas ([array features], int clase)\n",
    "\n",
    "        for d in DL_zip:\n",
    "\n",
    "            x, tag = d\n",
    "            n_votes = n_hits = 0 \n",
    "\n",
    "            for tree, ignored in self.ensemble.items():\n",
    "\n",
    "                if tree != hi and x in ignored:\n",
    "\n",
    "                    pred = hi.predict([x])[0]\n",
    "\n",
    "                    if pred == tag:\n",
    "                        n_hits += 1\n",
    "                    n_votes +=1\n",
    "\n",
    "            if (n_votes > 0):\n",
    "                ex = 1 - (n_hits/n_votes)\n",
    "                sum_errores += ex\n",
    "                total_dl_voted += 1\n",
    "\n",
    "        if total_dl_voted > 0:\n",
    "            return sum_errores/total_dl_voted\n",
    "\n",
    "        else:\n",
    "            return 1 #No se ha votado, se repite -> CAMBIAR POR EXCEPCIÃ“N\n",
    "\n",
    "\n",
    "    def confidence(self, hi, x, n_class_types):\n",
    "\n",
    "        count = {}\n",
    "\n",
    "        for i in range(n_class_types):\n",
    "            count[i] = 0\n",
    "\n",
    "        for tree in self.ensemble.keys():\n",
    "\n",
    "            if tree != hi:\n",
    "                prediction = tree.predict([x])[0]\n",
    "                count[prediction] += 1\n",
    "\n",
    "        max_agreement = max(count.values())\n",
    "        confidence = max_agreement/(len(self.ensemble) -1)\n",
    "\n",
    "        return confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "data=pd.DataFrame({\n",
    "    'sepal length':iris.data[:,0],\n",
    "    'sepal width':iris.data[:,1],\n",
    "    'petal length':iris.data[:,2],\n",
    "    'petal width':iris.data[:,3],\n",
    "    'species':iris.target\n",
    "})\n",
    "\n",
    "#data.head()\n",
    "X=data[['sepal length', 'sepal width', 'petal length', 'petal width']] \n",
    "y=data['species']\n",
    "n_class_types = len(iris.target_names)\n",
    "\n",
    "#X_train, X_test, y_train, y_test\n",
    "L, U, L_tags, U_tags = train_test_split(X, y, test_size=0.2)\n",
    "DL = (L, L_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error (todo L para los no entrenados con esos L): 0.016666666666666666; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.025; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.05; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.025; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.016666666666666666; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.008333333333333333; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.03333333333333333; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.016666666666666666; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.025; Confidence (en una muestra de U): 1.0\n",
      "Error (todo L para los no entrenados con esos L): 0.03333333333333333; Confidence (en una muestra de U): 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "coforest = Co_Forest(DL, U, 10, 0.75, n_class_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
