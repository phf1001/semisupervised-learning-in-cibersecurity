{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PHISHING VECTOR GENERATOR** ðŸŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/patripata/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/patripata/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from user_browsing import user_browsing\n",
    "from xml.etree import ElementTree as ET\n",
    "from urllib.parse import urlparse\n",
    "from os import path\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "from phishing_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PHISH_FVG:\n",
    "\n",
    "    def __init__(self, url, tfidf):\n",
    "\n",
    "        self.url = url\n",
    "        parsed = urlparse(url)\n",
    "        self.base = parsed.netloc\n",
    "        self.path = self.base + '/'.join(path.split('/')[:-1])\n",
    "\n",
    "        self.fv = np.array([-1 for i in range(19)])\n",
    "\n",
    "        self.user = user_browsing()\n",
    "        self.user.set_standard_header(self.base)\n",
    "\n",
    "        response_content = get_bin_source_code(self.url, self.user.get_simple_user_header_agent(), self.user.proxies) \n",
    "        self.html = response_content.decode(\"utf-8\", errors='ignore')\n",
    "        self.soup = BeautifulSoup(response_content)\n",
    "\n",
    "        self.hyperlinks = find_hyperlinks(self.html)\n",
    "        self.tfidf = tfidf\n",
    "\n",
    "\n",
    "    def set_feature_vector(self):\n",
    "\n",
    "        self.set_f1()\n",
    "        self.set_f2()\n",
    "        self.set_f3()\n",
    "        self.set_f4()\n",
    "        self.set_f5()\n",
    "        self.set_f6()\n",
    "        self.set_f7()\n",
    "        self.set_f8()\n",
    "        self.set_f9()\n",
    "        self.set_f10_f11()\n",
    "        self.set_f12()\n",
    "        self.set_f13()\n",
    "        self.set_f14()\n",
    "        self.set_f15()\n",
    "        self.set_f16()\n",
    "        self.set_f17()\n",
    "        self.set_f18()\n",
    "        self.set_f19()\n",
    "\n",
    "\n",
    "    def set_f1(self):\n",
    "        \"\"\"\n",
    "        Sets F1.\n",
    "        F1 = 1, if dots in url >= 4\n",
    "        F1 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        if self.url.count('.') >= 4:\n",
    "            self.fv[0] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[0] = 0\n",
    "\n",
    "\n",
    "    def set_f2(self):\n",
    "        \"\"\"\n",
    "        Sets F2.\n",
    "        F2 = 1, if URL contains '@' or '-' symbols\n",
    "        F2 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        if '@' in self.url or '-' in self.url:\n",
    "            self.fv[1] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[1] = 0\n",
    "\n",
    "\n",
    "    def set_f3(self):\n",
    "        \"\"\"\n",
    "        Sets F3.\n",
    "        F3 = 1, if URL length >= 74\n",
    "        F3 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.url) >= 74:\n",
    "            self.fv[2] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[2] = 0\n",
    "\n",
    "\n",
    "    def set_f4(self):\n",
    "        \"\"\"\n",
    "        Sets F4.\n",
    "        F4 = 1, if URL contains any suspicious word\n",
    "        F4 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        splitted_url = get_splitted_url(self.url)\n",
    "        suspicious_words = get_suspicious_keywords()\n",
    "\n",
    "        for word in splitted_url:\n",
    "            leet_translation = translate_leet_to_letters(word) #DecisiÃ³n propia\n",
    "            \n",
    "            if bool(suspicious_words & leet_translation):\n",
    "                self.fv[3] = 1\n",
    "                return\n",
    "\n",
    "        self.fv[3] = 0\n",
    "\n",
    "\n",
    "    def set_f5(self):\n",
    "        \"\"\"\n",
    "        Sets F5.\n",
    "        F5 = 1, if tlds in URL > 1\n",
    "        F5 = 0, otherwise\n",
    "\n",
    "        # REVISAR COMPUESTOS\n",
    "        \"\"\"\n",
    "\n",
    "        splitted_url = set(get_splitted_url(self.url))\n",
    "        tlds = get_tlds_set()\n",
    "\n",
    "        if len(splitted_url & tlds) > 1:\n",
    "            self.fv[4] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[4] = 0\n",
    "\n",
    "\n",
    "    def set_f6(self):\n",
    "        \"\"\"\n",
    "        Sets F6.\n",
    "        F6 = 1, if http count in URL > 1\n",
    "        F6 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        if len(re.findall('http', self.url)) > 1:\n",
    "            self.fv[5] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[5] = 0\n",
    "\n",
    "\n",
    "    def set_f7(self):\n",
    "        \"\"\"\n",
    "        Sets F7.\n",
    "        F7 = 1, if brand in incorrect position.\n",
    "        F7 = 0, otherwise\n",
    "        # Unitarias\n",
    "        \"\"\"\n",
    "\n",
    "        targets = get_phishing_targets_set()\n",
    "        parsed = urlparse(self.url.lower())\n",
    "        base = remove_tld(parsed.netloc)\n",
    "        base = remove_tld(base)\n",
    "        path = parsed.path\n",
    "\n",
    "        for target in targets:\n",
    "            if target in base or target in path:\n",
    "                self.fv[6] = 1\n",
    "                return\n",
    "\n",
    "        self.fv[6] = 0\n",
    "\n",
    "\n",
    "    def set_f8(self):\n",
    "        \"\"\"\n",
    "        Sets F8.\n",
    "        F8 = 1, if data URI present in website.\n",
    "        F8 = 0, otherwise\n",
    "\n",
    "        Syntax: data:[<mime type>][;charset=<charset>][;base64],<encoded data>\n",
    "        \"\"\"\n",
    "\n",
    "        matches = re.findall('data:(?:[^;,]*)?(?:;charset=[^;,]*)?(?:;base64)?,[^)\"\\';>]*[^)\"\\';>]', self.html)\n",
    "        \n",
    "        if len(matches) > 0:\n",
    "            self.fv[7] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[7] = 0\n",
    "            \n",
    "\n",
    "    def set_f9(self):\n",
    "        \"\"\"\n",
    "        Sets F9.\n",
    "        F9 = 1, if action field is blank or javascript:void(0)\n",
    "        F9 = 1, if action field is <name>.php\n",
    "        F9 = 1, if action field contains foreign base domain\n",
    "        F9 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        forms_found = re.findall(\"<form[^>]+>\", self.html)\n",
    "\n",
    "        if len(forms_found) > 0:\n",
    "\n",
    "            for i in range(len(forms_found)):\n",
    "                form_found = forms_found[i]\n",
    "                action_content = re.findall('(?:action=\\\")([^\"]*)(?:\\\")', form_found)\n",
    "\n",
    "                if len(action_content) > 0:\n",
    "\n",
    "                    if is_empty(action_content[0]):\n",
    "                        self.fv[8] = 1\n",
    "                        return\n",
    "\n",
    "                    elif is_simple_php_file(action_content[0]):\n",
    "                        self.fv[8] = 1\n",
    "                        return\n",
    "\n",
    "                    elif is_foreign(self.url, action_content[0]):\n",
    "                        self.fv[8] = 1\n",
    "                        return\n",
    "                        \n",
    "        self.fv[8] = 0\n",
    "\n",
    "\n",
    "    def set_f10_f11(self):\n",
    "        \"\"\"\n",
    "        Sets F10 and F11.\n",
    "\n",
    "        F10 = number of hyperlinks in source code.\n",
    "\n",
    "        F11 = 1, if no hyperlinks found in source.\n",
    "        F11 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        n_hyperlinks_found = len(self.hyperlinks)\n",
    "        self.fv[9] = n_hyperlinks_found\n",
    "\n",
    "        if n_hyperlinks_found == 0:\n",
    "            self.fv[10] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[10] = 0\n",
    "\n",
    "\n",
    "    def set_f12(self):\n",
    "        \"\"\"\n",
    "        Sets F12.\n",
    "\n",
    "        ratio = |n_foreign_hyp| / |n_hyp|\n",
    "\n",
    "        F12 = 1 if ratio > 0.5 and n_hyp > 0\n",
    "        F12 = 0 otherwise\n",
    "\n",
    "        REVISAR\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.hyperlinks) < 1:\n",
    "            self.fv[11] = 1 # DeberÃ­a ser 0 pero es mejor 1 ya que es phishing clarÃ­simamente\n",
    "            return\n",
    "            \n",
    "        n_foreigns = get_number_foreign_hyperlinks(self.url, self.hyperlinks)\n",
    "        ratio = (n_foreigns / len(self.hyperlinks))\n",
    "\n",
    "        if ratio > 0.5:\n",
    "            self.fv[11] = 1\n",
    "        else:\n",
    "            self.fv[11] = 0\n",
    "\n",
    "\n",
    "    def set_f13(self):\n",
    "        \"\"\"\n",
    "        Sets F13.\n",
    "\n",
    "        ratio = |n_empty_hyp| / |n_hyp|\n",
    "\n",
    "        F13 = 1 if ratio > 0.34 and n_hyp > 0\n",
    "        F13 = 0 otherwise\n",
    "\n",
    "        REVISAR\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.hyperlinks) < 1:\n",
    "            self.fv[12] = 1 # DeberÃ­a ser 0 pero es mejor 1 ya que es phishing clarÃ­simamente\n",
    "            return\n",
    "            \n",
    "        n_empty = get_number_empty_hyperlinks(self.hyperlinks)\n",
    "        ratio = (n_empty / len(self.hyperlinks))\n",
    "\n",
    "        if ratio > 0.34:\n",
    "            self.fv[12] = 1\n",
    "        else:\n",
    "            self.fv[12] = 0\n",
    "\n",
    "\n",
    "    def set_f14(self):\n",
    "        \"\"\"\n",
    "        Sets F14.\n",
    "\n",
    "        ratio = |n_errors_hyp| / |n_hyp|\n",
    "\n",
    "        F13 = 1 if ratio > 0.3 and n_hyp > 0\n",
    "        F13 = 0 otherwise\n",
    "\n",
    "        REVISAR\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.hyperlinks) < 1:\n",
    "            self.fv[13] = 1\n",
    "            return\n",
    "            \n",
    "        n_errors = get_number_errors(self.hyperlinks, self.user.header,  self.user.proxies)\n",
    "        ratio = (n_errors / len(self.hyperlinks))\n",
    "        print(ratio)\n",
    "\n",
    "        if ratio > 0.3:\n",
    "            self.fv[13] = 1\n",
    "        else:\n",
    "            self.fv[13] = 0\n",
    "\n",
    "    \n",
    "    def set_f15(self):\n",
    "        \"\"\"\n",
    "        Sets F15.\n",
    "\n",
    "        ratio = |n_redirects| / |n_hyp|\n",
    "\n",
    "        F13 = 1 if ratio > 0.3 and n_hyp > 0\n",
    "        F13 = 0 otherwise\n",
    "\n",
    "        REVISAR\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.hyperlinks) < 1:\n",
    "            self.fv[14] = 1\n",
    "            return\n",
    "            \n",
    "        n_redirects = get_number_redirects(self.hyperlinks, self.user.header,  self.user.proxies)\n",
    "        ratio = (n_redirects / len(self.hyperlinks))\n",
    "        print(ratio)\n",
    "\n",
    "        if ratio > 0.3:\n",
    "            self.fv[14] = 1\n",
    "        else:\n",
    "            self.fv[14] = 0\n",
    "\n",
    "\n",
    "    def set_f16(self):\n",
    "        \"\"\"\n",
    "        Sets F16.\n",
    "\n",
    "        F16 = 1, if CSS file is external and contains foreign domain name\n",
    "        F16 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        external_csss = self.soup.findAll(\"link\", rel=\"stylesheet\")\n",
    "\n",
    "        for css in external_csss:\n",
    "\n",
    "            link = extract_url_href(css)\n",
    "            \n",
    "            if is_foreign(self.url, link):\n",
    "                self.fv[15] = 1\n",
    "                return\n",
    "\n",
    "        self.fv[15] = 0 \n",
    "\n",
    "\n",
    "    def set_f17(self):\n",
    "        \"\"\"\n",
    "        Sets F17.\n",
    "        F17 = 0 if copyright keyword matches base domain\n",
    "        F17 = 1, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        copyright_clues = ['Â©', '& copy', '&copy', 'copy', 'copyright', 'copyright', 'all right reserved', 'rights', 'right'] #'@', \n",
    "\n",
    "        for clue in copyright_clues:\n",
    "\n",
    "            regex = '(?:{})([^<.>\"]*)(?:[<.>\"])'.format(clue)\n",
    "            copy_contents = re.findall(regex, self.html)\n",
    "\n",
    "            for copy_content in copy_contents:\n",
    "                copy_content = remove_punctuation(copy_content).reshape(1)\n",
    "\n",
    "                for content in copy_content[0].split():\n",
    "                    if re.findall(content.replace(\",\", \"\"), self.base, re.IGNORECASE):\n",
    "                        self.fv[16] = 0\n",
    "                        return\n",
    "        \n",
    "        self.fv[16] = 1\n",
    "\n",
    "    def set_f18(self):\n",
    "        \"\"\"\n",
    "        Set F18.\n",
    "        F18 = 1 if no keyword matches domain name\n",
    "        F18 = 0 Otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        keywords = get_site_keywords(self.html, self.tfidf, 15)\n",
    "\n",
    "        for keyword in keywords:\n",
    "\n",
    "            if re.findall(keyword, self.base):\n",
    "                self.fv[17] = 0\n",
    "                return\n",
    "        \n",
    "        self.fv[17] = 1\n",
    "\n",
    "\n",
    "    def set_f19(self):\n",
    "        \"\"\"\n",
    "        Sets F19.\n",
    "        F19 = 1, if foreign domain found in favicon link\n",
    "        F19 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        icons = self.soup.findAll(\"link\", rel=\"icon\") + self.soup.findAll(\"link\", rel=\"shortcut icon\")\n",
    "\n",
    "        for icon in icons:\n",
    "\n",
    "            link = extract_url_href(icon)\n",
    "\n",
    "            if is_foreign(self.url, link):\n",
    "                self.fv[18] = 1\n",
    "                return\n",
    "\n",
    "        self.fv[18] = 0 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GET TFIDF OBJECT FIRST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user = user_browsing()\n",
    "user.set_standard_header(\"https://github.com/\")\n",
    "\n",
    "urls = [    \"https://github.com/\", \n",
    "            \"https://towardsdatascience.com/\",\n",
    "            'https://www.naturaselection.com/es/',\n",
    "            'https://www.bershka.com/es/h-woman.html',\n",
    "            'https://ubuvirtual.ubu.es/',\n",
    "            'https://www.facebook.com/login/'\n",
    "            \n",
    "        ]\n",
    "\n",
    "corpus = get_tfidf_corpus(urls, user.get_simple_user_header_agent(), user.proxies)\n",
    "tfidf = get_tfidf(corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FVG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patripata/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patripata/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patripata/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "reales = ['https://ubuvirtual.ubu.es/', 'https://www.facebook.com/login/', 'https://github.com']\n",
    "\n",
    "for real in reales:\n",
    "    ph_entity = PHISH_FVG(real, tfidf)\n",
    "    ph_entity.set_f18()\n",
    "    #ph_entity.set_feature_vector()\n",
    "    print(ph_entity.fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "[ 0  0  0  0  0  0  0  0  0 10  0  0  1  0  0  0  1  1  0]\n"
     ]
    }
   ],
   "source": [
    "peces = ['http://onedrive.0ffice365sg.cloud/sasf9cwgb9adzam4/']\n",
    "\n",
    "for pez in peces:\n",
    "    ph_entity = PHISH_FVG(pez, tfidf)\n",
    "    ph_entity.set_feature_vector()\n",
    "    print(ph_entity.fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
