{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PHISHING VECTOR GENERATOR** üêü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from user_browsing import user_browsing\n",
    "from xml.etree import ElementTree as ET\n",
    "from urllib.parse import urlparse\n",
    "from os import path\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "from phishing_utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PHISH_FVG:\n",
    "\n",
    "    def __init__(self, url, fichero = 'html_dump'):\n",
    "\n",
    "        self.url = url\n",
    "        self.base, self.path = self.process_url(self.url)\n",
    "\n",
    "        self.fv = np.array([-1 for i in range(19)])\n",
    "        self.fichero = fichero\n",
    "\n",
    "        self.user = user_browsing()\n",
    "        self.user.set_standard_header(self.base)\n",
    "\n",
    "        response_content = self.get_bin_source_code()\n",
    "        self.html = response_content.decode(\"utf-8\")\n",
    "        self.soup = BeautifulSoup(response_content)\n",
    "\n",
    "        self.hyperlinks = self.find_hyperlinks()\n",
    "        \n",
    "\n",
    "    def process_url(self, url):\n",
    "\n",
    "        parsed = urlparse(url)\n",
    "        base = parsed.netloc\n",
    "        return base, base + '/'.join(path.split('/')[:-1])\n",
    "\n",
    "\n",
    "    def get_bin_source_code(self):\n",
    "\n",
    "        response = requests.get(self.url, headers=self.user.get_simple_user_header_agent() ) #, headers=self.user.header) #proxies=user.proxies, cookies=user.cookies)\n",
    "\n",
    "        if response.status_code != 400:\n",
    "            with open(self.fichero, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                f.close()\n",
    "\n",
    "        return response.content\n",
    "\n",
    "    def get_title(self):\n",
    "        return re.findall('(?:<title>)([^<]*)(?:</title>)', self.html)\n",
    "\n",
    "    def get_meta(self):\n",
    "\n",
    "        keywords = []\n",
    "        found = re.findall('(?:<meta)([^>]*)(?:>)', self.html) #(?:<meta.*content=\")([^\"]*)(?:\")\n",
    "\n",
    "        for content in found:\n",
    "            match = re.findall('(?:content=\")([^\"]*)(?:\")', content)\n",
    "\n",
    "            if len(match) > 0:\n",
    "                keywords.append(match[0])\n",
    "\n",
    "        return keywords\n",
    "\n",
    "\n",
    "    def get_meta_title_words(self):\n",
    "\n",
    "        list = self.get_title() + self.get_meta()\n",
    "        words = ' '.join(list)\n",
    "\n",
    "        return Utils().preprocess(words)\n",
    "\n",
    "\n",
    "    def find_hyperlinks(self):\n",
    "        return ( re.findall('(?:src\\b*=\\b*\\\")([^\"]*)(?:\\\")', self.html) + re.findall('(?:href\\b*=\\b*\\\")([^\"]*)(?:\\\")', self.html) )\n",
    "    \n",
    "    def url_validator(self, url):\n",
    "        parsed = urlparse(url)\n",
    "        return parsed.netloc != ''\n",
    "\n",
    "\n",
    "    def set_f9(self):\n",
    "\n",
    "        try:\n",
    "\n",
    "            forms_found = re.findall(\"<form[^>]+>\", self.html)\n",
    "\n",
    "            if len(forms_found) > 0:\n",
    "\n",
    "                for i in range(len(forms_found)):\n",
    "\n",
    "                    form_found = forms_found[i]\n",
    "                    action_content = re.findall('(?:action=\\\")([^\"]*)(?:\\\")', form_found)\n",
    "                    print(action_content[0])\n",
    "\n",
    "                    if (len(action_content[0]) <1) or (len(re.findall('javascript:void\\(0\\)', action_content[0])) > 0):\n",
    "                        self.fv[8] = 1\n",
    "                        return\n",
    "\n",
    "                    elif len(re.findall('^(.*\\.php)$', action_content[0])) > 0 and self.base != self.process_url(action_content[0])[0]:\n",
    "                        self.fv[8] = 1\n",
    "                        return\n",
    "\n",
    "                    elif action_content[0][0] != '/' and self.base != self.process_url(action_content[0])[0]:\n",
    "                        self.fv[8] = 1\n",
    "                        return\n",
    "                    \n",
    "                    else:\n",
    "                        self.fv[8] = 0\n",
    "                    \n",
    "            else:\n",
    "                self.fv[8] = 0\n",
    "        \n",
    "        # No action found\n",
    "        except:\n",
    "            self.fv[8] = 0\n",
    "\n",
    "    \n",
    "    def set_f10_f11(self):\n",
    "\n",
    "        try:\n",
    "            n_hyperlinks_found = len(self.hyperlinks)\n",
    "            self.fv[9] = n_hyperlinks_found\n",
    "\n",
    "            if n_hyperlinks_found == 0:\n",
    "                self.fv[10] = 1\n",
    "\n",
    "            else:\n",
    "                self.fv[10] = 0\n",
    "\n",
    "        except:\n",
    "            self.fv[9] = 0\n",
    "            self.fv[10] = 0\n",
    "\n",
    "\n",
    "    def get_number_foreign_hyperlinks(self):\n",
    "\n",
    "        n_foreigns = 0\n",
    "\n",
    "        for h in self.hyperlinks:\n",
    "            if self.is_foreign(h):\n",
    "                n_foreigns += 1\n",
    "\n",
    "        return n_foreigns\n",
    "\n",
    "        \n",
    "    def set_f12(self):\n",
    "\n",
    "        if len(self.hyperlinks) < 1:\n",
    "            self.fv[11] = 1\n",
    "            return 0\n",
    "            \n",
    "        n_foreigns = self.get_number_foreign_hyperlinks() \n",
    "            \n",
    "        ratio = (n_foreigns / len(self.hyperlinks))\n",
    "\n",
    "        if ratio < 0.5:\n",
    "            self.fv[11] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[11] = 0\n",
    "\n",
    "            # for h in hyperlinks_found:\n",
    "            #     print(\"{} {} \".format(h, self.is_foreign(h)))\n",
    "\n",
    "        print(ratio)\n",
    "\n",
    "\n",
    "    def set_f13(self):\n",
    "\n",
    "        if len(self.hyperlinks) < 1:\n",
    "            self.fv[12] = 1\n",
    "            return\n",
    "            \n",
    "        n_empty = self.get_number_empty_hyperlinks()\n",
    "            \n",
    "        ratio = (n_empty / len(self.hyperlinks))\n",
    "\n",
    "        if ratio > 0.34:\n",
    "            self.fv[12] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[12] = 0\n",
    "\n",
    "        print(ratio)\n",
    "\n",
    "\n",
    "    def set_f14(self):\n",
    "\n",
    "        if len(self.hyperlinks) < 1:\n",
    "            self.fv[13] = 1\n",
    "            return\n",
    "            \n",
    "        n_errors = self.get_number_errors()\n",
    "            \n",
    "        ratio = (n_errors / len(self.hyperlinks))\n",
    "\n",
    "        if ratio > 0.3:\n",
    "            self.fv[13] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[13] = 0\n",
    "\n",
    "        print(ratio)\n",
    "\n",
    "    \n",
    "    def set_f15(self):\n",
    "\n",
    "        if len(self.hyperlinks) < 1:\n",
    "            self.fv[14] = 1\n",
    "            return\n",
    "            \n",
    "        n_redirects = self.get_number_redirects()\n",
    "            \n",
    "        ratio = (n_redirects / len(self.hyperlinks))\n",
    "\n",
    "        if ratio > 0.3:\n",
    "            self.fv[14] = 1\n",
    "\n",
    "        else:\n",
    "            self.fv[14] = 0\n",
    "\n",
    "        print(ratio)\n",
    "\n",
    "\n",
    "    def set_f17(self):\n",
    "\n",
    "        copyright_clues = ['¬©', '& copy', 'copy', 'copyright', 'copyright', 'all right reserved', 'rights', 'right'] #'@', \n",
    "\n",
    "        base_domain = self.base.split(\".\")\n",
    "\n",
    "        for clue in copyright_clues:\n",
    "\n",
    "            regex = '(?:{})([^\"]*)(?:[\\.\\\"])'.format(clue)\n",
    "            copy_contents = re.findall(regex, self.html)\n",
    "\n",
    "            for copy_content in copy_contents:\n",
    "\n",
    "                copy_content = copy_content.replace(\" \", \"\")\n",
    "\n",
    "                for base in base_domain:\n",
    "                    if re.search(base, copy_content, re.IGNORECASE):\n",
    "                        self.fv[16] = 0\n",
    "                        return\n",
    "        \n",
    "        self.fv[16] = 1\n",
    "    \n",
    "\n",
    "    def get_response_code(self, url):\n",
    "        return requests.get(url).status_code\n",
    "\n",
    "\n",
    "\n",
    "    def get_number_empty_hyperlinks(self):\n",
    "\n",
    "        n_empty = 0\n",
    "\n",
    "        for h in self.hyperlinks:\n",
    "            if self.is_empty(h):\n",
    "                n_empty += 1\n",
    "\n",
    "        return n_empty\n",
    "\n",
    "\n",
    "\n",
    "    def is_absolute(self, url):\n",
    "        return bool(urlparse(url).netloc)\n",
    "\n",
    "    def is_empty(self, url):\n",
    "        return url[0] == '#' or bool(re.match('[Jj]ava[Ss]cript::?void\\(0\\)', url))\n",
    "\n",
    "    def is_relative_in_local(self, url):\n",
    "\n",
    "        if self.is_absolute(url):\n",
    "            return False\n",
    "\n",
    "        pattern = re.compile(\"^[/]?[A-z0-9_]\")\n",
    "        return bool (pattern.match(url))\n",
    "        \n",
    "    \n",
    "    def get_number_errors(self):\n",
    "\n",
    "        n_errors = 0\n",
    "\n",
    "        for h in self.hyperlinks:\n",
    "\n",
    "            if not self.is_empty(h) and not self.is_relative_in_local(h):\n",
    "                code = self.get_response_code(h)\n",
    "\n",
    "                if code == 404 or code == 403:\n",
    "                    n_errors += 1\n",
    "\n",
    "        return n_errors\n",
    "\n",
    "\n",
    "    def get_number_redirects(self):\n",
    "\n",
    "        n_redirects = 0\n",
    "\n",
    "        for h in self.hyperlinks:\n",
    "\n",
    "            if not self.is_empty(h) and not self.is_relative_in_local(h):\n",
    "                code = self.get_response_code(h)\n",
    "\n",
    "                if code == 302 or code == 301:\n",
    "                    n_redirects += 1\n",
    "\n",
    "        return n_redirects\n",
    "\n",
    "\n",
    "    def is_foreign(self, url):\n",
    "        return not self.is_relative_in_local(url) and not self.is_empty(url) and self.base != urlparse(url).netloc\n",
    "\n",
    "    def get_popular_words(self, k=10):\n",
    "\n",
    "        cleaned = BeautifulSoup(self.html, \"lxml\").text\n",
    "        tokens = Utils().preprocess(cleaned)\n",
    "        counter = Counter(tokens)\n",
    "        n_words = len(tokens)\n",
    "\n",
    "        for token in np.unique(tokens):\n",
    "        \n",
    "            tf = counter[token]/n_words\n",
    "            #df = doc_freq(token)\n",
    "            #idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        #tf_idf[doc, token] = tf*idf\n",
    "\n",
    "        return counter.most_common(k)\n",
    "\n",
    "\n",
    "    def get_site_keywords(self):\n",
    "        \n",
    "        set_one = set(self.get_meta_title_words())\n",
    "        set_two = set([word[0] for word in self.get_popular_words()])\n",
    "\n",
    "        return set_one.union(set_two)\n",
    "\n",
    "\n",
    "    def set_f18(self):\n",
    "        \n",
    "        keywords = self.get_site_keywords()\n",
    "        #base = re.match('(:?(www.)?)([^.]*)(:?.[A-Za-z]{0,4})', self.base)[0]\n",
    "        #base = base.split('.')\n",
    "\n",
    "        for keyword in keywords:\n",
    "\n",
    "            if re.findall(keyword, self.base):\n",
    "                self.fv[17] = 0\n",
    "                break\n",
    "        \n",
    "        self.fv[17] = 1\n",
    "\n",
    "\n",
    "    def set_f19(self):\n",
    "        \"\"\"\n",
    "        Sets F19.\n",
    "        F19 = 1, if foreign domain found in favicon link\n",
    "        F19 = 0, otherwise\n",
    "        \"\"\"\n",
    "\n",
    "        icons = self.soup.findAll(\"link\", rel=\"icon\") + self.soup.findAll(\"link\", rel=\"shortcut icon\")\n",
    "        print(icons)\n",
    "\n",
    "        for icon in icons:\n",
    "\n",
    "            link = re.findall('(?:href=\")([^\"]*)(?:\")', str(icon))[0]\n",
    "\n",
    "            if self.is_foreign(link):\n",
    "                self.fv[18] = 1\n",
    "                print(1)\n",
    "                break\n",
    "\n",
    "        self.fv[18] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ('https://www.naturaselection.com/es/') \n",
    "# ('https://www.bershka.com/es/h-woman.html') \n",
    "# ('https://ubuvirtual.ubu.es/') \n",
    "# ('https://fdeageadfahgeafeahg.azurewebsites.net/renner/inicio/login.php')\n",
    "# ('https://banrural.herokuapp.com/')\n",
    "\n",
    "ph_entity = PHISH_FVG('https://www.naturaselection.com/es/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ph_entity.set_f9()\n",
    "\n",
    "# ph_entity.set_f10_f11()\n",
    "\n",
    "\n",
    "# print(ph_entity.is_foreign('https://www.ubuvirtual.com/image.jpg'))\n",
    "# print(ph_entity.is_foreign('www.fdeageadfahgeafeahg.azurewebsites.net/renner/inicio/login.php'))\n",
    "\n",
    "# ph_entity.set_f12()\n",
    "# ph_entity.set_f13()\n",
    "#ph_entity.set_f17()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "ph_entity.set_f19()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
