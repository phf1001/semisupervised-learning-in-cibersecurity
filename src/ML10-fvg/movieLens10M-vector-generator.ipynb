{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– **MOVIE LENS 10M - DATA GENERATOR**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate feature vectors for genuine or attack profiles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML10M_FVG:\n",
    "\n",
    "    def load_ratings(self):\n",
    "\n",
    "        return pd.read_csv(\n",
    "            './dataset/ratings.dat',\n",
    "            sep='::',\n",
    "            engine='python',\n",
    "            header=None,\n",
    "            names=['userID', 'movieID', 'rating', 'timestamp'])\n",
    "            \n",
    "        \n",
    "    def load_movies(self):\n",
    "\n",
    "        return pd.read_csv(\n",
    "            './dataset/movies.dat',\n",
    "            sep='::',\n",
    "            engine='python',\n",
    "            header=None,\n",
    "            names=['movieID', 'Title', 'Genre'])\n",
    "\n",
    "\n",
    "    def get_movies_global_statistics(self, items):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -------\n",
    "        List containing the desired items. If none, the\n",
    "        whole database is used.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple\n",
    "            Tuple containing the mean of the mean rating \n",
    "            of all movies and its standard desviation.\n",
    "        \"\"\"\n",
    "\n",
    "        data = self.ratings\n",
    "        means = []\n",
    "\n",
    "        for item in items:\n",
    "            ratings_movie = data.loc[data[\"movieID\"] == item].values\n",
    "            if len(ratings_movie) > 0:\n",
    "                means.append(np.mean(ratings_movie[:, 2]))\n",
    "\n",
    "        return np.mean(means), np.std(means)\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.ratings = self.load_ratings()\n",
    "        self.movies = self.load_movies()\n",
    "        \n",
    "        self.movies_ids = self.movies.values[:, 0]\n",
    "        self.users_ids = set(self.ratings['userID'])\n",
    "\n",
    "        self.n_movies = len(self.movies_ids)\n",
    "        self.n_users = len(self.users_ids)\n",
    "        self.n_ratings = self.ratings.shape[0]\n",
    "\n",
    "        self.windows = None\n",
    "        self.n_windows = 0\n",
    "\n",
    "        self.rd = np.random.RandomState(5)\n",
    "        self.range_ratings = (0, 5)\n",
    "        self.range_mean = ((self.range_ratings[1] - self.range_ratings[0]) / 2)\n",
    "\n",
    "        self.most_popular_items = None\n",
    "        self.most_popular_items_data = None\n",
    "        self.n_most_popular_items = 0\n",
    "\n",
    "        self.global_mean, self.global_std = self.get_movies_global_statistics(self.movies_ids)\n",
    "\n",
    "\n",
    "    def dump_vectors_json(self, vectors, file):\n",
    "\n",
    "        with open(file, 'w') as f:\n",
    "            json_dumps_str = json.dumps(vectors, indent=2)\n",
    "            print(json_dumps_str, file=f)\n",
    "            f.close()\n",
    "\n",
    "\n",
    "    def dump_vectors_csv(self, vectors, tag, file):\n",
    "        \"\"\"\n",
    "        Dumps the vectors to a csv and tags them.\n",
    "        \"\"\"\n",
    "\n",
    "        values = list(vectors.values())\n",
    "\n",
    "        for value in values:\n",
    "            value.append(tag) \n",
    "\n",
    "        np.savetxt(file, np.array(values), fmt = '%.10f', delimiter=\",\")\n",
    "\n",
    "\n",
    "    def get_most_popular_items(self, number=50):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Array the most popular (voted) ratings and\n",
    "            its mean rating.\n",
    "            (film, number of ratings, mean of the ratings)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.most_popular_items is not None and self.n_most_popular_items == number:\n",
    "            pass\n",
    "\n",
    "        data = self.ratings\n",
    "        movies_info = []\n",
    "\n",
    "        for film in self.movies_ids:\n",
    "            ratings_movie = data.loc[data[\"movieID\"] == film].values\n",
    "\n",
    "            if len(ratings_movie) > 0:\n",
    "                movies_info.append( (film, len(ratings_movie), np.mean(ratings_movie[:, 2])) )\n",
    "            \n",
    "        ordered = sorted(movies_info, key = lambda x:x[1], reverse=True)\n",
    "        \n",
    "        self.most_popular_items_data = ordered[:number]\n",
    "        self.most_popular_items = [i[0] for i in self.most_popular_items_data]\n",
    "\n",
    "\n",
    "    def get_movies_particular_statistics(self, films_ids):\n",
    "        \"\"\"\n",
    "        Returns individual statistics for each\n",
    "        film in the array.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        films_ids: list with a bunch of ids.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple\n",
    "            Tuple containing the means and\n",
    "            the desviations (in order) for the iems.\n",
    "        \"\"\"\n",
    "\n",
    "        data = self.ratings\n",
    "        means = []\n",
    "        stds = []\n",
    "\n",
    "        for film in films_ids:\n",
    "            ratings_movie = data.loc[data[\"movieID\"] == film].values\n",
    "\n",
    "            if len(ratings_movie) > 0:\n",
    "                means.append(np.mean(ratings_movie[:, 2]))\n",
    "                stds.append(np.std(ratings_movie[:, 2]))\n",
    "\n",
    "            else:\n",
    "                means.append(None)\n",
    "                stds.append(None)\n",
    "\n",
    "        return means, stds\n",
    "\n",
    "\n",
    "    def get_windows(self, n_windows):\n",
    "        \"\"\"\n",
    "        Returns the items partitions made (by index).\n",
    "        First item is included, while second one is not.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            List of tuples, where the tuples are \n",
    "            (row_first_item_window_INCLUDED, row:last_item_window_EXCLUDED)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.n_windows == n_windows and self.windows is not None:\n",
    "            pass\n",
    "\n",
    "        Q, q = divmod(self.n_movies, n_windows)\n",
    "        index = 0\n",
    "        windows = []\n",
    "\n",
    "        for j in range(n_windows):\n",
    "\n",
    "            if j < q: # No = here since range starts in 0\n",
    "                n_items_window = Q + 1\n",
    "\n",
    "            else:\n",
    "                n_items_window = Q\n",
    "\n",
    "            windows.append((index, index + n_items_window))\n",
    "            index = index + n_items_window \n",
    "\n",
    "        self.windows = windows\n",
    "        self.n_windows = n_windows\n",
    "        \n",
    "\n",
    "    def obtain_array_user(self, ratings_user, J):\n",
    "        \"\"\"\n",
    "        Returns the feature vector of a user given\n",
    "        its ratings and desired number of windows.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            np.array\n",
    "                feature vector\n",
    "        \"\"\"\n",
    "        \n",
    "        self.get_windows(J) \n",
    "\n",
    "        n_ratings_user = len(ratings_user)\n",
    "        user_vector = []\n",
    "\n",
    "        for window in self.windows:\n",
    "            movies_window = self.movies_ids[window[0] : window[1]]\n",
    "            ratings_user_window = [rating for rating in ratings_user if int(rating[1]) in movies_window]\n",
    "            n_ratings_user_window = len(ratings_user_window)\n",
    "\n",
    "            user_vector.append(n_ratings_user_window) #NRW\n",
    "            user_vector.append(n_ratings_user_window/n_ratings_user) #NRWR\n",
    "\n",
    "        return user_vector\n",
    "\n",
    "\n",
    "    def discard_elements(self, all_elements, excluded):\n",
    "\n",
    "        all_elements = set(all_elements)\n",
    "        \n",
    "        if excluded is not None:\n",
    "            for item in excluded:\n",
    "                all_elements.discard(item)\n",
    "\n",
    "        return list(all_elements)\n",
    "\n",
    "\n",
    "    def obtain_genuine_vectors(self, number, J=40, filename='genuine', excluded=None):\n",
    "        \"\"\"\n",
    "        Returns the feature vectors of random users in \n",
    "        the database given the desired number of windows\n",
    "        and users.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            np.array\n",
    "                array of features vectors\n",
    "        \"\"\"\n",
    "\n",
    "        data = self.ratings\n",
    "        available_users_ids = self.discard_elements(deepcopy(self.users_ids), excluded)\n",
    "\n",
    "        users_ids = self.rd.choice(available_users_ids, replace = False, size=number)\n",
    "\n",
    "        vectors = { **dict.fromkeys([int(i) for i in users_ids], [])} \n",
    "\n",
    "        for user_id in users_ids:\n",
    "            ratings_user = data.loc[data[\"userID\"] == user_id].values\n",
    "            vectors[user_id] = self.obtain_array_user(ratings_user, 40)\n",
    "\n",
    "        self.dump_vectors_json(vectors, filename + '.json')\n",
    "        self.dump_vectors_csv(vectors, 0, filename + '.csv')\n",
    "\n",
    "        return users_ids\n",
    "\n",
    "\n",
    "    def get_filler_items(self, number, excluded):\n",
    "        \"\"\"\n",
    "        Returns a random array of items ids.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            np.array\n",
    "                vector of random items ids.\n",
    "        \"\"\"\n",
    "\n",
    "        available_moviles = self.discard_elements(deepcopy(self.movies_ids), excluded)\n",
    "        return self.rd.choice(available_moviles, replace = False, size=number)\n",
    "\n",
    "\n",
    "    def rating_correction(self, rating):\n",
    "        \"\"\"\n",
    "        Guarantees rating is inside a correct \n",
    "        interval.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            rating\n",
    "                the rating if it was correct, max or\n",
    "                min if not.\n",
    "        \"\"\"\n",
    "\n",
    "        if rating > self.range_ratings[1]:\n",
    "            return self.range_ratings[1]\n",
    "\n",
    "        elif rating < self.range_ratings[0]:\n",
    "            return self.range_ratings[0]\n",
    "\n",
    "        return rating\n",
    "\n",
    "\n",
    "    def generate_random_ratings(self, number_users, filler_number, target_items, rating_target):\n",
    "        \"\"\"\n",
    "        For each user, generates a list of ratings applying\n",
    "        random model.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            [ [[]], ]\n",
    "        \"\"\"\n",
    "\n",
    "        ratings = []\n",
    "\n",
    "        for i in range(number_users):\n",
    "\n",
    "            id_usuario = -1 * i\n",
    "            filler_items = self.get_filler_items(filler_number, target_items)\n",
    "            filler_items_ratings = self.rd.normal(loc=self.global_mean, scale=self.global_std, size=len(filler_items))\n",
    "\n",
    "            ratings_user = [ ]\n",
    "\n",
    "            for item, rating in zip(filler_items, filler_items_ratings):\n",
    "                ratings_user.append([id_usuario, item, self.rating_correction(rating)])\n",
    "\n",
    "            for item in target_items:\n",
    "                ratings_user.append([id_usuario, item, rating_target])\n",
    "\n",
    "            ratings.append(ratings_user)\n",
    "\n",
    "        return(ratings)\n",
    "\n",
    "\n",
    "    #VAS POR AQUI self.rating_correction(rating)\n",
    "    def generate_average_ratings(self, number_users, filler_number, target_items, rating_target):\n",
    "        \"\"\"\n",
    "        For each user, generates a list of ratings applying\n",
    "        average model.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            [ [[]], ]\n",
    "        \"\"\"\n",
    "\n",
    "        ratings = []\n",
    "\n",
    "        for i in range(number_users):\n",
    "\n",
    "            id_usuario = -1 * i\n",
    "            filler_items = self.get_filler_items(filler_number, target_items)\n",
    "            means, distributions = self.get_movies_particular_statistics(filler_items)\n",
    "\n",
    "            ratings_user = [ ]\n",
    "\n",
    "            for i in range(filler_number):\n",
    "\n",
    "                if means[i] is None:\n",
    "                    rating = self.rd.normal(loc=self.range_mean, scale=0, size=1) \n",
    "\n",
    "                else:\n",
    "                    rating = self.rd.normal(loc=means[i], scale=distributions[i], size=1)\n",
    "\n",
    "                ratings_user.append([id_usuario, filler_items[i], self.rating_correction(rating)])\n",
    "\n",
    "            for item in target_items:\n",
    "                ratings_user.append([id_usuario, item, rating_target])\n",
    "\n",
    "            ratings.append(ratings_user)\n",
    "\n",
    "        return(ratings)\n",
    "\n",
    "\n",
    "    def generate_bandwagon_ratings(self, number_users, filler_number, popular_number, target_items, rating_target):\n",
    "        \"\"\"\n",
    "        For each user, generates a list of ratings applying\n",
    "        bandwagon model.\n",
    "\n",
    "        Used average bandwagon attack as in the paper\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            [ [[]], ]\n",
    "        \"\"\"\n",
    "\n",
    "        ratings = []\n",
    "\n",
    "        self.get_most_popular_items(popular_number)\n",
    "\n",
    "        for i in range(number_users):\n",
    "            id_usuario = -1 * i\n",
    "            filler_items = self.get_filler_items(filler_number, target_items + self.most_popular_items)\n",
    "            filler_items_ratings = self.rd.normal(loc=self.global_mean, scale=self.global_std, size=filler_number)\n",
    "\n",
    "            ratings_user = [ ]\n",
    "\n",
    "            for item, rating in zip(filler_items, filler_items_ratings):\n",
    "                ratings_user.append([id_usuario, item, self.rating_correction(rating)])\n",
    "\n",
    "            for item in target_items:\n",
    "                ratings_user.append([id_usuario, item, rating_target])\n",
    "\n",
    "            for item in self.most_popular_items_data:\n",
    "\n",
    "                if item[2] < self.range_mean:\n",
    "                    ratings_user.append([id_usuario, item[0], self.range_ratings[0]])\n",
    "\n",
    "                else:\n",
    "                    ratings_user.append([id_usuario, item[0], self.range_ratings[1]])\n",
    "\n",
    "            ratings.append(ratings_user)\n",
    "\n",
    "        return(ratings)\n",
    "\n",
    "    def generate_attack_vectors_ratings(self, ratings):\n",
    "        \"\"\"\n",
    "        Given the ratings of certain users, returns the\n",
    "        feature vectors.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            np.array\n",
    "                array of features vectors\n",
    "        \"\"\"\n",
    "\n",
    "        users_ids = [i[0][0] for i in ratings]\n",
    "        vectors = { **dict.fromkeys([i for i in users_ids], [])} \n",
    "\n",
    "        for ratings_user in ratings:\n",
    "            vectors[ratings_user[0][0]] = self.obtain_array_user(ratings_user, 40)\n",
    "\n",
    "        return vectors\n",
    "\n",
    "\n",
    "    def generate_attack_vectors(self, number, filler_number, target_items, popular_number=50, type='Random', push=True, filename='vectores'):\n",
    "        \"\"\"\n",
    "        Returns the feature vectors of a certain number\n",
    "        of attackers given the target items, type of attack,\n",
    "        punctuation rate and push/nuke.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "            Array of vectors\n",
    "        \"\"\"\n",
    "\n",
    "        if (push):\n",
    "            rating_target = self.range_ratings[1]\n",
    "        else:\n",
    "            rating_target = self.range_ratings[0]\n",
    "\n",
    "\n",
    "        if type == 'Random':\n",
    "            ratings = self.generate_random_ratings(number, filler_number, target_items, rating_target)\n",
    "\n",
    "        elif type == 'Average':\n",
    "            ratings = self.generate_average_ratings(number, filler_number, target_items, rating_target)\n",
    "            \n",
    "        elif type == 'Bandwagon':\n",
    "            ratings = self.generate_bandwagon_ratings(number, filler_number, popular_number, target_items, rating_target)\n",
    "\n",
    "        vectors = self.generate_attack_vectors_ratings(ratings)\n",
    "        \n",
    "        #dump_vectors_json(vectors, filename + '.json')\n",
    "        self.dump_vectors_csv(vectors, 1, filename + '.csv')\n",
    "\n",
    "        return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m generator \u001b[39m=\u001b[39m ML10M_FVG()\n\u001b[0;32m      2\u001b[0m rd \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mRandomState(\u001b[39m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m total \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39mn_movies\n",
      "Cell \u001b[1;32mIn [8], line 50\u001b[0m, in \u001b[0;36mML10M_FVG.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mratings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_ratings()\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmovies \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_movies()\n\u001b[0;32m     53\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmovies_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmovies\u001b[39m.\u001b[39mvalues[:, \u001b[39m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn [8], line 5\u001b[0m, in \u001b[0;36mML10M_FVG.load_ratings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_ratings\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[0;32m      6\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39m./dataset/ratings.dat\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m         sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m::\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpython\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m         header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     10\u001b[0m         names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39muserID\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmovieID\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1772\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1765\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1766\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1767\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1768\u001b[0m     (\n\u001b[0;32m   1769\u001b[0m         index,\n\u001b[0;32m   1770\u001b[0m         columns,\n\u001b[0;32m   1771\u001b[0m         col_dict,\n\u001b[1;32m-> 1772\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1773\u001b[0m         nrows\n\u001b[0;32m   1774\u001b[0m     )\n\u001b[0;32m   1775\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1776\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:251\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\n\u001b[0;32m    246\u001b[0m     \u001b[39mself\u001b[39m, rows: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    247\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[\n\u001b[0;32m    248\u001b[0m     Index \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m, Sequence[Hashable] \u001b[39m|\u001b[39m MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[0;32m    249\u001b[0m ]:\n\u001b[0;32m    250\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m         content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_lines(rows)\n\u001b[0;32m    252\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_first_chunk:\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1124\u001b[0m, in \u001b[0;36mPythonParser._get_lines\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m   1121\u001b[0m rows \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m   1123\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m-> 1124\u001b[0m     new_row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_iter_line(row_num\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos \u001b[39m+\u001b[39;49m rows \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m   1125\u001b[0m     rows \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1127\u001b[0m     \u001b[39mif\u001b[39;00m new_row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:787\u001b[0m, in \u001b[0;36mPythonParser._next_iter_line\u001b[1;34m(self, row_num)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    785\u001b[0m     \u001b[39m# assert for mypy, data is Iterator[str] or None, would error in next\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    788\u001b[0m     \u001b[39m# for mypy\u001b[39;00m\n\u001b[0;32m    789\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(line, \u001b[39mlist\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:235\u001b[0m, in \u001b[0;36mPythonParser._make_reader.<locals>._read\u001b[1;34m()\u001b[0m\n\u001b[0;32m    231\u001b[0m pat \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(sep)\n\u001b[0;32m    233\u001b[0m \u001b[39myield\u001b[39;00m pat\u001b[39m.\u001b[39msplit(line\u001b[39m.\u001b[39mstrip())\n\u001b[1;32m--> 235\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f:\n\u001b[0;32m    236\u001b[0m     \u001b[39myield\u001b[39;00m pat\u001b[39m.\u001b[39msplit(line\u001b[39m.\u001b[39mstrip())\n",
      "File \u001b[1;32mc:\\Users\\patri\\source\\venvs\\tfg-01\\lib\\codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_buffer_decode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, errors, final):\n\u001b[0;32m    315\u001b[0m     \u001b[39m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m    322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_decode(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors, final)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1443\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1744\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\pydev_is_thread_alive.py:9\u001b[0m, in \u001b[0;36mis_thread_alive\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m      6\u001b[0m _temp \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread()\n\u001b[0;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_is_stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 3.x has this\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mis_thread_alive\u001b[39m(t):\n\u001b[0;32m     10\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39m_is_stopped\n\u001b[0;32m     12\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(_temp, \u001b[39m'\u001b[39m\u001b[39m_Thread__stopped\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# Python 2.x has this\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generator = ML10M_FVG()\n",
    "rd = np.random.RandomState(5)\n",
    "total = generator.n_movies\n",
    "used_users = np.array([], dtype=int)\n",
    "generator.get_most_popular_items()\n",
    "generator.get_windows(40)\n",
    "\n",
    "for i in [0.01, 0.03, 0.05, 0.1]:\n",
    "    target = rd.choice(generator.movies_ids, replace = False, size=1)\n",
    "    generator.generate_attack_vectors(10, int(i*total-1), target, type='Random', filename=\"train-random-{}\".format(i))\n",
    "    generator.generate_attack_vectors(10, int(i*total-1), target, type='Average', filename=\"train-average-{}\".format(i))\n",
    "    generator.generate_attack_vectors(10, int(i*total-1-50), target, type='Bandwagon', filename=\"train-bandwagon-{}\".format(i))\n",
    "\n",
    "iteration_used_users = generator.obtain_genuine_vectors(1000, filename='train-genuine')\n",
    "used_users = np.concatenate((used_users, iteration_used_users))\n",
    "\n",
    "#Generate test sets\n",
    "for p in range(1, 11):\n",
    "    iteration_used_users = generator.obtain_genuine_vectors(1000, filename='test-{}-genuine'.format(p), excluded=used_users)\n",
    "    used_users = np.concatenate((used_users, iteration_used_users))\n",
    "\n",
    "    for i in [0.01, 0.03, 0.05, 0.1]:\n",
    "        for k in [10, 20, 50, 100]:\n",
    "            target = rd.choice(generator.movies_ids, replace = False, size=1)\n",
    "            generator.generate_attack_vectors(k, int(i*total-1), target, type='Random', filename=\"test-{}-random-{}-{}\".format(p, i, k))\n",
    "            generator.generate_attack_vectors(k, int(i*total-1), target, type='Average', filename=\"test-{}-average-{}-{}\".format(p, i, k))\n",
    "            generator.generate_attack_vectors(k, int(i*total-1-50), target, type='Bandwagon', filename=\"test-{}-bandwagon-{}-{}\".format(p, i, k))\n",
    "\n",
    "\n",
    "n_r = []\n",
    "\n",
    "for user_id in generator.users_ids:\n",
    "            ratings_user = data.loc[data[\"userID\"] == user_id].values\n",
    "            n_r.append(len(ratings_user))\n",
    "\n",
    "print(np.mean(np.array(n_r)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5061e2ebcf242305dcdb45d871ef5cd4ba433365f314bc2418d41c77ce076e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
